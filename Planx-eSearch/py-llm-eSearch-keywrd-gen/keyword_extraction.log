2025-03-03 06:35:24,830 - config.config - INFO - Received request: text length=823, keyword_count=20
2025-03-03 06:35:24,831 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Cookin... and keyword_count: 20
2025-03-03 06:35:24,831 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:35:29,006 - config.config - INFO - AI response received successfully
2025-03-03 06:35:29,007 - config.config - INFO - Insufficient keywords (10/20): ['meal', 'food', 'recipe', 'ingredients', 'cuisine', 'flavors', 'dishes', 'cooking', 'chefs', 'restaurant']
2025-03-03 06:35:29,007 - config.config - INFO - Filtered keywords: ['meal', 'food', 'recipe', 'ingredients', 'cuisine', 'flavors', 'dishes', 'cooking', 'chefs', 'restaurant', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:35:29,008 - config.config - INFO - Returning keywords: ['meal', 'food', 'recipe', 'ingredients', 'cuisine', 'flavors', 'dishes', 'cooking', 'chefs', 'restaurant', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:37:32,426 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 06:37:32,427 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 06:37:32,427 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:37:33,022 - config.config - INFO - AI response received successfully
2025-03-03 06:37:33,023 - config.config - INFO - Filtered keywords: ['recipe', 'meal', 'food', 'ingredients', 'dish', 'flavors', 'cuisine', 'techniques', 'taste', 'presentation']
2025-03-03 06:37:33,024 - config.config - INFO - Returning keywords: ['recipe', 'meal', 'food', 'ingredients', 'dish', 'flavors', 'cuisine', 'techniques', 'taste', 'presentation']
2025-03-03 06:41:27,356 - config.config - INFO - Received request: text length=7241, keyword_count=10
2025-03-03 06:41:27,356 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Hi. Do... and keyword_count: 10
2025-03-03 06:41:27,357 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:41:28,386 - config.config - INFO - AI response received successfully
2025-03-03 06:41:28,387 - config.config - INFO - Filtered keywords: ['crypto', 'com', 'scammer', 'reminder', 'telegram', 'cro', 'price', 'investment', 'advice', 'scams']
2025-03-03 06:41:28,388 - config.config - INFO - Returning keywords: ['crypto', 'com', 'scammer', 'reminder', 'telegram', 'cro', 'price', 'investment', 'advice', 'scams']
2025-03-03 06:41:49,725 - config.config - INFO - Received request: text length=7241, keyword_count=20
2025-03-03 06:41:49,726 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Hi. Do... and keyword_count: 20
2025-03-03 06:41:49,726 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:41:50,705 - config.config - INFO - AI response received successfully
2025-03-03 06:41:50,706 - config.config - INFO - Insufficient keywords (10/20): ['crypto', 'com', 'scammer', 'reminder', 'important', 'message', 'private', 'telegram', 'channel', 'announcements']
2025-03-03 06:41:50,707 - config.config - INFO - Filtered keywords: ['crypto', 'com', 'scammer', 'reminder', 'important', 'message', 'private', 'telegram', 'channel', 'announcements', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:41:50,707 - config.config - INFO - Returning keywords: ['crypto', 'com', 'scammer', 'reminder', 'important', 'message', 'private', 'telegram', 'channel', 'announcements', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:42:04,245 - config.config - INFO - Received request: text length=7241, keyword_count=10
2025-03-03 06:42:04,245 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Hi. Do... and keyword_count: 10
2025-03-03 06:42:04,246 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:42:05,230 - config.config - INFO - AI response received successfully
2025-03-03 06:42:05,232 - config.config - INFO - Filtered keywords: ['crypto', 'scammer', 'reminder', 'group', 'investment', 'price', 'prediction', 'telegram', 'announcements', 'channel']
2025-03-03 06:42:05,232 - config.config - INFO - Returning keywords: ['crypto', 'scammer', 'reminder', 'group', 'investment', 'price', 'prediction', 'telegram', 'announcements', 'channel']
2025-03-03 06:42:36,161 - config.config - INFO - Received request: text length=7241, keyword_count=10
2025-03-03 06:42:36,162 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Hi. Do... and keyword_count: 10
2025-03-03 06:42:36,163 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-03 06:42:41,696 - config.config - INFO - AI response received successfully
2025-03-03 06:42:41,697 - config.config - INFO - Filtered keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'scams', 'bitcoin', 'ethereum']
2025-03-03 06:42:41,697 - config.config - INFO - Returning keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'scams', 'bitcoin', 'ethereum']
2025-03-03 06:43:02,085 - config.config - INFO - Received request: text length=7241, keyword_count=20
2025-03-03 06:43:02,086 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Hi. Do... and keyword_count: 20
2025-03-03 06:43:02,086 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-03 06:43:07,196 - config.config - INFO - AI response received successfully
2025-03-03 06:43:07,197 - config.config - INFO - Insufficient keywords (10/20): ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'group', 'official', 'important', 'reminder']
2025-03-03 06:43:07,197 - config.config - INFO - Filtered keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'group', 'official', 'important', 'reminder', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:43:07,198 - config.config - INFO - Returning keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'group', 'official', 'important', 'reminder', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:43:35,514 - config.config - INFO - Received request: text length=7241, keyword_count=50
2025-03-03 06:43:35,515 - config.config - INFO - Querying LLM with prompt: Extract the top 50 keywords from this text: Hi. Do... and keyword_count: 50
2025-03-03 06:43:35,516 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-03 06:43:40,671 - config.config - INFO - AI response received successfully
2025-03-03 06:43:40,672 - config.config - INFO - Insufficient keywords (10/50): ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'scams', 'group', 'official']
2025-03-03 06:43:40,672 - config.config - INFO - Filtered keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'scams', 'group', 'official', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:43:40,672 - config.config - INFO - Returning keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'scams', 'group', 'official', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:43:47,592 - config.config - INFO - Received request: text length=7241, keyword_count=50
2025-03-03 06:43:47,592 - config.config - INFO - Querying LLM with prompt: Extract the top 50 keywords from this text: Hi. Do... and keyword_count: 50
2025-03-03 06:43:47,592 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-03 06:43:49,484 - config.config - INFO - AI response received successfully
2025-03-03 06:43:49,485 - config.config - INFO - Insufficient keywords (10/50): ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'group', 'official', 'important', 'reminder', 'scams']
2025-03-03 06:43:49,485 - config.config - INFO - Filtered keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'group', 'official', 'important', 'reminder', 'scams', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:43:49,486 - config.config - INFO - Returning keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'group', 'official', 'important', 'reminder', 'scams', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:44:35,501 - config.config - INFO - Received request: text length=7241, keyword_count=15
2025-03-03 06:44:35,502 - config.config - INFO - Querying LLM with prompt: Extract the top 15 keywords from this text: Hi. Do... and keyword_count: 15
2025-03-03 06:44:35,502 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-03 06:44:40,634 - config.config - INFO - AI response received successfully
2025-03-03 06:44:40,635 - config.config - INFO - Insufficient keywords (10/15): ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'investment', 'price', 'scams', 'group', 'official']
2025-03-03 06:44:40,636 - config.config - INFO - Filtered keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'investment', 'price', 'scams', 'group', 'official', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:44:40,636 - config.config - INFO - Returning keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'investment', 'price', 'scams', 'group', 'official', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:45:44,286 - config.config - INFO - Received request: text length=7241, keyword_count=15
2025-03-03 06:45:44,286 - config.config - INFO - Querying LLM with prompt: Extract the top 15 keywords from this text: Hi. Do... and keyword_count: 15
2025-03-03 06:45:44,286 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-03 06:45:51,629 - config.config - INFO - AI response received successfully
2025-03-03 06:45:51,631 - config.config - INFO - Filtered keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'scams', 'group', 'official', 'announcements', 'channel', 'news', 'updates', 'insights', 'security', 'tips', 'reminder', 'team', 'support', 'ambassadors', 'moderators']
2025-03-03 06:45:51,631 - config.config - INFO - Returning keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'scams', 'group', 'official', 'announcements', 'channel', 'news', 'updates', 'insights']
2025-03-03 06:46:26,749 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 06:46:26,749 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 06:46:26,749 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:46:27,349 - config.config - INFO - AI response received successfully
2025-03-03 06:46:27,349 - config.config - INFO - Filtered keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'aroma']
2025-03-03 06:46:27,351 - config.config - INFO - Returning keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'aroma']
2025-03-03 06:46:28,896 - config.config - INFO - Received request: text length=7241, keyword_count=25
2025-03-03 06:46:28,896 - config.config - INFO - Querying LLM with prompt: Extract the top 25 keywords from this text: Hi. Do... and keyword_count: 25
2025-03-03 06:46:28,896 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-03 06:46:39,848 - config.config - INFO - AI response received successfully
2025-03-03 06:46:39,849 - config.config - INFO - Filtered keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'group', 'official', 'reminder', 'important', 'scams', 'protect', 'pinned', 'messages', 'buy', 'sell', 'earn', 'defi', 'bitcoin', 'ethereum', 'finance', 'lending', 'polkadot', 'trust', 'upgrade', 'revenue', 'trading', 'volume', 'spread', 'brokerage', 'service', 'xrp', 'prices', 'announcements', 'channel', 'news', 'updates', 'insights', 'onchain', 'wallet', 'lcro', 'delisted']
2025-03-03 06:46:39,849 - config.config - INFO - Returning keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'group', 'official', 'reminder', 'important', 'scams', 'protect', 'pinned', 'messages', 'buy', 'sell', 'earn', 'defi', 'bitcoin', 'ethereum', 'finance', 'lending', 'polkadot', 'trust']
2025-03-03 06:46:40,057 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 06:46:40,057 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 06:46:40,057 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:46:40,586 - config.config - INFO - AI response received successfully
2025-03-03 06:46:40,587 - config.config - INFO - Filtered keywords: ['food', 'meal', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'aroma']
2025-03-03 06:46:40,587 - config.config - INFO - Returning keywords: ['food', 'meal', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'aroma']
2025-03-03 06:47:06,073 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 06:47:06,074 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 06:47:06,074 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:47:06,606 - config.config - INFO - AI response received successfully
2025-03-03 06:47:06,606 - config.config - INFO - Filtered keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma']
2025-03-03 06:47:06,607 - config.config - INFO - Returning keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma']
2025-03-03 06:47:09,446 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 06:47:09,446 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 06:47:09,446 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:47:09,984 - config.config - INFO - AI response received successfully
2025-03-03 06:47:09,985 - config.config - INFO - Filtered keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques']
2025-03-03 06:47:09,985 - config.config - INFO - Returning keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques']
2025-03-03 06:47:13,212 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 06:47:13,212 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 06:47:13,213 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:47:13,756 - config.config - INFO - AI response received successfully
2025-03-03 06:47:13,757 - config.config - INFO - Filtered keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma']
2025-03-03 06:47:13,757 - config.config - INFO - Returning keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma']
2025-03-03 06:48:40,277 - config.config - INFO - Received request: text length=7241, keyword_count=18
2025-03-03 06:48:40,277 - config.config - INFO - Querying LLM with prompt: Extract the top 18 keywords from this text: Hi. Do... and keyword_count: 18
2025-03-03 06:48:40,277 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-03 06:48:50,529 - config.config - INFO - AI response received successfully
2025-03-03 06:48:50,531 - config.config - INFO - Filtered keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'scams', 'group', 'official', 'announcements', 'channel', 'news', 'updates', 'insights', 'security', 'tips', 'finance', 'decentralized', 'bitcoin', 'ethereum', 'defi', 'lending', 'polkadot', 'trust', 'pectra', 'upgrade', 'brokerage', 'service', 'revenue', 'trading', 'volume', 'xrp', 'prices', 'spread', 'buy', 'sell', 'cdc']
2025-03-03 06:48:50,531 - config.config - INFO - Returning keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'scams', 'group', 'official', 'announcements', 'channel', 'news', 'updates', 'insights', 'security', 'tips', 'finance']
2025-03-03 06:55:31,010 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 06:55:31,010 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 06:55:31,010 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:55:31,538 - config.config - INFO - AI response received successfully
2025-03-03 06:55:31,539 - config.config - INFO - Filtered keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'presentation']
2025-03-03 06:55:31,539 - config.config - INFO - Returning keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'presentation']
2025-03-03 06:58:05,325 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 06:58:05,327 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 06:58:05,328 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:58:05,974 - config.config - INFO - AI response received successfully
2025-03-03 06:58:05,975 - config.config - INFO - Filtered keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'aroma']
2025-03-03 06:58:05,975 - config.config - INFO - Returning keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'aroma']
2025-03-03 08:47:55,815 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 08:47:55,817 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 08:47:55,817 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 08:47:59,759 - config.config - INFO - AI response received successfully
2025-03-03 08:47:59,761 - config.config - INFO - Filtered keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'restaurant']
2025-03-03 08:47:59,761 - config.config - INFO - Returning keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'restaurant']
2025-03-03 08:51:34,884 - config.config - INFO - Received request: text length=823, keyword_count=20
2025-03-03 08:51:34,885 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Cookin... and keyword_count: 20
2025-03-03 08:51:34,885 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 08:51:35,791 - config.config - INFO - AI response received successfully
2025-03-03 08:51:35,792 - config.config - INFO - Filtered keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma', 'texture', 'presentation', 'restaurants', 'dining', 'kitchen', 'meat', 'vegetable', 'seasonal']
2025-03-03 08:51:35,792 - config.config - INFO - Returning keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma', 'texture', 'presentation', 'restaurants', 'dining', 'kitchen', 'meat', 'vegetable', 'seasonal']
2025-03-03 08:52:14,268 - config.config - INFO - Received request: text length=823, keyword_count=20
2025-03-03 08:52:14,268 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Cookin... and keyword_count: 20
2025-03-03 08:52:14,268 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 08:52:15,132 - config.config - INFO - AI response received successfully
2025-03-03 08:52:15,133 - config.config - INFO - Filtered keywords: ['recipe', 'meal', 'food', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma', 'texture', 'presentation', 'restaurants', 'dining', 'kitchens', 'cooks', 'meats', 'vegetables', 'herbs']
2025-03-03 08:52:15,133 - config.config - INFO - Returning keywords: ['recipe', 'meal', 'food', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma', 'texture', 'presentation', 'restaurants', 'dining', 'kitchens', 'cooks', 'meats', 'vegetables', 'herbs']
2025-03-03 08:53:17,024 - config.config - INFO - Received request: text length=823, keyword_count=20
2025-03-03 08:53:17,024 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Cookin... and keyword_count: 20
2025-03-03 08:53:17,025 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 08:53:17,886 - config.config - INFO - AI response received successfully
2025-03-03 08:53:17,888 - config.config - INFO - Filtered keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma', 'texture', 'presentation', 'restaurants', 'dining', 'cooks', 'kitchens', 'family', 'dinner', 'restaurant']
2025-03-03 08:53:17,888 - config.config - INFO - Returning keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma', 'texture', 'presentation', 'restaurants', 'dining', 'cooks', 'kitchens', 'family', 'dinner', 'restaurant']
2025-03-03 10:28:54,976 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 10:28:54,977 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 10:28:54,977 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 10:28:58,839 - config.config - INFO - AI response received successfully
2025-03-03 10:28:58,840 - config.config - INFO - Filtered keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques']
2025-03-03 10:28:58,840 - config.config - INFO - Returning keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques']
2025-03-03 10:29:04,571 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 10:29:04,571 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 10:29:04,572 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 10:29:05,098 - config.config - INFO - AI response received successfully
2025-03-03 10:29:05,099 - config.config - INFO - Filtered keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'restaurant']
2025-03-03 10:29:05,099 - config.config - INFO - Returning keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'restaurant']
2025-03-03 10:31:28,330 - config.config - INFO - Received request: text length=458, keyword_count=10
2025-03-03 10:31:28,330 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Bruise... and keyword_count: 10
2025-03-03 10:31:28,330 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 10:31:28,927 - config.config - INFO - AI response received successfully
2025-03-03 10:31:28,928 - config.config - INFO - Filtered keywords: ['zelensky', 'ukrainian', 'trump', 'vance', 'stansted', 'airport', 'british', 'summit', 'leaders', 'president']
2025-03-03 10:31:28,928 - config.config - INFO - Returning keywords: ['zelensky', 'ukrainian', 'trump', 'vance', 'stansted', 'airport', 'british', 'summit', 'leaders', 'president']
2025-03-03 10:33:21,041 - config.config - INFO - Received request: text length=4519, keyword_count=10
2025-03-03 10:33:21,042 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Bruise... and keyword_count: 10
2025-03-03 10:33:21,042 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 10:33:21,814 - config.config - INFO - AI response received successfully
2025-03-03 10:33:21,815 - config.config - INFO - Filtered keywords: ['zelensky', 'ukraine', 'trump', 'macron', 'uk', 'us', 'russia', 'putin', 'nato', 'war']
2025-03-03 10:33:21,815 - config.config - INFO - Returning keywords: ['zelensky', 'ukraine', 'trump', 'macron', 'uk', 'us', 'russia', 'putin', 'nato', 'war']
2025-03-03 10:39:30,864 - config.config - INFO - Received request: text length=2115, keyword_count=10
2025-03-03 10:39:30,864 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: BREAKI... and keyword_count: 10
2025-03-03 10:39:30,864 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 10:39:31,536 - config.config - INFO - AI response received successfully
2025-03-03 10:39:31,536 - config.config - INFO - Filtered keywords: ['cryptocurrency', 'tokens', 'governance', 'market', 'economy', 'investors', 'gdp', 'bitcoin', 'ethereum', 'blockchain']
2025-03-03 10:39:31,537 - config.config - INFO - Returning keywords: ['cryptocurrency', 'tokens', 'governance', 'market', 'economy', 'investors', 'gdp', 'bitcoin', 'ethereum', 'blockchain']
2025-03-04 06:29:06,515 - config.config - INFO - Received request: text length=823, keyword_count=20
2025-03-04 06:29:06,516 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Cookin... and keyword_count: 20
2025-03-04 06:29:06,516 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-04 06:29:10,953 - config.config - INFO - AI response received successfully
2025-03-04 06:29:10,954 - config.config - INFO - Filtered keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma', 'texture', 'presentation', 'restaurants', 'dining', 'kitchens', 'home', 'cooks', 'meat']
2025-03-04 06:29:10,954 - config.config - INFO - Returning keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma', 'texture', 'presentation', 'restaurants', 'dining', 'kitchens', 'home', 'cooks', 'meat']
2025-03-04 09:28:27,047 - config.config - INFO - Received request: text length=6, keyword_count=20
2025-03-04 09:28:27,048 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: string... and keyword_count: 20
2025-03-04 09:28:27,049 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-04 09:29:24,234 - config.config - INFO - AI response received successfully
2025-03-04 09:29:24,236 - config.config - INFO - Insufficient keywords (1/20): ['string']
2025-03-04 09:29:24,236 - config.config - INFO - Filtered keywords: ['string', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-04 09:29:24,237 - config.config - INFO - Returning keywords: ['string', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 02:26:31,836 - config.config - INFO - Produced data to Kafka topic doc2kywrd: doc_001
2025-03-05 02:26:31,839 - config.config - INFO - Starting Kafka consumer for topic: doc2kywrd
2025-03-05 02:26:31,839 - config.config - INFO - Starting FastAPI application...
2025-03-05 02:26:32,186 - config.config - INFO - Consumed message from Kafka topic doc2kywrd: doc_id=doc_001
2025-03-05 02:26:32,186 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: AI and... and keyword_count: 20
2025-03-05 02:26:32,186 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 02:28:01,325 - config.config - INFO - AI response received successfully
2025-03-05 02:28:01,327 - config.config - INFO - Filtered keywords: ['ai', 'machine', 'learning', 'transforming', 'tech', 'and', 'are', 'technology', 'artificial', 'intelligence', 'innovation', 'digital', 'future', 'industry', 'automation', 'data', 'science', 'computing', 'algorithms', 'systems']
2025-03-05 02:28:01,328 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Machin... and keyword_count: 20
2025-03-05 02:28:01,328 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 02:28:04,603 - config.config - INFO - AI response received successfully
2025-03-05 02:28:04,603 - config.config - INFO - Filtered keywords: ['machine', 'learning', 'news', 'trending', 'today', 'technology', 'artificial', 'intelligence', 'industry', 'innovation', 'data', 'science', 'computing', 'algorithm', 'model', 'training', 'neural', 'networks', 'deep', 'ai']
2025-03-05 02:28:04,604 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Tech d... and keyword_count: 20
2025-03-05 02:28:04,604 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 02:28:05,527 - config.config - INFO - AI response received successfully
2025-03-05 02:28:05,527 - config.config - INFO - Insufficient keywords (4/20): ['tech', 'data', 'innovation', 'drives']
2025-03-05 02:28:05,528 - config.config - INFO - Filtered keywords: ['tech', 'data', 'innovation', 'drives', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 02:28:05,649 - config.config - INFO - Processed and sent to Kafka topic kywrd 2vec: doc_001
2025-03-05 03:43:55,031 - config.llm_config - INFO - Produced data to Kafka topic document-to-keywords: doc_001
2025-03-05 03:43:55,032 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-05 03:43:55,033 - config.llm_config - INFO - Starting FastAPI application...
2025-03-05 03:43:55,406 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady2
2025-03-05 03:43:55,407 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Yeah b... and keyword_count: 20
2025-03-05 03:43:55,407 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 03:45:30,099 - config.llm_config - INFO - AI response received successfully
2025-03-05 03:45:30,102 - config.llm_config - INFO - Filtered keywords: ['crypto', 'cro', 'token', 'price', 'supply', 'demand', 'market', 'bitcoin', 'blockchain', 'scam', 'telegram', 'investment', 'trading', 'customers', 'loyal', 'support', 'ambassadors', 'announcements', 'channels', 'news', 'updates', 'insights', 'security']
2025-03-05 03:45:30,107 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3Wd1Ady2
2025-03-05 03:45:30,109 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=doc_001
2025-03-05 03:45:30,110 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: AI and... and keyword_count: 20
2025-03-05 03:45:30,110 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 03:45:33,360 - config.llm_config - INFO - AI response received successfully
2025-03-05 03:45:33,360 - config.llm_config - INFO - Filtered keywords: ['ai', 'machine', 'learning', 'tech', 'transforming', 'and', 'are', 'technology', 'artificial', 'intelligence', 'innovation', 'digital', 'future', 'data', 'science', 'automation', 'computing', 'algorithms', 'software', 'systems']
2025-03-05 03:45:33,361 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Machin... and keyword_count: 20
2025-03-05 03:45:33,361 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 03:45:36,495 - config.llm_config - INFO - AI response received successfully
2025-03-05 03:45:36,496 - config.llm_config - INFO - Filtered keywords: ['machine', 'learning', 'news', 'today', 'trending', 'is', 'artificial', 'intelligence', 'technology', 'data', 'science', 'ai', 'ml', 'model', 'algorithm', 'computer', 'system', 'network', 'deep', 'natural']
2025-03-05 03:45:36,496 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Tech d... and keyword_count: 20
2025-03-05 03:45:36,497 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 03:45:37,425 - config.llm_config - INFO - AI response received successfully
2025-03-05 03:45:37,425 - config.llm_config - INFO - Insufficient keywords (4/20): ['tech', 'data', 'drives', 'innovation']
2025-03-05 03:45:37,425 - config.llm_config - INFO - Filtered keywords: ['tech', 'data', 'drives', 'innovation', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 03:45:37,426 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: doc_001
2025-03-05 03:49:14,267 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady2
2025-03-05 03:49:14,270 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: È°∂È°∂È°∂È°∂È°∂È°∂... and keyword_count: 20 n
2025-03-05 03:49:14,271 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 03:49:17,863 - config.llm_config - INFO - AI response received successfully
2025-03-05 03:49:17,865 - config.llm_config - INFO - Insufficient keywords (19/20): ['d', 'a', 'w', 'o', 'i', 'b', 'k', 'j', 'f', 'h', 'g', 'v', 's', 'ddddddddddd', 'aaaaaaaaaaaa', 'wwwwwwwwwww', 'bj', 'fb', 'ji']
2025-03-05 03:49:17,865 - config.llm_config - INFO - Filtered keywords: ['d', 'a', 'w', 'o', 'i', 'b', 'k', 'j', 'f', 'h', 'g', 'v', 's', 'ddddddddddd', 'aaaaaaaaaaaa', 'wwwwwwwwwww', 'bj', 'fb', 'ji', 'default']
2025-03-05 03:49:17,867 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3Wd1Ady2
2025-03-05 06:39:16,099 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady2
2025-03-05 06:39:16,100 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: https:... and keyword_count: 20
2025-03-05 06:39:16,101 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:42:17,737 - config.llm_config - ERROR - Request failed, error type: InternalServerError, details: <html>
<head><title>504 Gateway Time-out</title></head>
<body>
<center><h1>504 Gateway Time-out</h1></center>
<hr><center>nginx/1.18.0 (Ubuntu)</center>
</body>
</html>
2025-03-05 06:42:17,738 - config.llm_config - ERROR - LLM query failed, returning 20 error keywords
2025-03-05 06:42:17,738 - config.llm_config - ERROR - Processing error for doc_id 3Wd1Ady2: Failed to extract keywords for block 1
2025-03-05 06:47:46,987 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady2
2025-03-05 06:47:46,988 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: What i... and keyword_count: 20
2025-03-05 06:47:46,988 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:49:14,897 - config.llm_config - INFO - AI response received successfully
2025-03-05 06:49:14,898 - config.llm_config - INFO - Filtered keywords: ['cryptocurrency', 'trading', 'spot', 'market', 'price', 'bitcoin', 'investors', 'gdp', 'economy', 'governance', 'tokens', 'crypto', 'assets', 'transactions', 'regulators', 'volatility', 'risk', 'yield', 'staking', 'liquidity']
2025-03-05 06:49:14,899 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: invest... and keyword_count: 20
2025-03-05 06:49:14,899 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:49:20,942 - config.llm_config - INFO - AI response received successfully
2025-03-05 06:49:20,943 - config.llm_config - INFO - Filtered keywords: ['cryptocurrency', 'trading', 'bitcoin', 'market', 'price', 'supply', 'demand', 'investors', 'risk', 'reward', 'volume', 'liquidity', 'sentiment', 'orders', 'capitalization', 'volatility', 'whales', 'flippening', 'ether', 'altcoin']
2025-03-05 06:49:20,943 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ump ad... and keyword_count: 20
2025-03-05 06:49:20,944 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:49:27,340 - config.llm_config - INFO - AI response received successfully
2025-03-05 06:49:27,341 - config.llm_config - INFO - Filtered keywords: ['trading', 'algorithms', 'crypto', 'bitcoin', 'market', 'volatility', 'vix', 'price', 'liquidity', 'assets', 'transactions', 'blockchain', 'risk', 'management', 'traders', 'strategies', 'investors', 'sentiment', 'supply', 'shocks', 'atomicity', 'exchanges']
2025-03-05 06:49:27,342 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: of tru... and keyword_count: 20
2025-03-05 06:49:27,342 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:49:34,159 - config.llm_config - INFO - AI response received successfully
2025-03-05 06:49:34,160 - config.llm_config - INFO - Insufficient keywords (16/20): ['bitcoin', 'crypto', 'trading', 'market', 'exchange', 'binance', 'microstrategy', 'stablecoins', 'tether', 'usdt', 'usdc', 'ethereum', 'blockchain', 'defi', 'investments', 'sec']
2025-03-05 06:49:34,160 - config.llm_config - INFO - Filtered keywords: ['bitcoin', 'crypto', 'trading', 'market', 'exchange', 'binance', 'microstrategy', 'stablecoins', 'tether', 'usdt', 'usdc', 'ethereum', 'blockchain', 'defi', 'investments', 'sec', 'default', 'default', 'default', 'default']
2025-03-05 06:49:34,160 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: thereu... and keyword_count: 20
2025-03-05 06:49:34,161 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:49:35,438 - config.llm_config - INFO - Received request: text length=6, keyword_count=20
2025-03-05 06:49:35,438 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: string... and keyword_count: 20
2025-03-05 06:49:35,439 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:49:36,225 - config.llm_config - INFO - AI response received successfully
2025-03-05 06:49:36,226 - config.llm_config - INFO - Insufficient keywords (1/20): ['string']
2025-03-05 06:49:36,226 - config.llm_config - INFO - Filtered keywords: ['string', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 06:49:36,227 - config.llm_config - INFO - Returning keywords: ['string', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 06:49:38,487 - config.llm_config - INFO - AI response received successfully
2025-03-05 06:49:38,487 - config.llm_config - INFO - Filtered keywords: ['bitcoin', 'blockchain', 'binance', 'transfers', 'security', 'ecosystem', 'networks', 'user', 'experience', 'cz', 'meme', 'coins', 'industry', 'trends', 'history', 'november', 'gain', 'daily', 'standardize', 'link']
2025-03-05 06:49:38,489 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3Wd1Ady2
2025-03-05 06:51:32,759 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady2
2025-03-05 06:51:32,760 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: [·ëé·ëå·ôê·ó™·òà... and keyword_count: 20
2025-03-05 06:51:32,760 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:51:58,472 - config.llm_config - INFO - AI response received successfully
2025-03-05 06:51:58,474 - config.llm_config - WARNING - No Python list format found in response: It appears you've shared a log of events from a Telegram group, detailing various user interactions and moderation actions. Here's a breakdown of what can be understood from the provided text:

1. **User Bans**: Multiple users have been banned due to "CAS ban," which refers to bans enforced by the Combot Anti-Spam system. This system is designed to automatically detect and prevent spam activities within Telegram groups. Users like `keller`, `svyatoslav`, `üòà`, `·Ö†·Ö†`, `ùì°ùì™ùì≠ùì∂ùì≤ùìµùìÆùì≤ùìµùì™`, `achaq`, `–Ø.. –ê –∫—Ç–æ —è? –Ø –ü–ò–ö–ú–ò –°–û–ë–ê–ö–ê`, `de`, `musema Abdela`, `Ahmad Sa‚Äôad`, `–í–µ—Ä–æ–Ω–∏–∫–∞`, `‚ìÇÔ∏è MEMES K,m`, `Orelvis BM`, `–ê–ª–∏–Ω–∞ –ú–∞—Å–ª–æ–≤–∞`, `–ê–∑–∞–ª–∏—è`, and `ü•Éü•ûüß°‚ô°ùô≥ùöéùöüùöòùöåùöëùöîùöä-ùöôùöíùöòùöóùöéùöõùöòùöåùöëùöîùöä‚ô°ü•ûüçÅ` have been banned for this reason.

2. **Muted Users**: Some users, like `Malik` and `Abdin`, have been muted for sending spam messages. The duration of their mute is specified, indicating a temporary measure to discourage further spamming.

3. **General Conversations**: Among the moderation actions, there are snippets of general conversation that seem unrelated to the bans or mutes. These include philosophical reflections on mistakes and learning, comments about dietary supplements, expressions of loneliness, and discussions on inner strength and wealth. There's also a mention of reading a book with a humorous title.

4. **Greetings and Positive Messages**: Some messages are simple greetings ("Assalamu Alaikum", "Hello everyone") or positive affirmations ("Have a nice day or night", "Inner strength is the greatest wealth").

In summary, the log shows a mix of moderation actions (bans and mutes) aimed at controlling spam within the group, alongside various conversational snippets that reflect the diverse discussions occurring among group members.
2025-03-05 06:51:58,474 - config.llm_config - ERROR - Processing error for doc_id 3Wd1Ady2: Failed to extract keywords for block 1
2025-03-05 06:57:21,219 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady215hLjbMO
2025-03-05 06:57:21,220 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **How ... and keyword_count: 20
2025-03-05 06:57:21,221 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:58:25,047 - config.llm_config - INFO - Received request: text length=6, keyword_count=20
2025-03-05 06:58:25,048 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: string... and keyword_count: 20
2025-03-05 06:58:25,048 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:58:48,393 - config.llm_config - INFO - AI response received successfully
2025-03-05 06:58:48,394 - config.llm_config - INFO - Insufficient keywords (1/20): ['string']
2025-03-05 06:58:48,395 - config.llm_config - INFO - Filtered keywords: ['string', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 06:58:48,395 - config.llm_config - INFO - Returning keywords: ['string', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 06:58:59,512 - config.llm_config - INFO - AI response received successfully
2025-03-05 06:58:59,513 - config.llm_config - WARNING - No Python list format found in response: Here are the top 20 keywords extracted from the text:

1. **Frog Farm** (14 occurrences)
2. **Crypto** (12 occurrences)
3. **Token** (8 occurrences)
4. **DeFi** (7 occurrences)
5. **Exchange** (6 occurrences)
6. **Trading** (6 occurrences)
7. **Ecosystem** (6 occurrences)
8. **Security** (5 occurrences)
9. **Privacy** (5 occurrences)
10. **Launchpad** (5 occurrences)
11. **VPN** (5 occurrences)
12. **$FROG** (5 occurrences)
13. **BingX** (4 occurrences)
14. **Spot trading** (4 occurrences)
15. **Meme coins** (3 occurrences)
16. **Automated bot** (3 occurrences)
17. **Staking** (3 occurrences)
18. **Liquidity** (3 occurrences)
19. **DAO** (2 occurrences)
20. **Gamification** (2 occurrences)

Note that the frequency of each keyword is an approximate measure and may vary depending on the specific text analysis tool or technique used.
2025-03-05 06:58:59,513 - config.llm_config - ERROR - Processing error for doc_id 3Wd1Ady215hLjbMO: Failed to extract keywords for block 1
2025-03-05 07:10:04,621 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady215hLjbMO
2025-03-05 07:10:04,622 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **How ... and keyword_count: 20
2025-03-05 07:10:04,623 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:11:46,263 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:11:46,264 - config.llm_config - INFO - Insufficient keywords (19/20): ['frog', 'farm', 'crypto', 'trading', 'exchange', 'token', 'ecosystem', 'security', 'fees', 'interface', 'execution', 'tokens', 'launchpad', 'vpn', 'community', 'event', 'airdrop', 'bingx', 'blockchain']
2025-03-05 07:11:46,264 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'crypto', 'trading', 'exchange', 'token', 'ecosystem', 'security', 'fees', 'interface', 'execution', 'tokens', 'launchpad', 'vpn', 'community', 'event', 'airdrop', 'bingx', 'blockchain', 'default']
2025-03-05 07:11:46,264 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ces, F... and keyword_count: 20
2025-03-05 07:11:46,265 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:11:52,499 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:11:52,500 - config.llm_config - INFO - Filtered keywords: ['frog', 'defi', 'token', 'ecosystem', 'crypto', 'trade', 'farm', 'usdt', 'exchange', 'bingx', 'wallet', 'launchpad', 'vpn', 'security', 'decentralized', 'finance', 'trading', 'invest', 'earn', 'frog']
2025-03-05 07:11:52,500 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: eciate... and keyword_count: 20
2025-03-05 07:11:52,501 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:12:01,393 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:12:01,394 - config.llm_config - INFO - Filtered keywords: ['frog', 'bingx', 'usdt', 'token', 'trade', 'listing', 'exchange', 'wallet', 'twitter', 'price', 'volume', 'ath', 'participants', 'prize', 'promo', 'celebration', 'giveaway', 'winners', 'ecosystem', 'market', 'liquidated', 'traders', 'trends', 'economy', 'supply', 'demand', 'value', 'burns']
2025-03-05 07:12:01,394 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  token... and keyword_count: 20
2025-03-05 07:12:01,394 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:12:08,310 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:12:08,311 - config.llm_config - INFO - Filtered keywords: ['token', 'ecosystem', 'listing', 'exchange', 'crypto', 'trading', 'bot', 'fees', 'rewards', 'features', 'launch', 'products', 'demand', 'engagement', 'price', 'impact', 'tokenomics', 'wallet', 'twitter', 'instagram']
2025-03-05 07:12:08,311 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: our pa... and keyword_count: 20
2025-03-05 07:12:08,311 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:12:15,149 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:12:15,150 - config.llm_config - INFO - Filtered keywords: ['token', 'frog', 'ecosystem', 'users', 'crypto', 'bot', 'trading', 'deposits', 'withdrawals', 'trades', 'airdrop', 'beta', 'testing', 'listing', 'cex', 'usdt', 'solana', 'blockchain', 'nfts', 'farming']
2025-03-05 07:12:15,150 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ive.go... and keyword_count: 20
2025-03-05 07:12:15,150 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:12:21,447 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:12:21,447 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'token', 'listing', 'solana', 'network', 'blockchain', 'crypto', 'ecosystem', 'wallet', 'exchange', 'launchpad', 'lottery', 'vpn', 'service', 'tokenomics', 'frog', 'coin', 'cryptocurrency', 'project']
2025-03-05 07:12:21,448 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: expect... and keyword_count: 20
2025-03-05 07:12:21,448 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:12:28,114 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:12:28,115 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'token', 'crypto', 'meme', 'coin', 'trading', 'airdrop', 'rewards', 'testing', 'ecosystem', 'wallet', 'telegram', 'bot', 'staking', 'lottery', 'bug', 'bounty', 'program', 'litepaper']
2025-03-05 07:12:28,115 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  and w... and keyword_count: 20
2025-03-05 07:12:28,115 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:12:34,696 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:12:34,697 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'ecosystem', 'beta', 'testing', 'crypto', 'bot', 'wallet', 'lottery', 'mining', 'listing', 'rewards', 'game', 'telegram', 'twitter', 'instagram', 'lite', 'paper', 'croaks', 'farming']
2025-03-05 07:12:34,698 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: produc... and keyword_count: 20
2025-03-05 07:12:34,698 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:12:41,239 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:12:41,240 - config.llm_config - INFO - Insufficient keywords (19/20): ['frog', 'farm', 'nft', 'ecosystem', 'cryptocurrency', 'security', 'telegram', 'integration', 'crypto', 'lottery', 'staking', 'transfers', 'unique', 'features', 'innovative', 'platform', 'assets', 'protection', 'safety']
2025-03-05 07:12:41,240 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'nft', 'ecosystem', 'cryptocurrency', 'security', 'telegram', 'integration', 'crypto', 'lottery', 'staking', 'transfers', 'unique', 'features', 'innovative', 'platform', 'assets', 'protection', 'safety', 'default']
2025-03-05 07:12:41,240 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: deos:*... and keyword_count: 20
2025-03-05 07:12:41,241 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:12:45,116 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:12:45,117 - config.llm_config - INFO - Filtered keywords: ['youtube', 'game', 'twitter', 'lite', 'paper', 'en', 'ru', 'eng', 'cis', 'you', 'tube', 'frog', 'farm', 'bot', 'xcom', 'farmgamefrog', 'google', 'drive', 'file', 'link']
2025-03-05 07:12:45,119 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3Wd1Ady215hLjbMO
2025-03-05 07:25:12,358 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady215hLjbMO
2025-03-05 07:25:12,359 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **How ... and keyword_count: 20
2025-03-05 07:25:12,359 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:26:40,867 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:26:40,868 - config.llm_config - INFO - Insufficient keywords (19/20): ['frog', 'farm', 'crypto', 'trading', 'exchange', 'token', 'security', 'ecosystem', 'launchpad', 'vpn', 'wallet', 'twitter', 'bingx', 'airdrop', 'event', 'spot', 'bot', 'nfts', 'defi']
2025-03-05 07:26:40,868 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'crypto', 'trading', 'exchange', 'token', 'security', 'ecosystem', 'launchpad', 'vpn', 'wallet', 'twitter', 'bingx', 'airdrop', 'event', 'spot', 'bot', 'nfts', 'defi', 'default']
2025-03-05 07:26:40,869 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ces, F... and keyword_count: 20
2025-03-05 07:26:40,869 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:26:47,171 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:26:47,172 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'defi', 'token', 'crypto', 'trade', 'earn', 'store', 'bingx', 'usdt', 'exchange', 'ecosystem', 'wallet', 'vpn', 'launchpad', 'security', 'privacy', 'invest', 'launch', 'trading']
2025-03-05 07:26:47,172 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: eciate... and keyword_count: 20
2025-03-05 07:26:47,173 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:26:54,647 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:26:54,647 - config.llm_config - INFO - Filtered keywords: ['frog', 'bingx', 'usdt', 'token', 'trade', 'listing', 'exchange', 'wallet', 'twitter', 'price', 'volume', 'ath', 'participants', 'prize', 'promo', 'celebration', 'giveaway', 'winners', 'ecosystem', 'market', 'cryptocurrency', 'blockchain']
2025-03-05 07:26:54,648 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  token... and keyword_count: 20
2025-03-05 07:26:54,648 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:27:00,958 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:27:00,959 - config.llm_config - INFO - Insufficient keywords (18/20): ['token', 'ecosystem', 'listing', 'exchange', 'crypto', 'trading', 'bot', 'fees', 'rewards', 'lottery', 'features', 'launch', 'products', 'demand', 'engagement', 'wallet', 'twitter', 'instagram']
2025-03-05 07:27:00,959 - config.llm_config - INFO - Filtered keywords: ['token', 'ecosystem', 'listing', 'exchange', 'crypto', 'trading', 'bot', 'fees', 'rewards', 'lottery', 'features', 'launch', 'products', 'demand', 'engagement', 'wallet', 'twitter', 'instagram', 'default', 'default']
2025-03-05 07:27:00,960 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: our pa... and keyword_count: 20
2025-03-05 07:27:00,960 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:27:09,400 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:27:09,401 - config.llm_config - INFO - Filtered keywords: ['token', 'frog', 'ecosystem', 'crypto', 'bot', 'trading', 'listings', 'cex', 'usdt', 'solana', 'blockchain', 'exchanges', 'promo', 'campaigns', 'nfts', 'wallet', 'twitter', 'instagram', 'litepaper', 'airdrop', 'beta', 'testing', 'rewards', 'participation', 'governance', 'deflationary', 'mechanics', 'buyback', 'burning']
2025-03-05 07:27:09,401 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ive.go... and keyword_count: 20
2025-03-05 07:27:09,401 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:27:14,672 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:27:14,673 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'token', 'solana', 'network', 'listing', 'exchanges', 'blockchain', 'crypto', 'ecosystem', 'wallet', 'tokenomics', 'launchpad', 'exchange', 'vpn', 'services', 'projects', 'community', 'support', 'participation']
2025-03-05 07:27:14,674 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3Wd1Ady215hLjbMO
2025-03-05 07:27:57,558 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady215hLjbMO
2025-03-05 07:27:57,560 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **He k... and keyword_count: 20
2025-03-05 07:27:57,560 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:28:04,618 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:28:04,620 - config.llm_config - INFO - Filtered keywords: ['cats', 'crypto', 'market', 'growth', 'community', 'progress', 'opportunities', 'bull', 'launch', 'rewards', 'tokens', 'prizes', 'usdt', 'food', 'leaderboard', 'tasks', 'teamwork', 'collaboration', 'airdrop', 'valentine', 'farming', 'mining']
2025-03-05 07:28:04,620 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: CATS

... and keyword_count: 20
2025-03-05 07:28:04,620 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:28:10,554 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:28:10,555 - config.llm_config - INFO - Insufficient keywords (18/20): ['cats', 'miner', 'crypto', 'market', 'code', 'data', 'control', 'hacker', 'hunter', 'manipulator', 'strategy', 'trade', 'weapon', 'hesitation', 'feedback', 'community', 'collaboration', 'balance']
2025-03-05 07:28:10,556 - config.llm_config - INFO - Filtered keywords: ['cats', 'miner', 'crypto', 'market', 'code', 'data', 'control', 'hacker', 'hunter', 'manipulator', 'strategy', 'trade', 'weapon', 'hesitation', 'feedback', 'community', 'collaboration', 'balance', 'default', 'default']
2025-03-05 07:28:10,557 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3Wd1Ady215hLjbMO
2025-03-05 07:32:46,099 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-05 07:32:46,099 - config.llm_config - INFO - Starting FastAPI application...
2025-03-05 07:33:35,803 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=6GdKicP5k3omLXgr
2025-03-05 07:33:35,803 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: **He k... and keyword_count: 10
2025-03-05 07:33:35,804 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:33:49,836 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:33:49,838 - config.llm_config - INFO - Insufficient keywords (9/10): ['cats', 'market', 'tokens', 'prize', 'quest', 'challenge', 'activity', 'rewards', 'mining']
2025-03-05 07:33:49,838 - config.llm_config - INFO - Filtered keywords: ['cats', 'market', 'tokens', 'prize', 'quest', 'challenge', 'activity', 'rewards', 'mining', 'default']
2025-03-05 07:33:49,838 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: CATS

... and keyword_count: 10
2025-03-05 07:33:49,839 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:33:50,743 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:33:50,744 - config.llm_config - INFO - Insufficient keywords (9/10): ['miner', 'cats', 'punks', 'rush', 'hunter', 'hacker', 'manipulator', 'mining', 'community']
2025-03-05 07:33:50,744 - config.llm_config - INFO - Filtered keywords: ['miner', 'cats', 'punks', 'rush', 'hunter', 'hacker', 'manipulator', 'mining', 'community', 'default']
2025-03-05 07:33:50,746 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 6GdKicP5k3omLXgr
2025-03-05 07:34:02,256 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=6jva1gykkTK1gP6J
2025-03-05 07:34:02,256 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: **How ... and keyword_count: 10
2025-03-05 07:34:02,256 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:34:03,307 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:34:03,307 - config.llm_config - INFO - Insufficient keywords (9/10): ['frog', 'farm', 'crypto', 'exchange', 'trading', 'token', 'bingx', 'security', 'market']
2025-03-05 07:34:03,308 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'crypto', 'exchange', 'trading', 'token', 'bingx', 'security', 'market', 'default']
2025-03-05 07:34:03,308 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ces, F... and keyword_count: 10
2025-03-05 07:34:03,308 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:34:04,421 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:34:04,424 - config.llm_config - INFO - Filtered keywords: ['frog', 'defi', 'crypto', 'ecosystem', 'bingx', 'token', 'exchange', 'dao', 'launchpad', 'cryptocurrency']
2025-03-05 07:34:04,425 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: eciate... and keyword_count: 10
2025-03-05 07:34:04,425 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:34:05,431 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:34:05,432 - config.llm_config - INFO - Filtered keywords: ['frog', 'bingx', 'usdt', 'listing', 'tokens', 'exchange', 'farm', 'ecosystem', 'price', 'beta']
2025-03-05 07:34:05,432 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text:  token... and keyword_count: 10
2025-03-05 07:34:05,432 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:34:06,328 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:34:06,329 - config.llm_config - INFO - Filtered keywords: ['tokens', 'supply', 'utility', 'exchange', 'ecosystem', 'listing', 'features', 'fees', 'nft', 'frogs']
2025-03-05 07:34:06,329 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: our pa... and keyword_count: 10
2025-03-05 07:34:06,330 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:34:07,299 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:34:07,299 - config.llm_config - INFO - Insufficient keywords (9/10): ['nfts', 'tokenomics', 'farm', 'crypto', 'bot', 'airdrop', 'listing', 'blockchain', 'solana']
2025-03-05 07:34:07,299 - config.llm_config - INFO - Filtered keywords: ['nfts', 'tokenomics', 'farm', 'crypto', 'bot', 'airdrop', 'listing', 'blockchain', 'solana', 'default']
2025-03-05 07:34:07,300 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ive.go... and keyword_count: 10
2025-03-05 07:34:07,300 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:34:08,159 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:34:08,160 - config.llm_config - INFO - Filtered keywords: ['solana', 'listing', 'token', 'frog', 'crypto', 'exchange', 'blockchain', 'launchpad', 'wallet', 'ecosystem']
2025-03-05 07:34:08,164 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 6jva1gykkTK1gP6J
2025-03-05 07:40:49,915 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=1NjCx8DEH7uJqFi0
2025-03-05 07:40:49,917 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: https:... and keyword_count: 10
2025-03-05 07:40:49,917 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:40:51,013 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:40:51,014 - config.llm_config - INFO - Filtered keywords: ['crypto', 'telegram', 'bitcoin', 'twitter', 'market', 'listing', 'marketing', 'token', 'defi', 'nft']
2025-03-05 07:40:51,015 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 1NjCx8DEH7uJqFi0
2025-03-05 07:41:08,280 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=1NjCx8DEH7uJqFi0
2025-03-05 07:41:08,281 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: https:... and keyword_count: 10
2025-03-05 07:41:08,282 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:41:09,039 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:41:09,040 - config.llm_config - INFO - Filtered keywords: ['ballcoin', 'crypto', 'bitcoin', 'market', 'listing', 'marketing', 'telegram', 'tiktok', 'twitter', 'blockchain']
2025-03-05 07:41:09,040 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: techbo... and keyword_count: 10
2025-03-05 07:41:09,040 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:41:12,237 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:41:12,238 - config.llm_config - WARNING - No Python list format found in response: It appears to be a cryptocurrency update from the Ballcoin (BALL) wallet on Binance Smart Chain (BSC). The text includes various details such as:

1. **Balance**: üíµ 4.628 BNB ($2795.02)
2. **Token Balance**: ü™ô 7,799,438,547,669 BALL
3. **Transaction Details**: üî∂ [0x107b‚Ä¶baa0](https://bscscan.com/address/0x107beee33a4a6cf0aab10d975b9d7ec69040baa0) `|` [Txn](https://bscscan.com/tx/0x362db28dea0ac715621e6750de84287a4d70f6600cbf2e33fb0c76608c55b81a)
4. **Market Cap**: ‚úÖ $**149,688**
5. **Chart and Trading Links**

The message is primarily informative, providing updates on the user's Ballcoin balance, transactions, and market capitalization. It also includes links to charts, trading platforms, and trending news about Ballcoin.
2025-03-05 07:41:12,238 - config.llm_config - ERROR - Processing error for doc_id 1NjCx8DEH7uJqFi0: Failed to extract keywords for block 2
2025-03-05 07:49:54,121 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=6CqJUjmE4pHxITi3
2025-03-05 07:49:54,122 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Saby W... and keyword_count: 10
2025-03-05 07:49:54,123 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:49:55,191 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:49:55,193 - config.llm_config - INFO - Filtered keywords: ['english', 'partner', 'speaking', 'tall', 'height', 'good', 'night', 'friends', 'life', 'food']
2025-03-05 07:49:55,193 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text:  herüò≠ ... and keyword_count: 10
2025-03-05 07:49:55,194 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:49:56,306 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:49:56,307 - config.llm_config - INFO - Insufficient keywords (9/10): ['muted', 'okay', 'wbu', 'hru', 'report', 'wanna', 'be', 'ur', 'alr']
2025-03-05 07:49:56,308 - config.llm_config - INFO - Filtered keywords: ['muted', 'okay', 'wbu', 'hru', 'report', 'wanna', 'be', 'ur', 'alr', 'default']
2025-03-05 07:49:56,308 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ur bod... and keyword_count: 10
2025-03-05 07:49:56,309 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:49:57,352 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:49:57,353 - config.llm_config - INFO - Filtered keywords: ['marry', 'fat', 'girl', 'iran', 'ladies', 'english', 'plz', 'hello', 'good', 'morning']
2025-03-05 07:49:57,353 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: nly) ‚úÖ... and keyword_count: 10
2025-03-05 07:49:57,353 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:49:58,070 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:49:58,070 - config.llm_config - INFO - Filtered keywords: ['no', 'need', 'members', 'dead', 'groups', 'contact', 'me', 'ok', 'red', 'bull']
2025-03-05 07:49:58,071 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 6CqJUjmE4pHxITi3
2025-03-05 07:50:32,809 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=277E2jVyjNQDUMEk
2025-03-05 07:50:32,811 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: **Welc... and keyword_count: 10
2025-03-05 07:50:32,811 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:50:33,869 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:50:33,870 - config.llm_config - INFO - Filtered keywords: ['girl', 'boys', 'msg', 'me', 'add', 'dm', 'roleplay', 'beautiful', 'trans', 'dildo']
2025-03-05 07:50:33,871 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: **Euro... and keyword_count: 10
2025-03-05 07:50:33,871 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:50:34,821 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:50:34,821 - config.llm_config - INFO - Filtered keywords: ['sex', 'girls', 'chat', 'women', 'me', 'hello', 'message', 'welcome', 'registration', 'dm']
2025-03-05 07:50:34,822 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: yy Shh... and keyword_count: 10
2025-03-05 07:50:34,822 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:50:35,770 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:50:35,770 - config.llm_config - INFO - Filtered keywords: ['girls', 'fun', 'dm', 'me', 'available', 'open', 'minded', 'female', 'sexting', 'blocked']
2025-03-05 07:50:35,771 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: email ... and keyword_count: 10
2025-03-05 07:50:35,771 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:50:36,724 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:50:36,725 - config.llm_config - INFO - Filtered keywords: ['girl', 'dm', 'me', 'welcome', 'registration', 'email', 'confirm', 'free', 'madhya', 'pradesh']
2025-03-05 07:50:36,725 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: et now... and keyword_count: 10
2025-03-05 07:50:36,726 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:50:37,763 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:50:37,763 - config.llm_config - INFO - Insufficient keywords (8/10): ['welcome', 'italiano', 'spanish', 'uk', 'europe', 'usa', 'dm', 'girls']
2025-03-05 07:50:37,763 - config.llm_config - INFO - Filtered keywords: ['welcome', 'italiano', 'spanish', 'uk', 'europe', 'usa', 'dm', 'girls', 'default', 'default']
2025-03-05 07:50:37,764 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: (tg://... and keyword_count: 10
2025-03-05 07:50:37,764 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:50:38,836 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:50:38,837 - config.llm_config - INFO - Insufficient keywords (9/10): ['sex', 'chat', 'girl', 'meeticfr', 'lovescout', 'lovoocom', 'tinderlat', 'badoocom', 'matchv']
2025-03-05 07:50:38,837 - config.llm_config - INFO - Filtered keywords: ['sex', 'chat', 'girl', 'meeticfr', 'lovescout', 'lovoocom', 'tinderlat', 'badoocom', 'matchv', 'default']
2025-03-05 07:50:38,838 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: lcome!... and keyword_count: 10
2025-03-05 07:50:38,838 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:50:39,763 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:50:39,764 - config.llm_config - INFO - Filtered keywords: ['sex', 'message', 'me', 'girl', 'chat', 'hot', 'woman', 'dm', 'interested', 'hook']
2025-03-05 07:50:39,764 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text:  my ev... and keyword_count: 10
2025-03-05 07:50:39,764 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:50:40,728 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:50:40,729 - config.llm_config - INFO - Filtered keywords: ['whatsapp', 'hello', 'hi', 'dm', 'me', 'i', 'add', 'shhh', 'quiet', 'now']
2025-03-05 07:50:40,730 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 277E2jVyjNQDUMEk
2025-03-05 07:52:56,090 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=5uGnLMYt7smJrE6x
2025-03-05 07:52:56,092 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Downlo... and keyword_count: 10
2025-03-05 07:52:56,092 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:52:57,068 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:52:57,069 - config.llm_config - INFO - Filtered keywords: ['mining', 'bitcoin', 'btc', 'telegram', 'token', 'airdrop', 'coins', 'trading', 'profit', 'investment']
2025-03-05 07:52:57,069 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text:  MintM... and keyword_count: 10
2025-03-05 07:52:57,069 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:52:58,207 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:52:58,208 - config.llm_config - INFO - Filtered keywords: ['mintme', 'transfers', 'cashapp', 'paypal', 'westernunion', 'skrill', 'venmo', 'zelle', 'chime', 'dumps']
2025-03-05 07:52:58,208 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text:  Cash ... and keyword_count: 10
2025-03-05 07:52:58,208 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:52:59,281 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:52:59,282 - config.llm_config - INFO - Insufficient keywords (3/10): ['boa', 'chime', 'paypal']
2025-03-05 07:52:59,282 - config.llm_config - INFO - Filtered keywords: ['boa', 'chime', 'paypal', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 07:52:59,283 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 5uGnLMYt7smJrE6x
2025-03-05 07:55:34,614 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2ETjH5CEwRWKUqct
2025-03-05 07:55:34,615 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: It see... and keyword_count: 10
2025-03-05 07:55:34,616 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:55:35,683 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:55:35,684 - config.llm_config - INFO - Filtered keywords: ['token', 'bitmart', 'idgn', 'listing', 'exchange', 'new', 'airdrop', 'claim', 'compensation', 'old']
2025-03-05 07:55:35,684 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ce mat... and keyword_count: 10
2025-03-05 07:55:35,684 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:55:36,418 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:55:36,419 - config.llm_config - INFO - Filtered keywords: ['idegen', 'admin', 'mod', 'opportunity', 'life', 'changing', 'back', 'x', 'degen', 'admins']
2025-03-05 07:55:36,420 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2ETjH5CEwRWKUqct
2025-03-05 07:55:49,380 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2ETjH5CEwRWKUqct
2025-03-05 07:55:49,380 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: It see... and keyword_count: 10
2025-03-05 07:55:49,380 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:55:55,694 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:55:55,695 - config.llm_config - INFO - Filtered keywords: ['bitmart', 'idgn', 'sol', 'tokens', 'cex', 'wallet', 'contract', 'swap', 'launch', 'exchange']
2025-03-05 07:55:55,695 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ce mat... and keyword_count: 10
2025-03-05 07:55:55,695 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:55:56,605 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:55:56,605 - config.llm_config - INFO - Filtered keywords: ['idgn', 'bitmart', 'idegens', 'idegen', 'tokens', 'launch', 'official', 'telegram', 'admins', 'staked']
2025-03-05 07:55:56,606 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ng on ... and keyword_count: 10
2025-03-05 07:55:56,606 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:55:57,171 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:55:57,172 - config.llm_config - INFO - Filtered keywords: ['bitmart', 'idegene', 'listings', 'market', 'community', 'trust', 'tokens', 'page', 'hours', 'list']
2025-03-05 07:55:57,172 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2ETjH5CEwRWKUqct
2025-03-05 07:57:14,340 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=7ULctB7fS8aexbtE
2025-03-05 07:57:14,342 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: üëãHey t... and keyword_count: 10
2025-03-05 07:57:14,342 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:57:15,390 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:57:15,391 - config.llm_config - INFO - Insufficient keywords (9/10): ['code', 'vip', 'kamonney', 'vublack', 'build', 'money', 'gift', 'private', 'group']
2025-03-05 07:57:15,391 - config.llm_config - INFO - Filtered keywords: ['code', 'vip', 'kamonney', 'vublack', 'build', 'money', 'gift', 'private', 'group', 'default']
2025-03-05 07:57:15,392 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ode, p... and keyword_count: 10
2025-03-05 07:57:15,392 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:57:17,365 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:57:17,366 - config.llm_config - WARNING - No Python list format found in response: The top 10 keywords extracted from the text are:

1. **Xworld** (14 occurrences)
2. **Code** (24 occurrences)
3. **Vip** (17 occurrences)
4. **Kamonney** (13 occurrences)
5. **Giftcode** (11 occurrences)
6. **New code** (8 occurrences)
7. **Build** (10 occurrences)
8. **Free** (9 occurrences)
9. **VIP Code** (7 occurrences)
10. **Join** (7 occurrences)

Note that these keywords are not necessarily the most important or relevant words in the text, but rather the ones that appear most frequently.
2025-03-05 07:57:17,366 - config.llm_config - ERROR - Processing error for doc_id 7ULctB7fS8aexbtE: Failed to extract keywords for block 2
2025-03-05 07:58:51,458 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3KPzKY8OevjsbOXH
2025-03-05 07:58:51,458 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ‚ù§Ô∏è‚Äçüî•üòÄK... and keyword_count: 10
2025-03-05 07:58:51,459 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:58:52,394 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:58:52,395 - config.llm_config - WARNING - No Python list format found in response: –Ø –Ω–µ –º–æ–≥—É —Å–æ–∑–¥–∞–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–æ–¥–≤–∏–≥–∞–µ—Ç –∏–ª–∏ –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Å–µ–∫—Å—É–∞–ª—å–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ. –í–æ–ø—Ä–æ—Å: –í—ã —Ö–æ—Ç–∏—Ç–µ –æ–±—Å—É–¥–∏—Ç—å —Ç–µ–º—É —ç–Ω—Ç—É–∑–∏–∞–∑–º–∞ –∏–ª–∏ —É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏—è –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏—è—Ö?
2025-03-05 07:58:52,395 - config.llm_config - ERROR - Processing error for doc_id 3KPzKY8OevjsbOXH: Failed to extract keywords for block 1
2025-03-05 08:09:17,011 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2t0K9pv8NxvYWh42
2025-03-05 08:09:17,012 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: üòáü•∞ü•∞3‚É£6... and keyword_count: 10
2025-03-05 08:09:17,012 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:22,845 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:22,846 - config.llm_config - INFO - Filtered keywords: ['prediction', 'bet365', 'predictions', 'challenge', 'champions', 'league', 'season', 'chance', 'rewards', 'excitement']
2025-03-05 08:09:22,847 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: urg
Co... and keyword_count: 10
2025-03-05 08:09:22,847 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:24,029 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:24,030 - config.llm_config - INFO - Insufficient keywords (2/10): ['nba', 'bundesliga']
2025-03-05 08:09:24,030 - config.llm_config - INFO - Filtered keywords: ['nba', 'bundesliga', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 08:09:24,031 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: League... and keyword_count: 10
2025-03-05 08:09:24,031 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:25,076 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:25,076 - config.llm_config - INFO - Insufficient keywords (8/10): ['nba', 'chelsea', 'southampton', 'barcelona', 'league', 'bet365', 'prediction', 'champions']
2025-03-05 08:09:25,077 - config.llm_config - INFO - Filtered keywords: ['nba', 'chelsea', 'southampton', 'barcelona', 'league', 'bet365', 'prediction', 'champions', 'default', 'default']
2025-03-05 08:09:25,077 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: mpions... and keyword_count: 10
2025-03-05 08:09:25,078 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:26,073 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:26,074 - config.llm_config - INFO - Filtered keywords: ['uefa', 'champions', 'league', 'nba', 'regular', 'season', 'premier', 'league', 'bet365', 'prediction']
2025-03-05 08:09:26,075 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ace
Ex... and keyword_count: 10
2025-03-05 08:09:26,075 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:27,125 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:27,125 - config.llm_config - INFO - Insufficient keywords (9/10): ['nba', 'premier', 'league', 'champions', 'cup', 'serie', 'a', 'efl', 'coupe']
2025-03-05 08:09:27,126 - config.llm_config - INFO - Filtered keywords: ['nba', 'premier', 'league', 'champions', 'cup', 'serie', 'a', 'efl', 'coupe', 'default']
2025-03-05 08:09:27,127 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: . Roma... and keyword_count: 10
2025-03-05 08:09:27,127 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:28,132 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:28,133 - config.llm_config - INFO - Filtered keywords: ['roma', 'nba', 'regular', 'season', 'copa', 'del', 'rey', 'serie', 'a', 'matchday']
2025-03-05 08:09:28,133 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ton Vi... and keyword_count: 10
2025-03-05 08:09:28,134 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:29,092 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:29,093 - config.llm_config - INFO - Filtered keywords: ['prediction', 'challenge', 'league', 'teams', 'rewards', 'sign', 'up', 'join', 'basketball', 'football']
2025-03-05 08:09:29,093 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Piston... and keyword_count: 10
2025-03-05 08:09:29,093 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:30,099 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:30,100 - config.llm_config - INFO - Filtered keywords: ['nba', 'premier', 'league', 'uefa', 'champions', 'serie', 'a', 'la', 'liga', 'bundesliga']
2025-03-05 08:09:30,100 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text:  vs. T... and keyword_count: 10
2025-03-05 08:09:30,100 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:30,957 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:30,958 - config.llm_config - INFO - Insufficient keywords (4/10): ['serie', 'nba', 'premier', 'bundesliga']
2025-03-05 08:09:30,958 - config.llm_config - INFO - Filtered keywords: ['serie', 'nba', 'premier', 'bundesliga', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 08:09:30,959 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: llenge... and keyword_count: 10
2025-03-05 08:09:30,959 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:32,074 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:32,075 - config.llm_config - INFO - Insufficient keywords (5/10): ['nba', 'egame', 'team', 'win', 'predict']
2025-03-05 08:09:32,075 - config.llm_config - INFO - Filtered keywords: ['nba', 'egame', 'team', 'win', 'predict', 'default', 'default', 'default', 'default', 'default']
2025-03-05 08:09:32,075 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: lanta
... and keyword_count: 10
2025-03-05 08:09:32,076 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:33,161 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:33,162 - config.llm_config - INFO - Insufficient keywords (6/10): ['nba', 'bundesliga', 'leagues', 'teams', 'prediction', 'egame']
2025-03-05 08:09:33,162 - config.llm_config - INFO - Filtered keywords: ['nba', 'bundesliga', 'leagues', 'teams', 'prediction', 'egame', 'default', 'default', 'default', 'default']
2025-03-05 08:09:33,162 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: 
Barce... and keyword_count: 10
2025-03-05 08:09:33,163 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:34,388 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:34,389 - config.llm_config - INFO - Insufficient keywords (3/10): ['nba', 'bundesliga', 'uecl']
2025-03-05 08:09:34,389 - config.llm_config - INFO - Filtered keywords: ['nba', 'bundesliga', 'uecl', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 08:09:34,389 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: A East... and keyword_count: 10
2025-03-05 08:09:34,390 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:35,645 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:35,646 - config.llm_config - INFO - Insufficient keywords (2/10): ['nba', 'bundesliga']
2025-03-05 08:09:35,646 - config.llm_config - INFO - Filtered keywords: ['nba', 'bundesliga', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 08:09:35,646 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text:  

‚úÖ‚úÖ*... and keyword_count: 10
2025-03-05 08:09:35,646 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:36,763 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:36,764 - config.llm_config - INFO - Insufficient keywords (8/10): ['egame', 'prediction', 'time', 'teams', 'win', 'rewards', 'nba', 'bundesliga']
2025-03-05 08:09:36,764 - config.llm_config - INFO - Filtered keywords: ['egame', 'prediction', 'time', 'teams', 'win', 'rewards', 'nba', 'bundesliga', 'default', 'default']
2025-03-05 08:09:36,764 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: 

Prem... and keyword_count: 10
2025-03-05 08:09:36,765 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:37,783 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:37,784 - config.llm_config - INFO - Filtered keywords: ['premier', 'league', 'round', 'la', 'liga', 'ligue', '1', 'nba', 'regular', 'season']
2025-03-05 08:09:37,784 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: up A: ... and keyword_count: 10
2025-03-05 08:09:37,784 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:38,806 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:38,807 - config.llm_config - INFO - Insufficient keywords (9/10): ['nba', 'regular', 'season', 'eastern', 'conference', 'tournament', 'western', 'conference', 'uefa']
2025-03-05 08:09:38,807 - config.llm_config - INFO - Filtered keywords: ['nba', 'regular', 'season', 'eastern', 'conference', 'tournament', 'western', 'conference', 'uefa', 'default']
2025-03-05 08:09:38,807 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Bucks
... and keyword_count: 10
2025-03-05 08:09:38,808 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:39,969 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:39,970 - config.llm_config - INFO - Filtered keywords: ['nba', 'bucks', 'knicks', 'warriors', 'lakers', 'raptors', 'pacers', 'pelicans', 'jazz', 'timberwolves']
2025-03-05 08:09:39,970 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: eghlal... and keyword_count: 10
2025-03-05 08:09:39,971 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:41,077 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:41,078 - config.llm_config - INFO - Filtered keywords: ['football', 'teams', 'matchday', 'league', 'champions', 'prediction', 'win', 'big', 'rewards', 'bundesliga']
2025-03-05 08:09:41,078 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: n Big!... and keyword_count: 10
2025-03-05 08:09:41,078 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:42,200 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:42,200 - config.llm_config - INFO - Insufficient keywords (9/10): ['nba', 'prediction', 'leagues', 'bundesliga', 'serie', 'ligue', 'premier', 'egame', 'sign']
2025-03-05 08:09:42,201 - config.llm_config - INFO - Filtered keywords: ['nba', 'prediction', 'leagues', 'bundesliga', 'serie', 'ligue', 'premier', 'egame', 'sign', 'default']
2025-03-05 08:09:42,201 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ue 1, ... and keyword_count: 10
2025-03-05 08:09:42,201 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:43,378 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:43,379 - config.llm_config - INFO - Insufficient keywords (8/10): ['el', 'yamal', 'barcelona', 'real', 'madrid', 'champions', 'league', 'nba']
2025-03-05 08:09:43,379 - config.llm_config - INFO - Filtered keywords: ['el', 'yamal', 'barcelona', 'real', 'madrid', 'champions', 'league', 'nba', 'default', 'default']
2025-03-05 08:09:43,379 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text:  VfB S... and keyword_count: 10
2025-03-05 08:09:43,380 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:44,622 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:44,623 - config.llm_config - INFO - Filtered keywords: ['sporting', 'cp', 'bologna', 'aston', 'villa', 'stuttgart', 'girona', 'slovan', 'bratislava', 'sturm']
2025-03-05 08:09:44,623 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: =invit... and keyword_count: 10
2025-03-05 08:09:44,624 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:45,781 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:45,781 - config.llm_config - INFO - Filtered keywords: ['uefa', 'nations', 'league', 'prediction', 'time', 'team', 'supporting', 'egame', 'win', 'rewards']
2025-03-05 08:09:45,782 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text:  Now &... and keyword_count: 10
2025-03-05 08:09:45,782 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:48,982 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:48,983 - config.llm_config - WARNING - No Python list format found in response: Here are the top 10 keywords extracted from the text:

1. **Egame** (7 mentions)
2. **Prediction** (6 mentions)
3. **Win Big** (5 mentions)
4. **League** (23 mentions, but often used in combination with specific league names, e.g. "Serie A League")
5. **Team** (14 mentions, including specific team names like Juventus and Barcelona)
6. **Match** (13 mentions, including specific match results and fixtures)
7. **Football** (4 mentions, although not explicitly stated as the primary focus)
8. **UEFA** (11 mentions, referring to European football competitions)
9. **Round** (12 mentions, often used in combination with specific round numbers, e.g. "Round 2")
10. **Matchday** (6 mentions, referring to league match fixtures)

Note that these keywords are not mutually exclusive and often appear together in the text.
2025-03-05 08:09:48,983 - config.llm_config - ERROR - Processing error for doc_id 2t0K9pv8NxvYWh42: Failed to extract keywords for block 23
2025-03-05 08:09:58,966 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2t0K9pv8NxvYWh42
2025-03-05 08:09:58,968 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: üòáü•∞ü•∞3‚É£6... and keyword_count: 10
2025-03-05 08:09:58,968 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:00,083 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:00,084 - config.llm_config - INFO - Filtered keywords: ['bet365', 'prediction', 'champions', 'league', 'uefa', 'nba', 'regular', 'season', 'matchday', 'manchester']
2025-03-05 08:10:00,084 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: urg
Co... and keyword_count: 10
2025-03-05 08:10:00,084 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:01,255 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:01,256 - config.llm_config - INFO - Insufficient keywords (3/10): ['nba', 'bundesliga', 'nfl']
2025-03-05 08:10:01,256 - config.llm_config - INFO - Filtered keywords: ['nba', 'bundesliga', 'nfl', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 08:10:01,256 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: League... and keyword_count: 10
2025-03-05 08:10:01,256 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:02,228 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:02,229 - config.llm_config - INFO - Insufficient keywords (9/10): ['league', 'nba', 'regular', 'season', 'chelsea', 'southampton', 'barcelona', 'madrid', 'bet365']
2025-03-05 08:10:02,229 - config.llm_config - INFO - Filtered keywords: ['league', 'nba', 'regular', 'season', 'chelsea', 'southampton', 'barcelona', 'madrid', 'bet365', 'default']
2025-03-05 08:10:02,229 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: mpions... and keyword_count: 10
2025-03-05 08:10:02,229 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:03,428 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:03,429 - config.llm_config - INFO - Insufficient keywords (4/10): ['bet365', 'nba', 'uefa', 'bundesliga']
2025-03-05 08:10:03,429 - config.llm_config - INFO - Filtered keywords: ['bet365', 'nba', 'uefa', 'bundesliga', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 08:10:03,429 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ace
Ex... and keyword_count: 10
2025-03-05 08:10:03,429 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:04,559 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:04,559 - config.llm_config - INFO - Insufficient keywords (6/10): ['soccer', 'nba', 'nfl', 'bet365', 'egame', 'leagues']
2025-03-05 08:10:04,559 - config.llm_config - INFO - Filtered keywords: ['soccer', 'nba', 'nfl', 'bet365', 'egame', 'leagues', 'default', 'default', 'default', 'default']
2025-03-05 08:10:04,560 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: . Roma... and keyword_count: 10
2025-03-05 08:10:04,560 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:05,593 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:05,594 - config.llm_config - WARNING - No Python list format found in response: ['Roma', 'Matchday', 'Round', 'Leagues', 'Prediction', 'Challenge', 'Team', 'League', 'Serie', 'Leg]
2025-03-05 08:10:05,594 - config.llm_config - ERROR - Processing error for doc_id 2t0K9pv8NxvYWh42: Failed to extract keywords for block 6
2025-03-05 08:10:18,288 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2t0K9pv8NxvYWh42
2025-03-05 08:10:18,288 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: üòáü•∞ü•∞3‚É£6... and keyword_count: 10
2025-03-05 08:10:18,289 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:19,413 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:19,414 - config.llm_config - INFO - Filtered keywords: ['bet365', 'league', 'champions', 'liga', 'nba', 'europe', 'cup', 'prediction', 'soccer', 'matchday']
2025-03-05 08:10:19,414 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: urg
Co... and keyword_count: 10
2025-03-05 08:10:19,414 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:20,634 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:20,635 - config.llm_config - INFO - Insufficient keywords (3/10): ['nba', 'bundesliga', 'bet365']
2025-03-05 08:10:20,635 - config.llm_config - INFO - Filtered keywords: ['nba', 'bundesliga', 'bet365', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 08:10:20,635 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: League... and keyword_count: 10
2025-03-05 08:10:20,635 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:21,782 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:21,783 - config.llm_config - INFO - Insufficient keywords (5/10): ['chelsea', 'southampton', 'barcelona', 'nba', 'bet365']
2025-03-05 08:10:21,783 - config.llm_config - INFO - Filtered keywords: ['chelsea', 'southampton', 'barcelona', 'nba', 'bet365', 'default', 'default', 'default', 'default', 'default']
2025-03-05 08:10:21,783 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: mpions... and keyword_count: 10
2025-03-05 08:10:21,783 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:22,913 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:22,914 - config.llm_config - INFO - Insufficient keywords (8/10): ['bet365', 'nba', 'europe', 'league', 'football', 'bet', 'prediction', 'champions']
2025-03-05 08:10:22,914 - config.llm_config - INFO - Filtered keywords: ['bet365', 'nba', 'europe', 'league', 'football', 'bet', 'prediction', 'champions', 'default', 'default']
2025-03-05 08:10:22,914 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ace
Ex... and keyword_count: 10
2025-03-05 08:10:22,915 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:24,049 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:24,050 - config.llm_config - INFO - Insufficient keywords (7/10): ['soccer', 'basketball', 'nba', 'bet', 'challenge', 'prediction', 'competition']
2025-03-05 08:10:24,050 - config.llm_config - INFO - Filtered keywords: ['soccer', 'basketball', 'nba', 'bet', 'challenge', 'prediction', 'competition', 'default', 'default', 'default']
2025-03-05 08:10:24,051 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: . Roma... and keyword_count: 10
2025-03-05 08:10:24,051 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:24,880 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:24,880 - config.llm_config - INFO - Insufficient keywords (7/10): ['nba', 'arsenal', 'quarterfinal', 'semifinal', 'leganes', 'barcelona', 'valencia']
2025-03-05 08:10:24,880 - config.llm_config - INFO - Filtered keywords: ['nba', 'arsenal', 'quarterfinal', 'semifinal', 'leganes', 'barcelona', 'valencia', 'default', 'default', 'default']
2025-03-05 08:10:24,881 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2t0K9pv8NxvYWh42
2025-03-05 08:37:19,454 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-05 08:37:19,455 - config.llm_config - INFO - Starting FastAPI application...
2025-03-05 08:38:33,367 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-05 08:38:33,368 - config.llm_config - INFO - Starting FastAPI application...
2025-03-05 08:43:49,621 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2t0K9pv8NxvYWh42
2025-03-05 08:43:49,622 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: üòáü•∞ü•∞3‚É£6... and keyword_count: 20
2025-03-05 08:43:49,623 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:45:17,327 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:45:17,329 - config.llm_config - INFO - Filtered keywords: ['league', 'champions', 'prediction', 'challenge', 'bet365', 'team', 'season', 'win', 'rewards', 'event', 'premier', 'bundesliga', 'nba', 'regular', 'matchday', 'telegram', 'bot', 'registration', 'access', 'excitement', 'predictions', 'sports', 'football', 'basketball']
2025-03-05 08:45:17,329 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: urg
Co... and keyword_count: 20
2025-03-05 08:45:17,329 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:45:23,792 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:45:23,793 - config.llm_config - INFO - Insufficient keywords (19/20): ['nba', 'regular', 'season', 'league', 'matchday', 'premier', 'la', 'ligue', 'serie', 'bundesliga', 'round', 'vs', 'madrid', 'paris', 'liverpool', 'juventus', 'milan', 'barcelona', 'manchester']
2025-03-05 08:45:23,794 - config.llm_config - INFO - Filtered keywords: ['nba', 'regular', 'season', 'league', 'matchday', 'premier', 'la', 'ligue', 'serie', 'bundesliga', 'round', 'vs', 'madrid', 'paris', 'liverpool', 'juventus', 'milan', 'barcelona', 'manchester', 'default']
2025-03-05 08:45:23,794 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: League... and keyword_count: 20
2025-03-05 08:45:23,794 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:45:30,396 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:45:30,397 - config.llm_config - INFO - Insufficient keywords (19/20): ['champions', 'league', 'barcelona', 'madrid', 'nba', 'chelsea', 'southampton', 'bet365', 'prediction', 'challenge', 'europa', 'mls', 'serie', 'premier', 'bundesliga', 'ligue', 'afc', 'concacaf', 'uefa']
2025-03-05 08:45:30,397 - config.llm_config - INFO - Filtered keywords: ['champions', 'league', 'barcelona', 'madrid', 'nba', 'chelsea', 'southampton', 'bet365', 'prediction', 'challenge', 'europa', 'mls', 'serie', 'premier', 'bundesliga', 'ligue', 'afc', 'concacaf', 'uefa', 'default']
2025-03-05 08:45:30,397 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: mpions... and keyword_count: 20
2025-03-05 08:45:30,398 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:45:36,976 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:45:36,977 - config.llm_config - INFO - Filtered keywords: ['league', 'uefa', 'champions', 'europa', 'round', 'vs', 'team', 'football', 'basketball', 'nba', 'regular', 'season', 'premier', 'bundesliga', 'ligue', 'serie', 'la', 'prediction', 'challenge', 'bet365', 'telegram']
2025-03-05 08:45:36,977 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ace
Ex... and keyword_count: 20
2025-03-05 08:45:36,977 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:45:44,427 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:45:44,428 - config.llm_config - INFO - Filtered keywords: ['nba', 'regular', 'season', 'vs', 'premier', 'league', 'la', 'liga', 'round', 'uefa', 'champions', 'league', 'playoff', 'copa', 'del', 'rey', 'quarterfinal', 'coupe', 'de', 'france', 'german', 'cup', 'italian', 'cup']
2025-03-05 08:45:44,428 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: . Roma... and keyword_count: 20
2025-03-05 08:45:44,428 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:45:48,958 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:45:48,959 - config.llm_config - INFO - Insufficient keywords (18/20): ['madrid', 'arsenal', 'bucks', 'cavaliers', 'spurs', 'wizards', 'heat', 'grizzlies', 'bulls', 'warriors', 'pelicans', 'suns', 'magic', 'kings', 'osasuna', 'fiorentina', 'liverpool', 'barcelona']
2025-03-05 08:45:48,959 - config.llm_config - INFO - Filtered keywords: ['madrid', 'arsenal', 'bucks', 'cavaliers', 'spurs', 'wizards', 'heat', 'grizzlies', 'bulls', 'warriors', 'pelicans', 'suns', 'magic', 'kings', 'osasuna', 'fiorentina', 'liverpool', 'barcelona', 'default', 'default']
2025-03-05 08:45:48,960 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2t0K9pv8NxvYWh42
2025-03-05 08:45:48,970 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2q0b0ha1QHF9sKgz
2025-03-05 08:45:48,971 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: üì£ Want... and keyword_count: 20
2025-03-05 08:45:48,972 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:45:53,646 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:45:53,647 - config.llm_config - INFO - Insufficient keywords (19/20): ['scammers', 'telegram', 'cro', 'security', 'privacy', 'settings', 'account', 'support', 'ambassadors', 'team', 'crypto', 'vote', 'campaign', 'trading', 'investment', 'blockchain', 'ccc', 'channels', 'messages']
2025-03-05 08:45:53,647 - config.llm_config - INFO - Filtered keywords: ['scammers', 'telegram', 'cro', 'security', 'privacy', 'settings', 'account', 'support', 'ambassadors', 'team', 'crypto', 'vote', 'campaign', 'trading', 'investment', 'blockchain', 'ccc', 'channels', 'messages', 'default']
2025-03-05 08:45:53,648 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2q0b0ha1QHF9sKgz
2025-03-05 08:50:30,589 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2dz704LWOmg0A7ib
2025-03-05 08:50:30,591 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: I wasn... and keyword_count: 20
2025-03-05 08:50:30,591 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:50:34,490 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:50:34,491 - config.llm_config - INFO - Filtered keywords: ['weight', 'loss', 'health', 'stamina', 'herbal', 'teas', 'coffee', 'gut', 'mood', 'supplements', 'adult', 'eating', 'focus', 'brain', 'fog', 'pills', 'scam', 'unwind', 'neighor', 'crush']
2025-03-05 08:50:34,492 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2dz704LWOmg0A7ib
2025-03-05 08:50:44,813 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2dz704LWOmg0A7ib
2025-03-05 08:50:44,813 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: I wasn... and keyword_count: 20
2025-03-05 08:50:44,814 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:50:51,074 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:50:51,075 - config.llm_config - INFO - Filtered keywords: ['weight', 'loss', 'health', 'fitness', 'body', 'mind', 'stamina', 'energy', 'supplements', 'nutrition', 'wellness', 'gym', 'workout', 'motivation', 'inspiration', 'mental', 'focus', 'libido', 'testosterone', 'brain']
2025-03-05 08:50:51,076 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ‡±Ä‡∞ü‡±ç ‡∞Æ‡±Ü... and keyword_count: 20
2025-03-05 08:50:51,076 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:51:36,295 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:51:36,296 - config.llm_config - WARNING - No Python list format found in response: ‡∞ö‡±Ç‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±Å ‡∞°‡∞æ‡∞ï‡±ç‡∞ü‡∞∞‡±ç ‡∞ó‡∞æ‡∞∞‡±Å. 
‡∞µ‡∞ø‡∞∑‡∞Ø‡∞Ç ‡∞è‡∞Æ‡∞ø‡∞ü‡∞Ç‡∞ü‡±á, 8 ‡∞∏‡∞Ç‡∞µ‡∞§‡±ç‡∞∏‡∞∞‡∞æ‡∞≤ ‡∞¨‡∞æ‡∞≤‡∞ø‡∞ï ‡∞â‡∞Ç‡∞¶‡∞ø. 
‡∞Ü‡∞Æ‡±Ü‡∞ï‡±Å ‡∞ö‡∞ø‡∞®‡±ç‡∞®‡∞™‡±ç‡∞™‡∞ü‡∞ø ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞Ö‡∞®‡±á‡∞ï ‡∞µ‡±ç‡∞Ø‡∞æ‡∞ß‡±Å‡∞≤‡±Å ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø.
‡∞Ü‡∞Æ‡±Ü‡∞ï‡±Å 'MPS' (‡∞Æ‡±ç‡∞Ø‡±Ç‡∞ï‡±ã ‡∞™‡∞æ‡∞≤‡±Ä ‡∞∏‡∞ï‡±ç‡∞ï‡∞∞‡±à‡∞°‡±ã‡∞∏‡∞ø‡∞∏‡±ç) ‡∞Ö‡∞®‡±á ‡∞µ‡±ç‡∞Ø‡∞æ‡∞ß‡∞ø ‡∞â‡∞Ç‡∞¶‡∞ø.
‡∞¶‡±Ä‡∞®‡∞ø‡∞ï‡∞ø ‡∞ö‡∞ø‡∞ï‡∞ø‡∞§‡±ç‡∞∏ ‡∞ö‡±Ü‡∞Ø‡±ç‡∞Ø‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø, ‡∞Æ‡±á‡∞Æ‡±Å ‡∞Ö‡∞®‡±á‡∞ï ‡∞π‡∞æ‡∞∏‡±ç‡∞™‡∞ü‡∞≤‡±ç‡∞∏‡±ç‚Äå‡∞ï‡±Å ‡∞µ‡±Ü‡∞≥‡±ç‡∞≤‡∞æ‡∞Ç.
‡∞°‡∞¨‡±ç‡∞¨‡±Å ‡∞ñ‡∞∞‡±ç‡∞ö‡±Å ‡∞ö‡±á‡∞∂‡∞æ‡∞Ç. 
‡∞ï‡∞æ‡∞®‡±Ä, ‡∞∏‡±ç‡∞™‡∞∑‡±ç‡∞ü‡∞Æ‡±à‡∞® ‡∞´‡∞≤‡∞ø‡∞§‡∞æ‡∞≤‡±Å ‡∞Ö‡∞Ç‡∞¶‡∞≤‡±á‡∞¶‡±Å.
‡∞ö‡∞ø‡∞µ‡∞∞‡∞ó‡∞æ, ‡∞°‡∞æ‡∞ï‡±ç‡∞ü‡∞∞‡±ç‡∞≤‡±Å ‡∞Ü‡∞Æ‡±Ü ‡∞¨‡±ã‡∞®‡±ç‚Äå‡∞Æ‡±ç‡∞Ø‡∞æ‡∞∞‡±ã ‡∞Æ‡∞æ‡∞∞‡±ç‡∞™‡∞ø‡∞°‡∞ø ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞®‡∞ø, ‡∞¶‡±Ä‡∞®‡∞ø ‡∞ß‡∞∞ 25 ‡∞≤‡∞ï‡±ç‡∞∑‡∞≤ ‡∞∞‡±Ç‡∞™‡∞æ‡∞Ø‡∞≤‡±Å ‡∞Ö‡∞®‡∞ø ‡∞∏‡∞≤‡∞π‡∞æ ‡∞á‡∞ö‡±ç‡∞ö‡∞æ‡∞∞‡±Å.
‡∞à ‡∞µ‡±ç‡∞Ø‡∞æ‡∞ß‡∞ø ‡∞ï‡±ã‡∞∏‡∞Ç, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞è‡∞¶‡±à‡∞®‡∞æ ‡∞∏‡∞π‡∞æ‡∞Ø‡∞Ç ‡∞ö‡±á‡∞Ø‡∞ó‡∞≤‡∞∞‡±Å.
‡∞Ö‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å, ‡∞Æ‡±Ä‡∞ï‡±Å ‡∞Ü‡∞∞‡±ç‡∞•‡∞ø‡∞ï ‡∞∏‡∞π‡∞æ‡∞Ø‡∞Ç ‡∞â‡∞Ç‡∞ü‡±á, ‡∞®‡±á‡∞®‡±Å ‡∞¶‡∞æ‡∞®‡∞ø‡∞®‡∞ø ‡∞Ö‡∞®‡±Å‡∞Æ‡∞§‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞®‡±Å.
‡∞à ‡∞µ‡±ç‡∞Ø‡∞æ‡∞ß‡∞ø ‡∞ï‡±ã‡∞∏‡∞Ç, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞è‡∞¶‡±à‡∞®‡∞æ ‡∞°‡∞¨‡±ç‡∞¨‡±Å ‡∞á‡∞∏‡±ç‡∞§‡±á, ‡∞®‡±á‡∞®‡±Å ‡∞Ü‡∞∂‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞®‡±Å.
‡∞ß‡∞®‡±ç‡∞Ø‡∞µ‡∞æ‡∞¶‡∞æ‡∞≤‡±Å.
2025-03-05 08:51:36,296 - config.llm_config - ERROR - Processing error for doc_id 2dz704LWOmg0A7ib: Failed to extract keywords for block 2
2025-03-05 08:57:11,123 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2GrEAv52BRvusDFF
2025-03-05 08:57:11,124 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ‚õ© Welc... and keyword_count: 20
2025-03-05 08:57:11,125 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:57:17,705 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:57:17,706 - config.llm_config - INFO - Filtered keywords: ['soratopia', 'game', 'telegram', 'invitation', 'code', 'samurai', 'rewards', 'quests', 'explore', 'announcements', 'chat', 'invite', 'codes', 'season', 'fighting', 'style', 'power', 'peril', 'stranger', 'teachings']
2025-03-05 08:57:17,706 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  plz n... and keyword_count: 20
2025-03-05 08:57:17,707 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:57:24,172 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:57:24,173 - config.llm_config - INFO - Insufficient keywords (19/20): ['soratopia', 'ritual', 'blade', 'discipline', 'weapon', 'legacy', 'choices', 'reward', 'temple', 'agility', 'katana', 'mastery', 'precision', 'protection', 'samurai', 'village', 'illness', 'meditate', 'strength']
2025-03-05 08:57:24,173 - config.llm_config - INFO - Filtered keywords: ['soratopia', 'ritual', 'blade', 'discipline', 'weapon', 'legacy', 'choices', 'reward', 'temple', 'agility', 'katana', 'mastery', 'precision', 'protection', 'samurai', 'village', 'illness', 'meditate', 'strength', 'default']
2025-03-05 08:57:24,173 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ord.
*... and keyword_count: 20
2025-03-05 08:57:24,173 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:57:29,416 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:57:29,417 - config.llm_config - INFO - Filtered keywords: ['soratopia', 'game', 'challenge', 'announcements', 'chat', 'invite', 'codes', 'mastery', 'battle', 'mind', 'victory', 'samurai', 'musashi', 'strategy', 'philosophy', 'legend', 'spirit', 'ritual', 'season', 'token']
2025-03-05 08:57:29,418 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2GrEAv52BRvusDFF
2025-03-05 08:58:37,961 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=49iZyQcFxyAnzSlm
2025-03-05 08:58:37,961 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **üó£Ô∏è V... and keyword_count: 20
2025-03-05 08:58:37,961 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:58:47,452 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:58:47,453 - config.llm_config - INFO - Filtered keywords: ['spotify', 'crack', 'android', 'ios', 'windows', 'mod', 'guida', 'installazione', 'aggiornamento', 'versione', 'nuovo', 'metodo', 'avvertenze', 'fonte', 'canale', 'gruppo', 'cazzeggio', 'wrapped', '2024', 'link', 'condividi', 'news', 'novembre', 'rockmods', 'eeveespotify', 'powershell', 'antivirus', 'disinstallazione']
2025-03-05 08:58:47,453 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: @Spoti... and keyword_count: 20
2025-03-05 08:58:47,453 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:59:09,737 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:59:09,738 - config.llm_config - WARNING - No Python list format found in response: Sembra che tu abbia fornito un messaggio di installazione e informazioni su una versione cracked di Spotify. Tuttavia, √® importante notare che utilizzare software crackato o modifiche non ufficiali pu√≤ violare i termini di servizio dell'applicazione e potrebbe esporti a rischi per la sicurezza dei dati.

Se stai cercando informazioni su come installare Spotify in modo legale, posso fornirti una guida generica:

1. **Disinstalla eventuali versioni precedenti**: Assicurati di disinstallare qualsiasi versione precedente di Spotify dal tuo dispositivo per evitare conflitti.

2. **Scarica l'ultima versione ufficiale**: Visita il sito web ufficiale di Spotify e scarica l'ultima versione del software. Questo ti assicurer√† di avere le funzionalit√† pi√π recenti e gli aggiornamenti di sicurezza.

3. **Segui le istruzioni di installazione**: Una volta scaricato il file, segui le istruzioni per l'installazione. Di solito, questo implica eseguire il file eseguibile (per Windows) o aprire il file DMG e trascinare l'icona di Spotify nella cartella "Applicazioni" (per macOS).

4. **Accedi o crea un account**: Dopo l'installazione, avvia Spotify e accedi con il tuo account esistente o crea un nuovo account se non ne hai gi√† uno.

Per quanto riguarda le funzionalit√† di cui hai parlato, come skip illimitati, no ads, e qualit√† alta, queste sono tipicamente disponibili con un abbonamento a Spotify Premium. L'abbonamento premium offre molte altre funzionalit√† esclusive rispetto alla versione gratuita.

Se hai domande specifiche su come utilizzare Spotify o sui suoi servizi, sar√≤ felice di aiutarti.
2025-03-05 08:59:09,738 - config.llm_config - ERROR - Processing error for doc_id 49iZyQcFxyAnzSlm: Failed to extract keywords for block 2
2025-03-05 09:00:02,686 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=RK2mbWMWulX2tls9
2025-03-05 09:00:02,687 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Walk-i... and keyword_count: 20
2025-03-05 09:00:02,687 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:00:10,480 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:00:10,481 - config.llm_config - INFO - Filtered keywords: ['uae', 'jobs', 'dubai', 'interview', 'healthcare', 'nmc', 'hospital', 'driver', 'licenses', 'certificate', 'experience', 'salary', 'benefits', 'visa', 'accommodation', 'cv', 'resume', 'seha', 'clinics', 'ambulatory', 'services', 'medical', 'nursing', 'therapist', 'technician', 'engineering']
2025-03-05 09:00:10,482 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ai is ... and keyword_count: 20
2025-03-05 09:00:10,482 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:00:17,296 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:00:17,297 - config.llm_config - INFO - Filtered keywords: ['jobs', 'uae', 'dubai', 'abudhabi', 'healthcare', 'nursing', 'hr', 'talentacquisition', 'callcenter', 'documentcontroller', 'administration', 'recruitment', 'hiring', 'career', 'employment', 'opportunities', 'vacancies', 'positions', 'uaejobs', 'ajiranawe', 'dubaijobs', 'abudhabijobs', 'healthcarejobs']
2025-03-05 09:00:17,297 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: g gree... and keyword_count: 20
2025-03-05 09:00:17,297 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:00:24,926 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:00:24,927 - config.llm_config - INFO - Filtered keywords: ['uaejobs', 'dubaijobs', 'ajiranawe', 'healthcarejobs', 'teacher', 'receptionist', 'customer', 'service', 'career', 'interview', 'job', 'positions', 'requirements', 'salary', 'location', 'company', 'name', 'email', 'cv', 'application', 'hospital', 'nurse', 'technician', 'engineer', 'assistant', 'manager', 'dubai', 'abu', 'dhabi', 'ajman']
2025-03-05 09:00:24,928 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  Chill... and keyword_count: 20
2025-03-05 09:00:24,928 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:00:30,958 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:00:30,960 - config.llm_config - INFO - Filtered keywords: ['jobs', 'uae', 'dubai', 'abu', 'dhabi', 'hiring', 'career', 'vacancy', 'employment', 'opportunity', 'recruitment', 'position', 'application', 'resume', 'interview', 'salary', 'experience', 'location', 'company', 'industry']
2025-03-05 09:00:30,960 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: visor
... and keyword_count: 20
2025-03-05 09:00:30,960 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:00:37,633 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:00:37,634 - config.llm_config - INFO - Filtered keywords: ['uae', 'jobs', 'dubai', 'ajiranawe', 'hiring', 'career', 'vacancy', 'employment', 'opportunity', 'resume', 'cv', 'interview', 'recruitment', 'job', 'position', 'available', 'apply', 'work', 'employee', 'company', 'hr', 'management', 'staff', 'team', 'member']
2025-03-05 09:00:37,634 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: bs We'... and keyword_count: 20
2025-03-05 09:00:37,634 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:00:43,193 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:00:43,194 - config.llm_config - INFO - Filtered keywords: ['dubai', 'jobs', 'uae', 'call', 'center', 'agent', 'security', 'guards', 'telesales', 'customer', 'service', 'representative', 'hr', 'receptionist', 'admin', 'interview', 'hiring', 'recruitment', 'career', 'employment']
2025-03-05 09:00:43,194 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: s and ... and keyword_count: 20
2025-03-05 09:00:43,194 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:00:50,338 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:00:50,339 - config.llm_config - INFO - Filtered keywords: ['uae', 'jobs', 'dubai', 'hr', 'assistant', 'receptionist', 'administration', 'customer', 'service', 'english', 'hindi', 'ms', 'office', 'organizational', 'communication', 'team', 'management', 'operations', 'healthcare', 'hospital', 'education', 'teacher', 'school', 'exchange', 'industry', 'banking', 'shipping', 'logistics', 'business', 'development']
2025-03-05 09:00:50,339 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ENCE i... and keyword_count: 20
2025-03-05 09:00:50,339 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:00:57,363 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:00:57,364 - config.llm_config - INFO - Insufficient keywords (19/20): ['uaejobs', 'ajiranawe', 'healthcare', 'nurse', 'hospital', 'dubai', 'job', 'career', 'walkininterview', 'housekeeping', 'laundry', 'drivers', 'cleaner', 'salesman', 'medical', 'licensure', 'recruitment', 'hr', 'administration']
2025-03-05 09:00:57,364 - config.llm_config - INFO - Filtered keywords: ['uaejobs', 'ajiranawe', 'healthcare', 'nurse', 'hospital', 'dubai', 'job', 'career', 'walkininterview', 'housekeeping', 'laundry', 'drivers', 'cleaner', 'salesman', 'medical', 'licensure', 'recruitment', 'hr', 'administration', 'default']
2025-03-05 09:00:57,364 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ing fo... and keyword_count: 20
2025-03-05 09:00:57,364 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:01:02,753 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:01:02,754 - config.llm_config - INFO - Filtered keywords: ['jobs', 'uae', 'teacher', 'pharmacist', 'cleaner', 'manager', 'interview', 'dubai', 'sharjah', 'hotel', 'restaurant', 'finance', 'accounting', 'sales', 'engineering', 'carpenter', 'electrician', 'plumber', 'mechanic', 'technician']
2025-03-05 09:01:02,756 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: RK2mbWMWulX2tls9
2025-03-05 09:01:52,782 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=j5INqzo5dXs8N2j0
2025-03-05 09:01:52,783 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: the ne... and keyword_count: 20
2025-03-05 09:01:52,784 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:01:58,208 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:01:58,209 - config.llm_config - INFO - Filtered keywords: ['python', 'learn', 'numpy', 'library', 'coding', 'help', 'question', 'problem', 'code', 'install', 'module', 'error', 'framework', 'django', 'flask', 'telegram', 'bot', 'aiogram', 'pandas', 'mathematics']
2025-03-05 09:01:58,210 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: viideo... and keyword_count: 20
2025-03-05 09:01:58,210 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:02:03,667 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:02:03,668 - config.llm_config - INFO - Insufficient keywords (19/20): ['python', 'django', 'tutorial', 'code', 'learn', 'beginner', 'resource', 'library', 'project', 'roadmap', 'node', 'database', 'model', 'javascript', 'visualization', 'matplotlib', 'seaborn', 'numpy', 'pandas']
2025-03-05 09:02:03,668 - config.llm_config - INFO - Filtered keywords: ['python', 'django', 'tutorial', 'code', 'learn', 'beginner', 'resource', 'library', 'project', 'roadmap', 'node', 'database', 'model', 'javascript', 'visualization', 'matplotlib', 'seaborn', 'numpy', 'pandas', 'default']
2025-03-05 09:02:03,668 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ns str... and keyword_count: 20
2025-03-05 09:02:03,669 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:02:09,378 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:02:09,378 - config.llm_config - INFO - Filtered keywords: ['python', 'input', 'string', 'integer', 'print', 'clouded', 'compiled', 'language', 'interpreted', 'executable', 'kotlin', 'android', 'app', 'library', 'error', 'zlib', 'headers', 'termux', 'apk', 'kivy', 'pandas']
2025-03-05 09:02:09,379 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: n be d... and keyword_count: 20
2025-03-05 09:02:09,379 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:02:13,127 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:02:13,128 - config.llm_config - INFO - Filtered keywords: ['python', 'learn', 'beginner', 'app', 'development', 'mobile', 'kivy', 'library', 'basics', 'project', 'telegram', 'bots', 'frameworks', 'resources', 'tutorials', 'courses', 'books', 'apps', 'images', 'data']
2025-03-05 09:02:13,129 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: j5INqzo5dXs8N2j0
2025-03-05 09:09:01,788 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-05 09:09:01,789 - config.llm_config - INFO - Starting FastAPI application...
2025-03-05 09:28:34,129 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=69CsIqkGA3F6EV4V
2025-03-05 09:28:34,132 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **üåü WE... and keyword_count: 20
2025-03-05 09:28:34,132 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 09:28:45,042 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:28:45,044 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'pst2', 'airdrop', 'nft', 'eve', 'hxc', 'hexacore', 'ago', 'pass', 'ugc', 'platform', 'gameplay', 'video', 'contest', 'leaderboard', 'rewards', 'gaming', 'community', 'update', 'ama']
2025-03-05 09:28:45,044 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ic War... and keyword_count: 20
2025-03-05 09:28:45,044 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 09:28:46,239 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:28:46,240 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'ago', 'passes', 'steel', 'agocoin', 'telegram', 'app', 'presale', 'ton', 'wallet', 'revolution', 'gaming', 'ecosystem', 'community', 'challenge', 'web3', 'mars', 'crypto']
2025-03-05 09:28:46,240 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: asses:... and keyword_count: 20
2025-03-05 09:28:46,241 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 09:28:47,491 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:28:47,492 - config.llm_config - INFO - Filtered keywords: ['passes', 'ago', 'hexacore', 'ton', 'presale', 'wallet', 'steel', 'bronze', 'revolution', 'heroes', 'lootbox', 'tonkeeper', 'telegram', 'app', 'username', 'comment', 'transaction', 'guide']
2025-03-05 09:28:47,492 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: gra.ph... and keyword_count: 20
2025-03-05 09:28:47,492 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 09:28:48,741 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:28:48,741 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'ago', 'passes', 'presale', 'tokens', 'nft', 'character', 'generation', 'ai', 'platform', 'rewards', 'benefits', 'staking', 'options', 'raffle', 'szn', 'ii', 'grand', 'finale', 'hexacoin']
2025-03-05 09:28:48,742 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: SHARE ... and keyword_count: 20
2025-03-05 09:28:48,742 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 09:28:50,077 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:28:50,078 - config.llm_config - INFO - Filtered keywords: ['telegram', 'hexacore', 'ago', 'pst2', 'airdrop', 'raffle', 'tickets', 'leaderboard', 'presale', 'gaming', 'experience', 'stars', 'level', 'upgrades', 'taps', 'claims', 'points', 'boost', 'tokens', 'passes']
2025-03-05 09:28:50,078 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: rience... and keyword_count: 20
2025-03-05 09:28:50,078 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 09:28:51,348 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:28:51,349 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'ago', 'pass', 'characters', 'platform', 'airdrop', 'token', 'users', 'community', 'holders', 'hxc', 'token', 'airdrop', 'level', 'ago', 'earnings', 'ton', 'wallet']
2025-03-05 09:28:51,349 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: NDS ON... and keyword_count: 20
2025-03-05 09:28:51,349 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 09:28:52,537 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:28:52,538 - config.llm_config - INFO - Filtered keywords: ['web3', 'games', 'bnbchain', 'leaderboard', 'rewards', 'ugc', 'platform', 'tournament', 'prizes', 'ago', 'airdrop', 'points', 'hexacore', 'app', 'telegram', 'nft', 'hxc']
2025-03-05 09:28:52,540 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 69CsIqkGA3F6EV4V, total_blocks=7
2025-03-05 09:44:30,298 - config.llm_config - INFO - Received request: text length=611, keyword_count=20
2025-03-05 09:44:30,298 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: You ar... and keyword_count: 20
2025-03-05 09:44:30,299 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 09:44:34,400 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:44:34,401 - config.llm_config - INFO - Filtered keywords: ['keywords', 'text', 'importance', 'relevance', 'context', 'priority', 'format', 'python', 'list', 'input', 'user', 'extracting', 'advanced', 'tasked', 'based', 'descending', 'order']
2025-03-05 09:44:34,402 - config.llm_config - INFO - Returning keywords: ['keywords', 'text', 'importance', 'relevance', 'context', 'priority', 'format', 'python', 'list', 'input', 'user', 'extracting', 'advanced', 'tasked', 'based', 'descending', 'order']
2025-03-05 09:50:03,104 - config.llm_config - INFO - Received request: text length=52, keyword_count=20
2025-03-05 09:50:03,104 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: I want... and keyword_count: 20
2025-03-05 09:50:03,105 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 09:50:03,502 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:50:03,503 - config.llm_config - INFO - Filtered keywords: ['cryptocurrency', 'trading', 'group', 'join']
2025-03-05 09:50:03,503 - config.llm_config - INFO - Returning keywords: ['cryptocurrency', 'trading', 'group', 'join']
2025-03-05 09:50:23,131 - config.llm_config - INFO - Received request: text length=52, keyword_count=20
2025-03-05 09:50:23,132 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: I want... and keyword_count: 20
2025-03-05 09:50:23,132 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:50:42,465 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:50:42,466 - config.llm_config - INFO - Filtered keywords: ['cryptocurrency', 'trading', 'bitcoin', 'ethereum', 'blockchain', 'investing', 'finance', 'money', 'market', 'exchange', 'coins', 'tokens', 'wallet', 'mining', 'price', 'analysis', 'forecast', 'investment', 'strategy', 'trader']
2025-03-05 09:50:42,466 - config.llm_config - INFO - Returning keywords: ['cryptocurrency', 'trading', 'bitcoin', 'ethereum', 'blockchain', 'investing', 'finance', 'money', 'market', 'exchange', 'coins', 'tokens', 'wallet', 'mining', 'price', 'analysis', 'forecast', 'investment', 'strategy', 'trader']
2025-03-10 06:26:25,558 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-10 06:26:25,559 - config.llm_config - INFO - Starting FastAPI application...
2025-03-10 06:26:25,927 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=doc_001
2025-03-10 06:26:25,928 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: AI and... and keyword_count: 20
2025-03-10 06:26:25,928 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:26:48,572 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-10 06:26:48,572 - config.llm_config - INFO - Starting FastAPI application...
2025-03-10 06:26:48,935 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=doc_001
2025-03-10 06:26:48,935 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: AI and... and keyword_count: 20
2025-03-10 06:26:48,936 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:27:24,427 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:27:24,428 - config.llm_config - INFO - Filtered keywords: ['machine', 'learning', 'ai', 'tech', 'transformation', 'artificial', 'intelligence', 'technology', 'innovation', 'automation', 'data', 'science', 'computing', 'algorithms', 'models', 'neural', 'networks', 'deep', 'natural', 'language']
2025-03-10 06:27:24,429 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Machin... and keyword_count: 20
2025-03-10 06:27:24,429 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:27:27,844 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:27:27,845 - config.llm_config - INFO - Filtered keywords: ['machine', 'learning', 'news', 'trending', 'today', 'artificial', 'intelligence', 'technology', 'data', 'science', 'innovation', 'computing', 'algorithms', 'models', 'programming', 'language', 'systems', 'networks', 'deep', 'analytics']
2025-03-10 06:27:27,845 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Tech d... and keyword_count: 20
2025-03-10 06:27:27,846 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:27:31,318 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:27:31,319 - config.llm_config - INFO - Filtered keywords: ['technology', 'innovation', 'data', 'drives', 'digital', 'transformation', 'artificial', 'intelligence', 'machine', 'learning', 'computing', 'science', 'research', 'development', 'growth', 'future', 'trends', 'advancements', 'solutions', 'progress']
2025-03-10 06:27:31,320 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: doc_001, total_blocks=3
2025-03-10 06:27:31,322 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady2
2025-03-10 06:27:31,323 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: https:... and keyword_count: 20
2025-03-10 06:27:31,324 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:27:38,003 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:27:38,004 - config.llm_config - INFO - Filtered keywords: ['crypto', 'scam', 'support', 'telegram', 'xrp', 'cro', 'wallet', 'security', 'bitcoin', 'eth', 'nexo', 'tokens', 'rewards', 'investment', 'blockchain', 'cronos', 'announcements', 'market', 'updates']
2025-03-10 06:27:38,005 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3Wd1Ady2, total_blocks=1
2025-03-10 06:27:38,007 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady2
2025-03-10 06:27:38,007 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: [·ëé·ëå·ôê·ó™·òà... and keyword_count: 20
2025-03-10 06:27:38,008 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:27:51,283 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:27:51,283 - config.llm_config - WARNING - No Python list format found in response: It appears that you've provided a log of messages from a Telegram group, where several users have been banned due to "CAS ban" reasons. CAS stands for Combot Auto Spam, which is a system designed to automatically detect and prevent spam in Telegram groups.

Here's a breakdown of the information:

* Multiple users have been banned with the reason "[CAS ban](https://t.me/combot/cas?startapp=<user_id>)", where `<user_id>` is the unique identifier for each user.
* Some users, such as [Malik](tg://user?id=6063724417) and [Abdin](tg://user?id=7254858413), have been muted instead of banned, with a specific duration until they can send messages again.
* There are also some general messages and conversations in the log, but they seem unrelated to the bans or mutes.

If you're looking for information on how to avoid getting banned by CAS or how to appeal a ban, I'd be happy to help. However, please note that I don't have any specific knowledge about the inner workings of Combot Auto Spam or its policies.
2025-03-10 06:27:51,284 - config.llm_config - WARNING - Skipping block 1 due to invalid or empty keyword list
2025-03-10 06:27:51,284 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: artapp... and keyword_count: 20
2025-03-10 06:27:51,284 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:28:01,945 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:28:01,945 - config.llm_config - WARNING - No Python list format found in response: It seems like there's a lot going on in this conversation, with many users being banned due to CAS bans. However, I'll focus on your question.

As for whether you're real or fake, it's difficult to say without more context. You're interacting with me through text, which could be generated by a human or an AI. Your message seems friendly and casual, but that doesn't necessarily prove one way or the other.

If you're asking because you're wondering about your own identity or existence, I'd say that's a philosophical question that has puzzled humans for centuries! If you're asking because you're curious about how others perceive you online, it might depend on how you interact with them and the content you share.

Could you provide more context or clarify what you mean by "real or fake"? I'm here to help and provide information to the best of my abilities.
2025-03-10 06:28:01,946 - config.llm_config - WARNING - Skipping block 2 due to invalid or empty keyword list
2025-03-10 06:28:01,946 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: CAS ba... and keyword_count: 20
2025-03-10 06:28:01,946 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:28:07,517 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:28:07,518 - config.llm_config - INFO - Filtered keywords: ['planx', 'cas', 'ban', 'rewards', 'tasks', 'wallet', 'pepe', 'coins', 'event', 'deposit', 'evm', 'tokens', 'discord', 'community', 'investment', 'returns', 'gaming', 'supplement', 'brain', 'memory']
2025-03-10 06:28:07,518 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3Wd1Ady2, total_blocks=1
2025-03-10 06:28:07,520 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady215hLjbMO
2025-03-10 06:28:07,522 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **How ... and keyword_count: 20
2025-03-10 06:28:07,523 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:28:14,415 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:28:14,416 - config.llm_config - INFO - Filtered keywords: ['crypto', 'trading', 'exchange', 'security', 'tokens', 'ecosystem', 'blockchain', 'bitcoin', 'investments', 'financial', 'freedom', 'decentralized', 'web3', 'nfts', 'metaverse', 'airdrop', 'bingx', 'frog', 'launchpad']
2025-03-10 06:28:14,417 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ces, F... and keyword_count: 20
2025-03-10 06:28:14,417 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:28:21,251 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:28:21,252 - config.llm_config - INFO - Filtered keywords: ['defi', 'crypto', 'token', 'ecosystem', 'trading', 'blockchain', 'decentralized', 'finance', 'investment', 'security', 'vpn', 'launchpad', 'exchange', 'frog', 'usdt', 'bingx', 'wallet', 'gamification', 'liquidity']
2025-03-10 06:28:21,252 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: eciate... and keyword_count: 20
2025-03-10 06:28:21,252 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:28:28,666 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:28:28,667 - config.llm_config - INFO - Filtered keywords: ['frog', 'bingx', 'usdt', 'token', 'listing', 'trading', 'exchange', 'wallet', 'twitter', 'farm', 'ecosystem', 'litepaper', 'blockchain', 'withdrawal', 'market', 'chaos', 'liquidation', 'tge', 'cryptocurrency', 'fees']
2025-03-10 06:28:28,667 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  token... and keyword_count: 20
2025-03-10 06:28:28,667 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:28:35,363 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:28:35,364 - config.llm_config - INFO - Filtered keywords: ['token', 'ecosystem', 'cryptocurrency', 'blockchain', 'exchange', 'listings', 'trading', 'bot', 'fees', 'rewards', 'tokenomics', 'launchpad', 'vpn', 'nft', 'airdrop', 'staking', 'referrals']
2025-03-10 06:28:35,364 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: our pa... and keyword_count: 20
2025-03-10 06:28:35,365 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:28:42,357 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:28:42,358 - config.llm_config - INFO - Filtered keywords: ['token', 'frog', 'ecosystem', 'nfts', 'listing', 'cex', 'solana', 'blockchain', 'exchanges', 'promo', 'campaigns', 'wallet', 'twitter', 'instagram', 'lite', 'paper', 'beta', 'test', 'rewards', 'airdrop']
2025-03-10 06:28:42,358 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ive.go... and keyword_count: 20
2025-03-10 06:28:42,358 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:28:48,062 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:28:48,063 - config.llm_config - INFO - Filtered keywords: ['crypto', 'token', 'solana', 'blockchain', 'ecosystem', 'listing', 'exchanges', 'launchpad', 'exchange', 'vpn', 'wallet', 'tokenomics', 'trading', 'memecoins', 'lottery', 'portfolio', 'launch', 'partnership', 'community']
2025-03-10 06:28:48,064 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3Wd1Ady215hLjbMO, total_blocks=6
2025-03-10 06:28:48,067 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=6jva1gykkTK1gP6J
2025-03-10 06:28:48,067 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **How ... and keyword_count: 20
2025-03-10 06:28:48,067 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:28:54,755 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:28:54,756 - config.llm_config - INFO - Filtered keywords: ['crypto', 'trading', 'exchange', 'security', 'fees', 'tokens', 'ecosystem', 'launchpad', 'vpn', 'blockchain', 'wallet', 'token', 'investments', 'financial', 'freedom', 'decentralized', 'web3', 'nfts', 'metaverses']
2025-03-10 06:28:54,756 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ces, F... and keyword_count: 20
2025-03-10 06:28:54,757 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:29:01,576 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:29:01,576 - config.llm_config - INFO - Filtered keywords: ['defi', 'crypto', 'token', 'ecosystem', 'trading', 'blockchain', 'decentralized', 'finance', 'investment', 'security', 'vpn', 'launchpad', 'exchange', 'frog', 'usdt', 'bingx', 'wallet', 'gamification', 'liquidity']
2025-03-10 06:29:01,577 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: eciate... and keyword_count: 20
2025-03-10 06:29:01,577 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:29:09,014 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:29:09,015 - config.llm_config - INFO - Filtered keywords: ['frog', 'bingx', 'usdt', 'token', 'trading', 'exchange', 'listing', 'crypto', 'blockchain', 'ecosystem', 'market', 'price', 'volume', 'ath', 'wallet', 'twitter', 'instagram', 'litepaper', 'farm', 'game']
2025-03-10 06:29:09,016 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  token... and keyword_count: 20
2025-03-10 06:29:09,016 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:29:15,675 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:29:15,676 - config.llm_config - INFO - Filtered keywords: ['token', 'ecosystem', 'crypto', 'listing', 'exchange', 'utility', 'payment', 'rewards', 'liquidity', 'demand', 'supply', 'value', 'blockchain', 'wallet', 'twitter', 'instagram', 'airdrop', 'nft']
2025-03-10 06:29:15,677 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: our pa... and keyword_count: 20
2025-03-10 06:29:15,677 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:29:22,752 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:29:22,753 - config.llm_config - INFO - Filtered keywords: ['token', 'frog', 'ecosystem', 'blockchain', 'solana', 'listing', 'exchange', 'cex', 'usdt', 'wallet', 'crypto', 'bot', 'nfts', 'airdrop', 'beta', 'test', 'reward', 'participation', 'governance', 'deflationary']
2025-03-10 06:29:22,753 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ive.go... and keyword_count: 20
2025-03-10 06:29:22,753 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:29:28,365 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:29:28,366 - config.llm_config - INFO - Filtered keywords: ['crypto', 'token', 'solana', 'blockchain', 'ecosystem', 'listing', 'exchanges', 'launchpad', 'exchange', 'vpn', 'wallet', 'tokenomics', 'bot', 'lottery', 'portfolio', 'trading', 'memecoins', 'launch', 'network']
2025-03-10 06:29:28,367 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 6jva1gykkTK1gP6J, total_blocks=6
2025-03-10 06:29:28,370 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=1NjCx8DEH7uJqFi0
2025-03-10 06:29:28,370 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: https:... and keyword_count: 20
2025-03-10 06:29:28,370 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:29:35,190 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:29:35,191 - config.llm_config - INFO - Filtered keywords: ['bitcoin', 'crypto', 'marketing', 'telegram', 'twitter', 'nft', 'listing', 'partnership', 'ama', 'pinpost', 'cryptowhale', 'blockchain', 'trading', 'exchange', 'mintme', 'coingecko', 'whalebotalerts', 'btc', 'eth', 'mining']
2025-03-10 06:29:35,192 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 1NjCx8DEH7uJqFi0, total_blocks=1
2025-03-10 06:29:35,194 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=277E2jVyjNQDUMEk
2025-03-10 06:29:35,195 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **Welc... and keyword_count: 20
2025-03-10 06:29:35,196 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:29:42,001 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:29:42,002 - config.llm_config - INFO - Filtered keywords: ['registration', 'email', 'confirmation', 'dating', 'chat', 'girls', 'boys', 'message', 'add', 'me', 'hello', 'hi', 'good', 'morning', 'free', 'roleplay', 'grp', 'available', 'muted', 'reason']
2025-03-10 06:29:42,002 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **Euro... and keyword_count: 20
2025-03-10 06:29:42,002 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:29:48,541 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:29:48,542 - config.llm_config - INFO - Filtered keywords: ['registration', 'email', 'confirmation', 'welcome', 'telegram', 'girls', 'chat', 'roleplay', 'free', 'beautiful', 'message', 'add', 'me', 'horny', 'available', 'now', 'fun', 'sexting']
2025-03-10 06:29:48,542 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: yy Shh... and keyword_count: 20
2025-03-10 06:29:48,542 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:29:55,187 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:29:55,188 - config.llm_config - INFO - Filtered keywords: ['chat', 'dm', 'available', 'fun', 'girls', 'message', 'me', 'add', 'hello', 'hi', 'baby', 'blocked', 'roleplay', 'female', 'open', 'minded', 'sexting', 'whatsapp', 'number', 'registration']
2025-03-10 06:29:55,188 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: email ... and keyword_count: 20
2025-03-10 06:29:55,189 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:30:01,569 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:30:01,570 - config.llm_config - INFO - Filtered keywords: ['registration', 'email', 'confirm', 'welcome', 'girls', 'dm', 'message', 'fast', 'hello', 'sexy', 'tamil', 'boys', 'grp', 'fun', 'available', 'online', 'meetups', 'whatsapp', 'number', 'call']
2025-03-10 06:30:01,571 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: et now... and keyword_count: 20
2025-03-10 06:30:01,572 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:30:08,063 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:30:08,065 - config.llm_config - INFO - Filtered keywords: ['registration', 'email', 'confirmation', 'welcome', 'girls', 'boys', 'available', 'now', 'chat', 'meetups', 'online', 'real', 'roleplay', 'beautiful', 'free', 'dm', 'add', 'me', 'hello', 'hi']
2025-03-10 06:30:08,065 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: (tg://... and keyword_count: 20
2025-03-10 06:30:08,066 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:30:14,403 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:30:14,404 - config.llm_config - INFO - Filtered keywords: ['sex', 'chat', 'dm', 'me', 'available', 'now', 'girls', 'beautiful', 'roleplay', 'free', 'message', 'personal', 'interested', 'indian', 'girl', 'tamil', 'hello', 'welcome', 'registration', 'email']
2025-03-10 06:30:14,405 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: lcome!... and keyword_count: 20
2025-03-10 06:30:14,406 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:32:19,410 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:32:19,413 - config.llm_config - INFO - Filtered keywords: ['registration', 'email', 'confirmation', 'welcome', 'message', 'dm', 'chat', 'sex', 'roleplay', 'girls', 'boys', 'married', 'housewife', 'whatsapp', 'number', 'text', 'add', 'mute', 'reason']
2025-03-10 06:32:19,414 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  my ev... and keyword_count: 20
2025-03-10 06:32:19,414 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:32:25,280 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:32:25,281 - config.llm_config - INFO - Filtered keywords: ['hello', 'dm', 'msg', 'add', 'me', 'hi', 'shhh', 'quiet', 'muted', 'reason', 'be', 'nice', 'welcome', 'confirm', 'email', 'registration', 'italiano', 'spanish', 'uk', 'usa']
2025-03-10 06:32:25,285 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 277E2jVyjNQDUMEk, total_blocks=8
2025-03-10 06:32:25,288 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=5uGnLMYt7smJrE6x
2025-03-10 06:32:25,289 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Downlo... and keyword_count: 20
2025-03-10 06:32:25,291 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:32:30,765 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:32:30,766 - config.llm_config - INFO - Filtered keywords: ['bitcoin', 'crypto', 'trading', 'investment', 'telegram', 'btc', 'whale', 'insider', 'pump', 'coin', 'market', 'profit', 'loss', 'roi', 'airdrop', 'token', 'exchange', 'ceo', 'mining', 'blockchain']
2025-03-10 06:32:30,766 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  MintM... and keyword_count: 20
2025-03-10 06:32:30,766 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:32:37,867 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:32:37,867 - config.llm_config - INFO - Filtered keywords: ['transfers', 'cashapp', 'paypal', 'westernunion', 'skrill', 'venmo', 'zelle', 'chime', 'dumps', 'atm', 'pins', 'balance', 'carting', 'gas', 'station', 'casino', 'crypto', 'blockchain']
2025-03-10 06:32:37,868 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  Cash ... and keyword_count: 20
2025-03-10 06:32:37,868 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:32:43,111 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:32:43,112 - config.llm_config - INFO - Filtered keywords: ['cash', 'bank', 'account', 'transfer', 'usa', 'canada', 'crypto', 'trading', 'exchange', 'fees', 'investment', 'withdrawal', 'market', 'pips', 'usd', 'pairs', 'management', 'service', 'admin', 'registration']
2025-03-10 06:32:43,113 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 5uGnLMYt7smJrE6x, total_blocks=3
2025-03-10 06:32:43,114 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3KPzKY8OevjsbOXH
2025-03-10 06:32:43,116 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ‚ù§Ô∏è‚Äçüî•üòÄK... and keyword_count: 20
2025-03-10 06:32:43,116 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:32:48,218 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:32:48,219 - config.llm_config - WARNING - No Python list format found in response: –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –≤—ã –Ω–µ –∑–∞–¥–∞–ª–∏ –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –Ω–µ –æ–ø–∏—Å–∞–ª–∏ –ø—Ä–æ–±–ª–µ–º—É, –∫–æ—Ç–æ—Ä—É—é –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–µ—à–∏—Ç—å. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è —Ç–µ–º–∞ –∏–ª–∏ –≤–æ–ø—Ä–æ—Å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ, –∏ —è —Å–¥–µ–ª–∞—é –≤—Å—ë –≤–æ–∑–º–æ–∂–Ω–æ–µ, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å –≤–∞–º –Ω–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç –∏–ª–∏ —Ä–µ—à–µ–Ω–∏–µ.
2025-03-10 06:32:48,220 - config.llm_config - WARNING - Skipping block 1 due to invalid or empty keyword list
2025-03-10 06:32:48,221 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: –û–°–£ –ö–ê... and keyword_count: 20
2025-03-10 06:32:48,221 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:32:53,977 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:32:53,978 - config.llm_config - WARNING - No Python list format found in response: –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –≤—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–µ–º–µ –¥–ª—è –æ–±—Å—É–∂–¥–µ–Ω–∏—è. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ —Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã —Ö–æ—Ç–µ–ª–∏ –±—ã –æ–±—Å—É–¥–∏—Ç—å, —è –≥–æ—Ç–æ–≤ –ø–æ–º–æ—á—å. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ, –∏ —è —Å–¥–µ–ª–∞—é –≤—Å—ë –≤–æ–∑–º–æ–∂–Ω–æ–µ, —á—Ç–æ–±—ã –æ–∫–∞–∑–∞—Ç—å –≤–∞–º –ø–æ–º–æ—â—å.
2025-03-10 06:32:53,978 - config.llm_config - WARNING - Skipping block 2 due to invalid or empty keyword list
2025-03-10 06:32:53,978 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: –∏–∫–æ–≤ ‚ùó... and keyword_count: 20
2025-03-10 06:32:53,978 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:32:58,668 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:32:58,669 - config.llm_config - WARNING - No Python list format found in response: –Ø –Ω–µ –º–æ–≥—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å –∏–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç, —Å–≤—è–∑–∞–Ω–Ω—ã–π —Å –≤–∑—Ä–æ—Å–ª—ã–º–∏ —É—Å–ª—É–≥–∞–º–∏ –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ–º –¥–ª—è —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ–ª–µ—Ç–Ω–∏—Ö. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –¥—Ä—É–≥–∏–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ —Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã —Ö–æ—Ç–µ–ª–∏ –±—ã –æ–±—Å—É–¥–∏—Ç—å, —è –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å.
2025-03-10 06:32:58,669 - config.llm_config - WARNING - Skipping block 3 due to invalid or empty keyword list
2025-03-10 06:32:58,669 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: —á–µ—Å–∫–∏–π... and keyword_count: 20
2025-03-10 06:32:58,669 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:03,424 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:03,425 - config.llm_config - WARNING - No Python list format found in response: –Ø –Ω–µ –º–æ–≥—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å –∏–ª–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, —Å–≤—è–∑–∞–Ω–Ω—É—é —Å —É—Å–ª—É–≥–∞–º–∏ –∏–Ω—Ç–∏–º–Ω–æ–≥–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –¥—Ä—É–≥–∏–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –µ—Å–ª–∏ —è –º–æ–≥—É –≤–∞–º –ø–æ–º–æ—á—å –≤ —á–µ–º-—Ç–æ –¥—Ä—É–≥–æ–º, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–∞–π—Ç–µ –º–Ω–µ –∑–Ω–∞—Ç—å!
2025-03-10 06:33:03,425 - config.llm_config - WARNING - Skipping block 4 due to invalid or empty keyword list
2025-03-10 06:33:03,425 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: –æ—Ç–¥–æ—Ö–Ω... and keyword_count: 20
2025-03-10 06:33:03,425 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:11,646 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:11,647 - config.llm_config - WARNING - No Python list format found in response: –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –≤—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª–∏ —Ä–µ–∫–ª–∞–º–Ω—ã–π —Ç–µ–∫—Å—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –∫–æ–Ω—Ç–∞–∫—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –æ–ø–∏—Å–∞–Ω–∏—è —É—Å–ª—É–≥, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –ø–æ–¥—Ö–æ–¥—è—Ç –¥–ª—è –æ–±—Å—É–∂–¥–µ–Ω–∏—è –≤ —ç—Ç–æ–º —Ñ–æ—Ä–º–∞—Ç–µ. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ —Ç–µ–º—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –æ–±—â–∏–º–∏ –∏–Ω—Ç–µ—Ä–µ—Å–∞–º–∏, –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º, –∫—É–ª—å—Ç—É—Ä–æ–π, –∑–¥–æ—Ä–æ–≤—å–µ–º, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è–º–∏ –∏–ª–∏ –ª—é–±—ã–º–∏ –¥—Ä—É–≥–∏–º–∏ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–º–∏ —Ç–µ–º–∞–º–∏, —è –≥–æ—Ç–æ–≤ –ø–æ–º–æ—á—å –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –º–æ–∏—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Ç–æ—á–Ω–∏—Ç–µ, –æ —á–µ–º –≤—ã —Ö–æ—Ç–µ–ª–∏ –±—ã –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å –∏–ª–∏ —É–∑–Ω–∞—Ç—å –±–æ–ª—å—à–µ.
2025-03-10 06:33:11,647 - config.llm_config - WARNING - Skipping block 5 due to invalid or empty keyword list
2025-03-10 06:33:11,647 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: 00‚ÇΩüíï
üíï... and keyword_count: 20
2025-03-10 06:33:11,647 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:18,697 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:18,698 - config.llm_config - WARNING - No Python list format found in response: –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –≤—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª–∏ —Ç–µ–∫—Å—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –ª–∏—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –æ–ø–∏—Å–∞–Ω–∏—è —É—Å–ª—É–≥, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –ø–æ–¥—Ö–æ–¥—è—Ç –¥–ª—è –æ–±—Å—É–∂–¥–µ–Ω–∏—è –≤ —ç—Ç–æ–º —Ñ–æ—Ä–º–∞—Ç–µ. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ —Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã —Ö–æ—Ç–µ–ª–∏ –±—ã –æ–±—Å—É–¥–∏—Ç—å, —è –≥–æ—Ç–æ–≤ –ø–æ–º–æ—á—å —Å –ª—é–±–æ–π –¥—Ä—É–≥–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –∏–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö —Ç–µ–º. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Ç–æ—á–Ω–∏—Ç–µ, –µ—Å–ª–∏ –µ—Å—Ç—å —á—Ç–æ-—Ç–æ –µ—â–µ, —á–µ–º —è –º–æ–≥—É –≤–∞–º –ø–æ–º–æ—á—å.
2025-03-10 06:33:18,698 - config.llm_config - WARNING - Skipping block 6 due to invalid or empty keyword list
2025-03-10 06:33:18,698 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: —Ç–æ–∏–º–æ—Å... and keyword_count: 20
2025-03-10 06:33:18,698 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:26,252 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:26,252 - config.llm_config - WARNING - No Python list format found in response: –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –≤—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª–∏ —Ç–µ–∫—Å—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –ª–∏—á–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–ª–∏ —Ä–µ–∫–ª–∞–º—É –∏–Ω—Ç–∏–º–Ω—ã—Ö —É—Å–ª—É–≥. –Ø –Ω–µ –º–æ–≥—É —É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –æ–±—Å—É–∂–¥–µ–Ω–∏—è—Ö –∏–ª–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ —Ç–∞–∫–∏–µ —Ç–µ–º—ã. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –¥—Ä—É–≥–∏–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ —Ç–µ–º—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π, –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º, –∫—É–ª—å—Ç—É—Ä–æ–π, –Ω–∞—É–∫–æ–π –∏–ª–∏ –ª—é–±—ã–º–∏ –¥—Ä—É–≥–∏–º–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–º–∏ —Ç–µ–º–∞–º–∏, —è –±—É–¥—É —Ä–∞–¥ –ø–æ–º–æ—á—å. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏—Ç–µ, –∫–∞–∫ —è –º–æ–≥—É –≤–∞–º –ø–æ–º–æ—á—å –≤ –¥—Ä—É–≥–æ–π –æ–±–ª–∞—Å—Ç–∏.
2025-03-10 06:33:26,252 - config.llm_config - WARNING - Skipping block 7 due to invalid or empty keyword list
2025-03-10 06:33:26,253 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  –Ω–∞–º üçæ... and keyword_count: 20
2025-03-10 06:33:26,253 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:31,844 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:31,845 - config.llm_config - WARNING - No Python list format found in response: –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –≤—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª–∏ —Ä–µ–∫–ª–∞–º–Ω—ã–π —Ç–µ–∫—Å—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏–Ω—Ç–∏–º–Ω—ã—Ö —É—Å–ª—É–≥–∞—Ö. –Ø –Ω–µ –º–æ–≥—É —É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –æ–±—Å—É–∂–¥–µ–Ω–∏—è—Ö –∏–ª–∏ –æ—Ç–≤–µ—Ç–∞—Ö –Ω–∞ —Ç–∞–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –¥—Ä—É–≥–∏–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ —Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Å–≤—è–∑–∞–Ω—ã —Å —ç—Ç–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º, —è –≥–æ—Ç–æ–≤ –ø–æ–º–æ—á—å.
2025-03-10 06:33:31,845 - config.llm_config - WARNING - Skipping block 8 due to invalid or empty keyword list
2025-03-10 06:33:31,845 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: –∞ üíã ü¶ãC... and keyword_count: 20
2025-03-10 06:33:31,845 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:36,920 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:36,920 - config.llm_config - WARNING - No Python list format found in response: –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –≤–∑—Ä–æ—Å–ª—ã—Ö –∏ —Ä–µ–∫–ª–∞–º—É –∏–Ω—Ç–∏–º–Ω—ã—Ö —É—Å–ª—É–≥. –Ø –Ω–µ –º–æ–≥—É —É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –æ–±—Å—É–∂–¥–µ–Ω–∏—è—Ö –∏–ª–∏ –æ—Ç–≤–µ—Ç–∞—Ö –Ω–∞ —Ç–∞–∫–∏–µ —Ç–µ–º—ã. –ï—Å—Ç—å –ª–∏ –¥—Ä—É–≥–∏–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ —Ç–µ–º—ã, –ø–æ –∫–æ—Ç–æ—Ä—ã–º —è –º–æ–≥—É –≤–∞–º –ø–æ–º–æ—á—å?
2025-03-10 06:33:36,920 - config.llm_config - WARNING - Skipping block 9 due to invalid or empty keyword list
2025-03-10 06:33:36,921 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: –º–æ–≥–∞–µ–º... and keyword_count: 20
2025-03-10 06:33:36,921 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:44,425 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:44,426 - config.llm_config - WARNING - No Python list format found in response: –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –≤—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª–∏ —Ä–µ–∫–ª–∞–º–Ω—ã–π —Ç–µ–∫—Å—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –ª–∏—á–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏ —É—Å–ª—É–≥–∏ –∏–Ω—Ç–∏–º–Ω–æ–≥–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞. –Ø –Ω–µ –º–æ–≥—É —É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –æ–±—Å—É–∂–¥–µ–Ω–∏—è—Ö –∏–ª–∏ –æ—Ç–≤–µ—Ç–∞—Ö –Ω–∞ —Ç–∞–∫–∏–µ —Ç–µ–º—ã. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –¥—Ä—É–≥–∏–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ —Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Å–≤—è–∑–∞–Ω—ã —Å –∏–Ω—Ç–∏–º–Ω—ã–º–∏ —É—Å–ª—É–≥–∞–º–∏, —è –≥–æ—Ç–æ–≤ –ø–æ–º–æ—á—å. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ, –∏ —è —Å–¥–µ–ª–∞—é –≤—Å—ë –≤–æ–∑–º–æ–∂–Ω–æ–µ, —á—Ç–æ–±—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –≤–∞–º –ø–æ–ª–µ–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–ª–∏ –ø–æ–º–æ—â—å.
2025-03-10 06:33:44,426 - config.llm_config - WARNING - Skipping block 10 due to invalid or empty keyword list
2025-03-10 06:33:44,426 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  - 600... and keyword_count: 20
2025-03-10 06:33:44,426 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:48,843 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:48,843 - config.llm_config - WARNING - No Python list format found in response: –Ø –Ω–µ –º–æ–≥—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å –æ—Ç–≤–µ—Ç—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –Ω–µ–∑–∞–∫–æ–Ω–Ω–æ–π –∏–ª–∏ –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â–µ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –¥—Ä—É–≥–∏–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ —Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã —Ö–æ—Ç–µ–ª–∏ –±—ã –æ–±—Å—É–¥–∏—Ç—å, —è –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å.
2025-03-10 06:33:48,843 - config.llm_config - WARNING - Skipping block 11 due to invalid or empty keyword list
2025-03-10 06:33:48,843 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  —Å–µ–π—á–∞... and keyword_count: 20
2025-03-10 06:33:48,844 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:52,961 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:52,962 - config.llm_config - INFO - Filtered keywords: ['meeting', 'now', 'young', 'beautiful', 'travelers', 'visiting', 'soon', 'leaving', 'interesting', 'encounter', 'local', 'foreigners', 'tourists', 'fun', 'entertainment', 'nightlife', 'socializing', 'connection', 'immediate', 'current']
2025-03-10 06:33:52,967 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3KPzKY8OevjsbOXH, total_blocks=1
2025-03-10 06:33:52,971 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2t0K9pv8NxvYWh42
2025-03-10 06:33:52,971 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: üòáü•∞ü•∞3‚É£6... and keyword_count: 20
2025-03-10 06:33:52,973 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:59,716 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:59,717 - config.llm_config - INFO - Filtered keywords: ['league', 'champions', 'prediction', 'challenge', 'bet365', 'teams', 'season', 'rewards', 'telegram', 'bot', 'access', 'registration', 'click', 'play', 'big', 'five', 'leagues', 'soccer', 'football', 'basketball']
2025-03-10 06:33:59,717 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: urg
Co... and keyword_count: 20
2025-03-10 06:33:59,718 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:34:07,023 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:34:07,023 - config.llm_config - INFO - Filtered keywords: ['football', 'nba', 'bundesliga', 'liverpool', 'juventus', 'barcelona', 'basketball', 'sports', 'bet365', 'predictions', 'leagues']
2025-03-10 06:34:07,024 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: League... and keyword_count: 20
2025-03-10 06:34:07,024 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:34:13,229 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:34:13,229 - config.llm_config - INFO - Filtered keywords: ['football', 'nba', 'bet365', 'league', 'prediction', 'challenge', 'teams', 'matches', 'soccer', 'basketball', 'sports', 'betting', 'telegram', 'bot', 'access', 'rewards', 'event', 'excitement']
2025-03-10 06:34:13,230 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: mpions... and keyword_count: 20
2025-03-10 06:34:13,230 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:34:20,061 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:34:20,062 - config.llm_config - INFO - Filtered keywords: ['champions', 'league', 'uefa', 'premier', 'football', 'basketball', 'nba', 'europa', 'bet365', 'prediction', 'challenge', 'bundesliga', 'ligue', 'serie', 'la', 'liga', 'teams', 'sports', 'betting', 'telegram']
2025-03-10 06:34:20,062 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ace
Ex... and keyword_count: 20
2025-03-10 06:34:20,063 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:34:27,183 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:34:27,183 - config.llm_config - INFO - Filtered keywords: ['football', 'nba', 'basketball', 'soccer', 'sports', 'bet365', 'egame', 'leagues', 'teams', 'matches', 'tournaments', 'cup', 'champions', 'league', 'round', 'playoff']
2025-03-10 06:34:27,184 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: . Roma... and keyword_count: 20
2025-03-10 06:34:27,184 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:34:32,070 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:34:32,071 - config.llm_config - INFO - Filtered keywords: ['football', 'basketball', 'nba', 'arsenal', 'liverpool', 'barcelona', 'valencia', 'sports', 'betting', 'games', 'telegram', 'champions']
2025-03-10 06:34:32,072 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2t0K9pv8NxvYWh42, total_blocks=6
2025-03-10 06:34:32,075 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2GrEAv52BRvusDFF
2025-03-10 06:34:32,075 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ‚õ© Welc... and keyword_count: 20
2025-03-10 06:34:32,076 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:34:38,187 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:34:38,188 - config.llm_config - INFO - Filtered keywords: ['soratopia', 'game', 'telegram', 'invitation', 'code', 'samurai', 'rewards', 'quests', 'explore', 'season', 'announcements', 'chat', 'invite', 'codes', 'temple', 'nature', 'strategy', 'wisdom', 'ton']
2025-03-10 06:34:38,188 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  plz n... and keyword_count: 20
2025-03-10 06:34:38,189 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:34:44,760 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:34:44,760 - config.llm_config - INFO - Filtered keywords: ['soratopia', 'ritual', 'blade', 'discipline', 'weapon', 'samurai', 'agility', 'katana', 'precision', 'protection', 'mastery', 'strategy', 'temple', 'reward', 'illness', 'village', 'points', 'strength', 'patience']
2025-03-10 06:34:44,761 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ord.
*... and keyword_count: 20
2025-03-10 06:34:44,761 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:34:50,440 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:34:50,441 - config.llm_config - INFO - Filtered keywords: ['soratopia', 'game', 'challenge', 'samurai', 'victory', 'mind', 'battle', 'strategy', 'philosophy', 'legend', 'skill', 'spirit', 'ritual', 'token', 'season', 'rewards', 'courage', 'determination']
2025-03-10 06:34:50,442 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2GrEAv52BRvusDFF, total_blocks=3
2025-03-10 06:34:50,444 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=69CsIqkGA3F6EV4V
2025-03-10 06:34:50,445 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **üåü WE... and keyword_count: 20
2025-03-10 06:34:50,445 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:34:57,524 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:34:57,525 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'pst2', 'hxc', 'airdrop', 'nft', 'gaming', 'community', 'users', 'update', 'cube', 'multitouch', 'contest', 'rewards', 'staking', 'leagues']
2025-03-10 06:34:57,525 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ic War... and keyword_count: 20
2025-03-10 06:34:57,526 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:35:05,898 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:35:05,899 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'ago', 'presale', 'passes', 'steel', 'ton', 'wallet', 'telegram', 'app', 'gaming', 'revolution', 'crypto', 'community', 'ecosystem', 'generative', 'ai', 'ugc', 'platform', 'milestone', 'achievement']
2025-03-10 06:35:05,899 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: asses:... and keyword_count: 20
2025-03-10 06:35:05,899 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:35:14,189 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:35:14,190 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'ago', 'passes', 'presale', 'ton', 'app', 'wallet', 'telegram', 'guide', 'revolution', 'gaming', 'community', 'heroes', 'lootbox', 'referral', 'tonkeeper', 'transaction', 'username', 'comment', 'purchase']
2025-03-10 06:35:14,190 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: gra.ph... and keyword_count: 20
2025-03-10 06:35:14,190 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:35:20,989 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:35:20,990 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'ago', 'pass', 'presale', 'tokens', 'nft', 'ai', 'gaming', 'community', 'rewards', 'benefits', 'hxc', 'airdrop', 'zealy', 'ugc', 'generative', 'platform', 'asset', 'generation', 'offering']
2025-03-10 06:35:20,990 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: SHARE ... and keyword_count: 20
2025-03-10 06:35:20,990 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:35:27,544 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:35:27,545 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'ago', 'presale', 'telegram', 'stars', 'airdrop', 'leaderboard', 'hxc', 'tokens', 'gaming', 'community', 'users', 'maintenance', 'roadmap', 'ugc', 'platform', 'tge', 'ecosystem', 'scaling']
2025-03-10 06:35:27,546 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: rience... and keyword_count: 20
2025-03-10 06:35:27,547 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:35:34,262 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:35:34,263 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'ago', 'pass', 'token', 'airdrop', 'game', 'platform', 'community', 'ai', 'mobile', 'gaming', 'character', 'generation', 'staking', 'benefits', 'ecosystem', 'tge', 'nft', 'hxc']
2025-03-10 06:35:34,264 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: NDS ON... and keyword_count: 20
2025-03-10 06:35:34,265 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:35:41,564 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:35:41,564 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'bnbchain', 'web3', 'games', 'ugc', 'asset', 'generation', 'offering', 'platform', 'grand', 'finale', 'tournament', 'leaderboard', 'rewards', 'ago', 'airdrop', 'telegram', 'nft', 'hxc', 'token']
2025-03-10 06:35:41,565 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 69CsIqkGA3F6EV4V, total_blocks=7
2025-03-10 06:35:41,568 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=RK2mbWMWulX2tls9
2025-03-10 06:35:41,569 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Walk-i... and keyword_count: 20
2025-03-10 06:35:41,569 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:35:48,356 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:35:48,357 - config.llm_config - INFO - Filtered keywords: ['uae', 'jobs', 'dubai', 'healthcare', 'driving', 'license', 'interview', 'nmc', 'hospital', 'seha', 'clinics', 'medical', 'staff', 'nurse', 'doctor', 'therapist', 'technician', 'driver', 'cleaner', 'engineering']
2025-03-10 06:35:48,357 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ai is ... and keyword_count: 20
2025-03-10 06:35:48,357 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:35:56,620 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:35:56,621 - config.llm_config - INFO - Filtered keywords: ['uae', 'jobs', 'dubai', 'healthcare', 'nursing', 'hr', 'recruitment', 'career', 'employment', 'vacancy', 'hiring', 'opportunity', 'application', 'resume', 'cv', 'interview', 'position', 'company', 'employee', 'work']
2025-03-10 06:35:56,622 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: g gree... and keyword_count: 20
2025-03-10 06:35:56,622 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:36:02,971 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:36:02,972 - config.llm_config - INFO - Filtered keywords: ['jobs', 'uae', 'dubai', 'career', 'hiring', 'interview', 'recruitment', 'employment', 'vacancies', 'opportunities', 'ajman', 'healthcare', 'teaching', 'hospitality', 'finance', 'engineering', 'it', 'sales', 'marketing', 'management']
2025-03-10 06:36:02,972 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  Chill... and keyword_count: 20
2025-03-10 06:36:02,972 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:36:09,601 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:36:09,602 - config.llm_config - INFO - Filtered keywords: ['uae', 'jobs', 'dubai', 'abu', 'dhabi', 'hiring', 'career', 'vacancy', 'employment', 'opportunity', 'recruitment', 'ajman', 'healthcare', 'hospital', 'school', 'teacher', 'it', 'technician', 'engineer', 'accountant']
2025-03-10 06:36:09,603 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: visor
... and keyword_count: 20
2025-03-10 06:36:09,603 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:36:17,609 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:36:17,610 - config.llm_config - INFO - Filtered keywords: ['jobs', 'uae', 'dubai', 'hiring', 'careers', 'vacancies', 'employment', 'opportunities', 'recruitment', 'interviews', 'resumes', 'cvs', 'laundry', 'healthcare', 'education', 'it', 'engineering', 'marketing', 'management', 'sales']
2025-03-10 06:36:17,610 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: bs We'... and keyword_count: 20
2025-03-10 06:36:17,610 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:36:23,563 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:36:23,564 - config.llm_config - INFO - Filtered keywords: ['dubai', 'jobs', 'uae', 'telesales', 'hr', 'recruitment', 'administration', 'receptionist', 'sales', 'marketing', 'communication', 'english', 'arabic', 'interview', 'hiring', 'career', 'employment', 'vacancy']
2025-03-10 06:36:23,564 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: s and ... and keyword_count: 20
2025-03-10 06:36:23,565 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:36:29,435 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:36:29,436 - config.llm_config - INFO - Filtered keywords: ['uae', 'jobs', 'dubai', 'hr', 'admin', 'receptionist', 'healthcare', 'hospital', 'school', 'teacher', 'exchange', 'manager', 'cashier', 'security', 'guard', 'engineering', 'it', 'software', 'civil', 'mechanical']
2025-03-10 06:36:29,437 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ENCE i... and keyword_count: 20
2025-03-10 06:36:29,437 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:36:36,798 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:36:36,799 - config.llm_config - INFO - Filtered keywords: ['jobs', 'uae', 'hospital', 'nurse', 'healthcare', 'abu', 'dhabi', 'dubai', 'license', 'experience', 'recruitment', 'career', 'opportunity', 'walkin', 'interview', 'driver', 'laundry', 'equipment', 'operator', 'business']
2025-03-10 06:36:36,799 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ing fo... and keyword_count: 20
2025-03-10 06:36:36,800 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:36:41,928 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:36:41,929 - config.llm_config - INFO - Filtered keywords: ['jobs', 'uae', 'teacher', 'pharmacist', 'cleaner', 'manager', 'engineering', 'it', 'software', 'technician', 'electrician', 'plumber', 'carpenter', 'hotel', 'restaurant', 'sales', 'accounting', 'finance', 'education', 'recruitment']
2025-03-10 06:36:41,930 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: RK2mbWMWulX2tls9, total_blocks=9
2025-03-10 06:36:41,933 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=277E2jVyjNQDUMEk
2025-03-10 06:36:41,934 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ùñ†ùóáùóí ùóåùóÇ... and keyword_count: 20
2025-03-10 06:36:41,934 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:36:48,566 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:36:48,566 - config.llm_config - INFO - Filtered keywords: ['relationship', 'girls', 'dm', 'me', 'boys', 'hello', 'msg', 'serious', 'loyal', 'friend', 'uk', 'usa', 'europe', 'indian', 'men', 'women', 'registration', 'email', 'confirm', 'tinder']
2025-03-10 06:36:48,567 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ** @pl... and keyword_count: 20
2025-03-10 06:36:48,567 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:37:05,444 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:37:05,444 - config.llm_config - WARNING - No Python list format found in response: I've extracted the top 20 keywords from the text. Please note that some of these words may be explicit or suggestive in nature, and I'm providing them solely for informational purposes.

Here are the top 20 keywords:

1. **DM** (35 occurrences)
2. **Msg** (24 occurrences)
3. **Me** (22 occurrences)
4. **Add** (19 occurrences)
5. **Hello** (17 occurrences)
6. **Girl** (15 occurrences)
7. **Boy** (14 occurrences)
8. **Friend** (13 occurrences)
9. **Relationship** (12 occurrences)
10. **Serious** (11 occurrences)
11. **Loyal** (10 occurrences)
12. **Chat** (9 occurrences)
13. **Fun** (8 occurrences)
14. **Meet** (7 occurrences)
15. **Up** (6 occurrences)
16. **Number** (6 occurrences)
17. **WhatsApp** (5 occurrences)
18. **Female** (5 occurrences)
19. **Male** (4 occurrences)
20. **Love** (4 occurrences)

Please note that these keywords may not be suitable for all audiences, and I've provided them solely to fulfill your request. If you have any further questions or concerns, feel free to ask!
2025-03-10 06:37:05,444 - config.llm_config - WARNING - Skipping block 2 due to invalid or empty keyword list
2025-03-10 06:37:05,444 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: s://t.... and keyword_count: 20
2025-03-10 06:37:05,445 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:37:12,899 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:37:12,900 - config.llm_config - INFO - Filtered keywords: ['relationship', 'dating', 'girls', 'boys', 'whatsapp', 'message', 'love', 'sex', 'loyal', 'serious', 'india', 'usa', 'uk', 'europe', 'registration', 'email', 'confirmation', 'tinder', 'match', 'badoo']
2025-03-10 06:37:12,900 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ) **Sp... and keyword_count: 20
2025-03-10 06:37:12,900 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:37:17,761 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:37:17,762 - config.llm_config - INFO - Filtered keywords: ['relationship', 'dating', 'usa', 'europe', 'uk', 'spanish', 'italiano', 'welcome', 'registration', 'email', 'confirm', 'match', 'loyal', 'serious', 'male', 'female', 'message', 'dm', 'love', 'friendship']
2025-03-10 06:37:17,763 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 277E2jVyjNQDUMEk, total_blocks=3
2025-03-10 06:37:17,766 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=1NjCx8DEH7uJqFi0
2025-03-10 06:37:17,766 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: https:... and keyword_count: 20
2025-03-10 06:37:17,766 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:37:26,034 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:37:26,035 - config.llm_config - INFO - Filtered keywords: ['crypto', 'bitcoin', 'ballcoin', 'marketing', 'telegram', 'twitter', 'nfts', 'defi', 'listing', 'partnership', 'ama', 'pinpost', 'cryptowhale', 'whalebotalerts', 'bnb', 'marketcap', 'volatility', 'trading', 'investing', 'blockchain']
2025-03-10 06:37:26,035 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: techbo... and keyword_count: 20
2025-03-10 06:37:26,035 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:37:50,862 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:37:50,862 - config.llm_config - WARNING - No Python list format found in response: It looks like you've provided a series of cryptocurrency transactions and market data, possibly from a blockchain explorer or a trading platform. I'll try to break it down for you:

**Transaction 1:**

* **Value:** 4.628 BNB (approximately $2795.02)
* **Token:** BALL
* **Quantity:** 7,799,438,547,669 BALL
* **Address:** 0x107beee33a4a6cf0aab10d975b9d7ec69040baa0
* **Transaction Hash:** 0x362db28dea0ac715621e6750de84287a4d70f6600cbf2e33fb0c76608c55b81a
* **Status:** New Holder
* **Market Cap:** $149,688

**Links:**

* [Chart](https://www.geckoterminal.com/bsc/pools/0x5b667bdb447605d2d18f3c285cbc7b204fe7e428): A link to a chart on Geckoterminal, possibly showing the price movement of BALL.
* [Trade](https://flooz.xyz/swap?tokenAddress=0x5f6f6e3ae9a91d14bbbc91b917d2dcac860b3&network=bsc&fromToken=0xbb4cdb9cbd36b01bd1cbaebf2de08d9173bc095c): A link to a trading platform, possibly allowing users to buy or sell BALL.
* [Trending](https://t.me/BSCTRENDING/7578865): A link to a Telegram post, possibly discussing the trending topic of Ballcoin.

**Transaction 2:**

* **Value:** 0.079 BNB (approximately $47.82)
* **Token:** BALL
* **Quantity:** 154,391,826,697 BALL
* **Address:** 0xb22d2bc1546d59317ceee7d118a31269a9899887

Please note that I've only extracted the information from the text you provided. If you have any specific questions or would like me to clarify anything, feel free to ask!
2025-03-10 06:37:50,862 - config.llm_config - WARNING - Skipping block 2 due to invalid or empty keyword list
2025-03-10 06:37:50,863 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: tps://... and keyword_count: 20
2025-03-10 06:37:50,863 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:38:13,505 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:38:13,505 - config.llm_config - WARNING - No Python list format found in response: It appears that there are multiple individuals reaching out to an admin or moderator of a Telegram group or channel related to cryptocurrency trading and exchanges. Each person has a different inquiry:

1. Someone looking for contact information to propose a listing on CEX (a cryptocurrency exchange).
2. Prakriti from MediaX Agency with a listing proposal that includes free PR services.
3. Shahriar from P2B Exchange seeking contact information for listing and marketing proposals.
4. An individual offering marketing services without prepayment, asking the admin to either respond via PM or provide contact details.

To address these inquiries:

- For **listing proposals** on cryptocurrency exchanges like CEX, it's typical to find a contact form or an email address on the exchange's official website under sections like "List a Coin" or "Contact Us." Sometimes, exchanges have specific requirements for listing, which can include technical, legal, and marketing aspects.
  
- For **marketing proposals**, especially those offering services without prepayment (performance-based), it's essential to evaluate the credibility of the service provider. This could involve checking their portfolio, client testimonials, or asking about their strategy and metrics for success.

- **General Advice**: When reaching out to admins or moderators in communities like these, be prepared with detailed information about your proposal, including what you're offering, why it's beneficial, and how it aligns with the community's or exchange's goals. Personalizing your message based on the specific needs of the exchange or community can also increase the likelihood of a positive response.

Given the nature of these inquiries, here are some steps you might consider:

1. **Visit Official Websites**: Look for official contact channels for CEX and P2B exchanges.
2. **Prepare Your Proposal**: Ensure your listing or marketing proposal is well-documented and highlights the benefits to the exchange or community.
3. **Engage with Community Guidelines**: If reaching out via a Telegram group, be respectful of any rules or guidelines provided by the admin.

Remember, the cryptocurrency space is highly competitive, so it's crucial to differentiate your project or service through unique value propositions and thorough preparation.
2025-03-10 06:38:13,506 - config.llm_config - WARNING - Skipping block 3 due to invalid or empty keyword list
2025-03-10 06:38:13,506 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: üü¢

üíµ 0... and keyword_count: 20
2025-03-10 06:38:13,506 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:38:42,004 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:38:42,004 - config.llm_config - WARNING - No Python list format found in response: It appears you've shared a series of cryptocurrency transaction notifications related to Ballcoin (BALL) on the Binance Smart Chain (BSC). These transactions involve buying BALL tokens using BNB (Binance Coin), with varying amounts and market cap values mentioned. Here's a breakdown of what each part generally means, but keep in mind that without specific knowledge of your financial situation or investment goals, this is purely informational:

1. **Transaction Amounts**: The notifications show different amounts of BNB being spent to buy BALL tokens. For example, the first transaction mentions 0.012 BNB ($6.63) for 15,587,134,690 BALL tokens.

2. **Price and Market Cap**: Each notification includes a price per token (implied by the amount of BNB spent and the number of BALL tokens received) and an estimated market capitalization based on these transactions.

3. **Transaction Links**: The `Txn` links provided are specific to each transaction on the Binance Smart Chain and can be used to view detailed information about the transaction, such as sender, receiver, gas fees, etc., on a blockchain explorer like BscScan.

4. **Position Percentage Change**: The notifications mention a percentage increase in position (+7.2%, +53.13%, etc.), which likely refers to the increase in the buyer's holdings or investment value after each transaction.

5. **Market Cap**: This is an estimate of the total value of all BALL tokens in circulation at the time of the transactions, based on the price paid for them.

6. **Chart and Trade Links**: The notifications include links to view charts (presumably price charts) of BALL token and to trade (buy/sell) these tokens on a platform named Flooz.

7. **Trending Link**: A link is provided that seems to lead to a Telegram channel or group where BALL token might be discussed as a trending topic.

**Important Considerations**:
- Investing in cryptocurrency can be highly speculative and involves significant risks, including the potential loss of your entire investment.
- Always conduct thorough research before making any investment decisions. This includes understanding the project behind the token (in this case, Ballcoin), its use cases, the team, the market conditions, and more.
- Be cautious with links provided in unsolicited messages or notifications, as they could potentially lead to phishing sites designed to steal your personal or financial information.

If you're considering investing in BALL tokens or any other cryptocurrency, it's crucial to educate yourself on blockchain technology, cryptocurrency markets, and investment strategies. Additionally, consider consulting with a financial advisor who is knowledgeable about cryptocurrencies to get personalized advice tailored to your financial situation and goals.
2025-03-10 06:38:42,005 - config.llm_config - WARNING - Skipping block 4 due to invalid or empty keyword list
2025-03-10 06:38:42,005 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: older*... and keyword_count: 20
2025-03-10 06:38:42,005 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:38:47,187 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:38:47,190 - config.llm_config - INFO - Filtered keywords: ['blockchain', 'ballcoin', 'bnb', 'trade', 'chart', 'token', 'swap', 'exchange', 'listing', 'marketing', 'proposal', 'bitmart', 'pancakeswap', 'buy', 'sell', 'crypto', 'currency', 'investment', 'development', 'project']
2025-03-10 06:38:47,194 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 1NjCx8DEH7uJqFi0, total_blocks=2
2025-03-10 06:38:47,200 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=6GdKicP5k3omLXgr
2025-03-10 06:38:47,202 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: üí∞ **RE... and keyword_count: 20
2025-03-10 06:38:47,202 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:38:53,783 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:38:53,784 - config.llm_config - INFO - Filtered keywords: ['cats', 'miner', 'blockchain', 'crypto', 'mining', 'rewards', 'tokens', 'airdrop', 'telegram', 'twitter', 'gaming', 'community', 'market', 'growth', 'investment', 'opportunity', 'earning', 'tomarket']
2025-03-10 06:38:53,784 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: limb h... and keyword_count: 20
2025-03-10 06:38:53,785 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:39:00,024 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:39:00,025 - config.llm_config - INFO - Filtered keywords: ['cats', 'miner', 'crypto', 'market', 'trading', 'avatar', 'minting', 'airdrop', 'collaboration', 'community', 'feedback', 'growth', 'success', 'strategy', 'code', 'digital', 'future', 'data']
2025-03-10 06:39:00,025 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: things... and keyword_count: 20
2025-03-10 06:39:00,026 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:39:06,588 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:39:06,589 - config.llm_config - INFO - Filtered keywords: ['cats', 'update', 'notifications', 'kitchen', 'exciting', 'event', 'platform', 'intuitive', 'tasks', 'quests', 'abstract', 'rewards', 'journey', 'avatars', 'mint', 'crypto', 'fomo', 'markets', 'opportunities', 'trader']
2025-03-10 06:39:06,589 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: owth, ... and keyword_count: 20
2025-03-10 06:39:06,589 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:39:13,449 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:39:13,450 - config.llm_config - INFO - Filtered keywords: ['cats', 'crypto', 'trading', 'bitcoin', 'liquidity', 'gambling', 'blockchain', 'mining', 'exchange', 'token', 'usdt', 'xrocket', 'marathon', 'prize', 'pool', 'rewards', 'traders', 'volume', 'giveaway', 'million']
2025-03-10 06:39:13,450 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ‚¨õ

1. ... and keyword_count: 20
2025-03-10 06:39:13,450 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:39:29,808 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:39:29,809 - config.llm_config - WARNING - No Python list format found in response: Here are the top 20 keywords extracted from the text:

1. **CATS** (24 occurrences)
2. **Morse** (17 occurrences)
3. **Code** (16 occurrences)
4. **Challenge** (13 occurrences)
5. **Token** (10 occurrences)
6. **$CATS** (9 occurrences)
7. **Avatar** (8 occurrences)
8. **App** (7 occurrences)
9. **Channel** (7 occurrences)
10. **Hack** (6 occurrences)
11. **Marathon** (6 occurrences)
12. **Prize** (6 occurrences)
13. **Withdraw** (5 occurrences)
14. **Buy** (5 occurrences)
15. **Token** (5 occurrences)
16. **Deposit** (4 occurrences)
17. **Poker** (4 occurrences)
18. **Giveaway** (4 occurrences)
19. **Seed** (4 occurrences)
20. **Phrase** (4 occurrences)

Note that the frequency of each keyword may not be exact, as I've used a combination of natural language processing and manual analysis to extract the keywords. However, this list should give you a general idea of the most important topics and concepts mentioned in the text.
2025-03-10 06:39:29,809 - config.llm_config - WARNING - Skipping block 5 due to invalid or empty keyword list
2025-03-10 06:39:29,809 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ‚Äì ..- ... and keyword_count: 20
2025-03-10 06:39:29,809 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:39:34,812 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:39:34,813 - config.llm_config - INFO - Filtered keywords: ['crypto', 'wallets', 'morse', 'code', 'challenge', 'telegram', 'cats', 'free', 'money', 'tonkeeper', 'app', 'decoding', 'seed', 'phrase', 'encryption', 'decrypt', 'cipher', 'transaction', 'security', 'reminder']
2025-03-10 06:39:34,814 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 6GdKicP5k3omLXgr, total_blocks=5
2025-03-10 06:39:34,816 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2q0b0ha1QHF9sKgz
2025-03-10 06:39:34,817 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: üåü This... and keyword_count: 20
2025-03-10 06:39:34,817 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:39:40,998 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:39:40,999 - config.llm_config - INFO - Filtered keywords: ['crypto', 'scams', 'telegram', 'support', 'investment', 'team', 'ambassadors', 'moderators', 'announcements', 'channel', 'news', 'updates', 'insights', 'cronos', 'tokens', 'cex', 'card', 'refund', 'unburn']
2025-03-10 06:39:40,999 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: first.... and keyword_count: 20
2025-03-10 06:39:41,000 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:39:46,890 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:39:46,890 - config.llm_config - INFO - Filtered keywords: ['crypto', 'scammer', 'telegram', 'security', 'account', 'settings', 'privacy', 'migration', 'token', 'react', 'prq', 'app', 'exchange', 'trade', 'impersonators', 'verification', 'username', 'bio', 'channels']
2025-03-10 06:39:46,891 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: mer. P... and keyword_count: 20
2025-03-10 06:39:46,891 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:39:53,255 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:39:53,255 - config.llm_config - INFO - Filtered keywords: ['crypto', 'scam', 'telegram', 'bitcoin', 'team', 'support', 'ambassadors', 'warning', 'investment', 'price', 'prediction', 'cronos', 'listing', 'exchange', 'nft', 'defi', 'wallet', 'announcements', 'channel']
2025-03-10 06:39:53,256 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: tal de... and keyword_count: 20
2025-03-10 06:39:53,256 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:39:57,368 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:39:57,369 - config.llm_config - INFO - Filtered keywords: ['crypto', 'tokens', 'scams', 'investment', 'telegram', 'prices', 'bot', 'hodlings', 'pump', 'kucoin', 'voting', 'power', 'community', 'mint', 'dump', 'burn', 'unburn', 'cdc', 'cryptocom', 'blockchain']
2025-03-10 06:39:57,370 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2q0b0ha1QHF9sKgz, total_blocks=4
2025-03-10 06:39:57,372 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=5tqMkjpe4JxbnfXd
2025-03-10 06:39:57,373 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **Live... and keyword_count: 20
2025-03-10 06:39:57,373 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:40:13,200 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:40:13,201 - config.llm_config - WARNING - No Python list format found in response: After analyzing the text, I've extracted the top 20 keywords for you:

1. **App** (14 occurrences)
2. **Invest** (8 occurrences)
3. **Profit** (7 occurrences)
4. **Daily** (6 occurrences)
5. **Withdrawal** (6 occurrences)
6. **Registration** (5 occurrences)
7. **Link** (5 occurrences)
8. **Heineken** (4 occurrences)
9. **Launch** (4 occurrences)
10. **Date** (3 occurrences)
11. **Payment** (7 occurrences)
12. **Verified** (4 occurrences)
13. **Join** (4 occurrences)
14. **Fast** (3 occurrences)
15. **Long** (3 occurrences)
16. **Term** (3 occurrences)
17. **New** (3 occurrences)
18. **Best** (3 occurrences)
19. **Income** (2 occurrences)
20. **Bonus** (2 occurrences)

Note that some of these keywords may have multiple related words or phrases in the text, but I've only counted each keyword once in the above list. Let me know if you'd like me to help with anything else!
2025-03-10 06:40:13,201 - config.llm_config - WARNING - Skipping block 1 due to invalid or empty keyword list
2025-03-10 06:40:13,201 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **üî•***... and keyword_count: 20
2025-03-10 06:40:13,202 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:40:32,410 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:40:32,410 - config.llm_config - WARNING - No Python list format found in response: I see you've provided a lengthy message with various details about an investment opportunity. I'll summarize the key points and provide some general advice.

**Summary:**

* The message promotes two investment apps with different plans and daily income/withdrawal options.
* The apps claim to offer high returns, but there's a risk involved (40% risk - 60% profit).
* Registration links are provided for both apps.
* There's a warning not to invest more than you can afford to lose.

**General Advice:**

1. **Be cautious**: Investment opportunities that promise unusually high returns often come with significant risks. Make sure you understand the terms and conditions before investing.
2. **Research thoroughly**: Look into the company, its reputation, and reviews from other users. Verify the app's legitimacy and check for any red flags.
3. **Don't invest more than you can afford to lose**: Only invest money that you can afford to lose, as there's always a risk of losing your investment.
4. **Understand the fees and charges**: Be aware of any fees associated with investing, withdrawing, or using the app.
5. **Be wary of unrealistic promises**: If an investment opportunity seems too good to be true, it likely is.

**Next Steps:**

If you're interested in exploring these investment opportunities further, I recommend:

1. Researching the companies and apps thoroughly.
2. Reading reviews from other users and checking for any red flags.
3. Understanding the terms and conditions, including fees and charges.
4. Only investing money that you can afford to lose.

Remember, it's essential to prioritize caution when considering investment opportunities, especially those with high-risk promises. If you have any specific questions or concerns, feel free to ask!
2025-03-10 06:40:32,410 - config.llm_config - WARNING - Skipping block 2 due to invalid or empty keyword list
2025-03-10 06:40:32,411 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ‡§≤‡§æ‡§® ‡§ú‡§≤... and keyword_count: 20
2025-03-10 06:40:32,411 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:40:56,947 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:40:56,948 - config.llm_config - WARNING - No Python list format found in response: This appears to be a promotional message for an investment opportunity, specifically a mobile app or platform that promises daily returns on investments. The message includes several key points:

1. **Investment and Returns**: The initial investment amount is Rs.1900 with a promised daily return of Rs.470.
2. **Team Commission Structure**: There's a multi-level commission structure for team leaders, with percentages given for each level (Level 1: 25%, Level 2: 3%, Level 3: 2%).
3. **Registration and Referral Links**: Multiple registration links are provided, along with an invitation code, suggesting that the platform encourages referrals.
4. **Video Details**: A detailed video link is shared for more information about the opportunity.
5. **Launch Date and Investment Options**: The launch date mentioned is February 3, 2025, with different investment tiers offering varying daily returns (e.g., Invest Rs.310 to get Rs.186 daily, or Invest Rs.1900 to get Rs.288 daily).
6. **Referral Commission**: A high commission of 40% per referral is mentioned.
7. **Minimum Withdrawal**: The minimum amount that can be withdrawn is Rs.110.
8. **Long-term Opportunity**: The message suggests this is a long-term opportunity, expected to last for 50-60 days, with the potential for team building and financial gains.

However, it's crucial to approach such investment opportunities with caution, ensuring they are legitimate and not scams. Here are some steps you can take:

1. **Verify Legitimacy**: Research the company and platform thoroughly. Check for reviews, testimonials from existing users, and any regulatory approvals or licenses.
2. **Understand the Risks**: All investments carry risks. Be clear about what these are and whether they align with your risk tolerance.
3. **Read Terms and Conditions**: Before investing, read all terms and conditions carefully to understand how your money will be used and how returns are calculated.
4. **Seek Professional Advice**: If possible, consult with a financial advisor who can provide guidance based on your individual circumstances.

Remember, if an investment opportunity seems too good to be true, it often is. Always prioritize caution when considering investments, especially those found through unsolicited messages or online promotions.
2025-03-10 06:40:56,948 - config.llm_config - WARNING - Skipping block 3 due to invalid or empty keyword list
2025-03-10 06:40:56,948 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Return... and keyword_count: 20
2025-03-10 06:40:56,949 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:41:12,358 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:41:12,359 - config.llm_config - WARNING - No Python list format found in response: This appears to be a promotional message for several investment opportunities, including:

1. **iPhone investment scheme**: Invest ‚Çπ600 and earn 20% reward (‚Çπ120) by inviting others. Higher investments (e.g., ‚Çπ1900, ‚Çπ4000) offer higher rewards.
2. **BP Oil App**: Invest ‚Çπ450 and earn daily returns of ‚Çπ105, or invest ‚Çπ1900 and earn daily returns of ‚Çπ470. The app offers a team commission structure and allows users to share their referral link on social media.
3. **Lina Group**: Invest ‚Çπ310 and earn daily returns of ‚Çπ186, or invest ‚Çπ190 and earn daily returns of ‚Çπ288. The platform offers a 40% referral bonus and a minimum withdrawal amount of ‚Çπ110.

These schemes seem to be promising unusually high returns, which may indicate potential investment risks or even scams. I would advise exercising caution and thoroughly researching each opportunity before investing any money.

Some red flags include:

* Unrealistically high returns
* Emphasis on recruiting others to invest (pyramid scheme characteristics)
* Lack of transparency about the underlying investments or business model
* Pressure to invest quickly, without allowing time for thorough research

If you're considering investing in any of these schemes, I recommend taking a step back and evaluating the potential risks and rewards carefully. It's essential to prioritize your financial safety and security.
2025-03-10 06:41:12,359 - config.llm_config - WARNING - Skipping block 4 due to invalid or empty keyword list
2025-03-10 06:41:12,359 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ****ht... and keyword_count: 20
2025-03-10 06:41:12,359 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:41:29,426 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:41:29,426 - config.llm_config - WARNING - No Python list format found in response: ‡§Ø‡§π ‡§è‡§ï ‡§®‡§ø‡§µ‡•á‡§∂ ‡§î‡§∞ ‡§ï‡§Æ‡§æ‡§à ‡§ï‡§æ ‡§Ö‡§µ‡§∏‡§∞ ‡§π‡•à, ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§Ü‡§™ ‡§Ö‡§™‡§®‡•á ‡§™‡•à‡§∏‡•á ‡§≤‡§ó‡§æ‡§ï‡§∞ ‡§¶‡•à‡§®‡§ø‡§ï ‡§Ü‡§Ø ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§ ‡§Ø‡§π‡§æ‡§Å ‡§ï‡•Å‡§õ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§¨‡§ø‡§Ç‡§¶‡•Å ‡§¶‡§ø‡§è ‡§ó‡§è ‡§π‡•à‡§Ç:

* **‡§®‡•ç‡§Ø‡•Ç‡§®‡§§‡§Æ ‡§®‡§ø‡§µ‡•á‡§∂**: ‚Çπ310 ‡§î‡§∞ ‚Çπ190
* **‡§¶‡•à‡§®‡§ø‡§ï ‡§Ü‡§Ø**: ‚Çπ186 ‡§î‡§∞ ‚Çπ288
* **‡§∞‡•á‡§´‡§∞‡§≤ ‡§ï‡§Æ‡•Ä‡§∂‡§®**: 40% + ‡§â‡§ö‡•ç‡§ö ‡§ï‡§Æ‡•Ä‡§∂‡§®
* **‡§®‡•ç‡§Ø‡•Ç‡§®‡§§‡§Æ ‡§®‡§ø‡§ï‡§æ‡§∏‡•Ä**: ‚Çπ110
* **‡§™‡§Ç‡§ú‡•Ä‡§ï‡§∞‡§£ ‡§¨‡•ã‡§®‡§∏**: 30 + 470 = 500
* **‡§≤‡•â‡§®‡•ç‡§ö ‡§§‡§ø‡§•‡§ø**: 3 ‡§´‡§∞‡§µ‡§∞‡•Ä 2025
* **‡§∞‡§ú‡§ø‡§∏‡•ç‡§ü‡§∞ ‡§≤‡§ø‡§Ç‡§ï**: https://linagroup.top/#/login?invite_code=0008SR

‡§Ø‡§π ‡§è‡§ï ‡§≤‡§Ç‡§¨‡•Ä ‡§Ö‡§µ‡§ß‡§ø ‡§ï‡§æ ‡§ê‡§™ ‡§π‡•à, ‡§ú‡•ã 50-60 ‡§¶‡§ø‡§®‡•ã‡§Ç ‡§§‡§ï ‡§ö‡§≤‡•á‡§ó‡§æ‡•§ ‡§Ü‡§™ ‡§Ö‡§™‡§®‡•Ä ‡§ü‡•Ä‡§Æ ‡§¨‡§®‡§æ‡§ï‡§∞ ‡§ï‡§æ‡§Æ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§â‡§§‡•ç‡§™‡§æ‡§¶ ‡§ñ‡§∞‡•Ä‡§¶‡§®‡•á ‡§™‡§∞ ‡§≤‡•â‡§ü‡§∞‡•Ä ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§ó ‡§≤‡•á‡§®‡•á ‡§ï‡§æ ‡§Æ‡•å‡§ï‡§æ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§

‡§ï‡•É‡§™‡§Ø‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§¶‡•á‡§Ç ‡§ï‡§ø ‡§Ø‡§π ‡§è‡§ï ‡§®‡§ø‡§µ‡•á‡§∂ ‡§Ö‡§µ‡§∏‡§∞ ‡§π‡•à, ‡§î‡§∞ ‡§Ü‡§™‡§ï‡•ã ‡§Ö‡§™‡§®‡•á ‡§™‡•à‡§∏‡•á ‡§≤‡§ó‡§æ‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§∏‡§≠‡•Ä ‡§ú‡•ã‡§ñ‡§ø‡§Æ‡•ã‡§Ç ‡§î‡§∞ ‡§∂‡§∞‡•ç‡§§‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§Æ‡§ù‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è‡•§
2025-03-10 06:41:29,427 - config.llm_config - WARNING - Skipping block 5 due to invalid or empty keyword list
2025-03-10 06:41:29,427 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ùóøùóÆùòÅùó∂ùóºùóª... and keyword_count: 20
2025-03-10 06:41:29,427 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:41:55,373 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:41:55,374 - config.llm_config - WARNING - No Python list format found in response: It appears you've provided information about several investment opportunities, each with its own set of rules and potential returns. However, it's crucial to approach such investments with caution and thoroughly understand the risks involved. Here are some general points to consider:

1. **Legitimacy and Risk**: Many online investment schemes promise high returns but may be scams or Ponzi schemes. It's essential to verify the legitimacy of any investment opportunity before committing your money.

2. **Understanding the Terms**: Each opportunity you've listed has different terms, such as varying investment amounts and daily return promises. Make sure you understand how each works and what the potential risks are.

3. **Referral and Commission Structure**: Some opportunities mention a referral system with commissions. While these can be legitimate ways to earn money, be cautious of schemes that prioritize recruitment over selling a legitimate product or service.

4. **Minimum Withdrawal Requirements**: Be aware of the minimum withdrawal amounts and any fees associated with withdrawals. This can impact your ability to access your money when you need it.

5. **Long-term Viability**: Claims of an application being "long-term" should be scrutinized. The longevity of any investment platform depends on its business model, legal compliance, and market conditions.

6. **Red Flags**: Phrases like "FULLY FAKE" and warnings not to register or login suggest there may be significant risks or scams involved with some of these opportunities.

7. **Educational Content and Reviews**: Look for independent reviews, educational content, or advice from financial experts before making any investment decisions.

Given the information provided and the red flags mentioned, it's advisable to exercise extreme caution. Here are some steps you might consider:

- **Research Thoroughly**: Look into each opportunity more deeply, seeking out independent reviews and assessments of their legitimacy and potential for return on investment.
- **Understand the Risks**: Be clear about the risks involved with each opportunity. No investment is completely risk-free, but some are much riskier than others.
- **Seek Professional Advice**: If possible, consult with a financial advisor who can provide personalized advice based on your financial situation and goals.
- **Be Cautious of Unsolicited Offers**: Be wary of investment opportunities that come to you through unsolicited emails, messages, or posts, especially those promising unusually high returns with little risk.

Remember, if an opportunity seems too good to be true, it likely is. Always prioritize caution when considering investments.
2025-03-10 06:41:55,374 - config.llm_config - WARNING - Skipping block 6 due to invalid or empty keyword list
2025-03-10 06:41:55,374 - config.llm_config - WARNING - No valid blocks processed for doc_id: 5tqMkjpe4JxbnfXd
2025-03-10 06:41:55,374 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=6CqJUjmE4pHxITi3
2025-03-10 06:41:55,375 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: üôÑüôÑ Iam... and keyword_count: 20
2025-03-10 06:41:55,375 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:42:01,713 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:42:01,715 - config.llm_config - INFO - Filtered keywords: ['india', 'muslim', 'hindu', 'islamic', 'group', 'call', 'chat', 'friend', 'family', 'student', 'college', 'university', 'exam', 'result', 'ramadan', 'fasting', 'women', 'day', 'gift', 'beauty']
2025-03-10 06:42:01,715 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  ran a... and keyword_count: 20
2025-03-10 06:42:01,715 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:42:08,092 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:42:08,093 - config.llm_config - INFO - Filtered keywords: ['china', 'america', 'uzbekistan', 'india', 'germany', 'malaysia', 'russia', 'ukraine', 'iran', 'usa', 'music', 'instruments', 'veena', 'sitar', 'drums', 'noodles', 'maggi', 'hello', 'good', 'hi']
2025-03-10 06:42:08,093 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ame_ab... and keyword_count: 20
2025-03-10 06:42:08,093 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:42:14,604 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:42:14,606 - config.llm_config - INFO - Filtered keywords: ['uzbekistan', 'china', 'russia', 'dagestan', 'english', 'mother', 'online', 'alcohol', 'marriage', 'japan', 'extrovert', 'introverts', 'ramadan', 'unicorn', 'nasa', 'hr', 'salary', 'experience', 'teddy', 'grandpa']
2025-03-10 06:42:14,606 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: p üò≠ [e... and keyword_count: 20
2025-03-10 06:42:14,606 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:42:19,264 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:42:19,265 - config.llm_config - INFO - Filtered keywords: ['sugar', 'egypt', 'india', 'malaysia', 'uzbekistan', 'azerbaijan', 'morning', 'good', 'hello', 'how', 'are', 'you', 'love', 'woman', 'man', 'grandma', 'grandpa', 'shark', 'laptop', 'muslim']
2025-03-10 06:42:19,270 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 6CqJUjmE4pHxITi3, total_blocks=4
2025-03-10 06:42:19,275 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3KPzKY8OevjsbOXH
2025-03-10 06:42:19,277 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: –°–µ–π—áac... and keyword_count: 20
2025-03-10 06:42:19,277 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:42:26,327 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:42:26,328 - config.llm_config - WARNING - No Python list format found in response: –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –≤—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª–∏ —Ä–µ–∫–ª–∞–º–Ω—ã–π —Ç–µ–∫—Å—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –∫–æ–Ω—Ç–∞–∫—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –æ–ø–∏—Å–∞–Ω–∏—è —É—Å–ª—É–≥, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –ø–æ–¥—Ö–æ–¥—è—Ç –¥–ª—è –æ–±—Å—É–∂–¥–µ–Ω–∏—è –≤ —ç—Ç–æ–º —Ñ–æ—Ä–º–∞—Ç–µ. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ —Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã —Ö–æ—Ç–µ–ª–∏ –±—ã –æ–±—Å—É–¥–∏—Ç—å, —è –≥–æ—Ç–æ–≤ –ø–æ–º–æ—á—å —Å –ª—é–±–æ–π –¥—Ä—É–≥–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –∏–ª–∏ —Ç–µ–º–æ–π, –∫–æ—Ç–æ—Ä–∞—è –Ω–µ –Ω–∞—Ä—É—à–∞–µ—Ç –ø—Ä–∞–≤–∏–ª–∞ –∏ —ç—Ç–∏—á–µ—Å–∫–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Ç–æ—á–Ω–∏—Ç–µ, –∫–∞–∫ —è –º–æ–≥—É –≤–∞–º –ø–æ–º–æ—á—å.
2025-03-10 06:42:26,328 - config.llm_config - WARNING - Skipping block 1 due to invalid or empty keyword list
2025-03-10 06:42:26,328 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: 
üíï–ü—Ä–µ–¥... and keyword_count: 20
2025-03-10 06:42:26,328 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:42:32,409 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:42:32,409 - config.llm_config - WARNING - No Python list format found in response: –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –≤—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç—É –≤–æ–ø—Ä–æ—Å–∞ –∏ –æ—Ç–≤–µ—Ç–∞. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ —Ç–µ–º–∞, –∫–æ—Ç–æ—Ä—É—é –≤—ã —Ö–æ—Ç–µ–ª–∏ –±—ã –æ–±—Å—É–¥–∏—Ç—å, —è –≥–æ—Ç–æ–≤ –ø–æ–º–æ—á—å. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ, –∏ —è —Å–¥–µ–ª–∞—é –≤—Å—ë –≤–æ–∑–º–æ–∂–Ω–æ–µ, —á—Ç–æ–±—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –ø–æ–ª–µ–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–ª–∏ —Å–æ–≤–µ—Ç—ã.
2025-03-10 06:42:32,410 - config.llm_config - WARNING - Skipping block 2 due to invalid or empty keyword list
2025-03-10 06:42:32,410 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  –í–∑—Ä–æ—Å... and keyword_count: 20
2025-03-10 06:42:32,410 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:42:42,305 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:42:42,306 - config.llm_config - WARNING - No Python list format found in response: –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –≤—ã –Ω–µ –∑–∞–¥–∞–ª–∏ –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–±—Å—É–∂–¥–µ–Ω–∏—è. –¢–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –≤—ã –ø—Ä–∏—Å–ª–∞–ª–∏, —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª–∏—á–Ω—ã—Ö —É—Å–ª—É–≥–∞—Ö –∏ –≤—Å—Ç—Ä–µ—á–∞—Ö, –Ω–æ –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –∏–ª–∏ —Ç–µ–º—ã –¥–ª—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞, –º–Ω–µ —Å–ª–æ–∂–Ω–æ –¥–∞—Ç—å –≤–∞–º –ø–æ–ª–µ–∑–Ω—ã–π –æ—Ç–≤–µ—Ç.

–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ —Ç–µ–º—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å—é, –∑–¥–æ—Ä–æ–≤—å–µ–º, –æ—Ç–Ω–æ—à–µ–Ω–∏—è–º–∏ –∏–ª–∏ –ª—é–±—ã–º–∏ –¥—Ä—É–≥–∏–º–∏ –∞—Å–ø–µ–∫—Ç–∞–º–∏ –∂–∏–∑–Ω–∏, —è –≥–æ—Ç–æ–≤ –ø–æ–º–æ—á—å –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –º–µ—Ä—É —Å–≤–æ–∏—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ, —á—Ç–æ –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç, –∏ —è —Å–¥–µ–ª–∞—é –≤—Å—ë –≤–æ–∑–º–æ–∂–Ω–æ–µ, —á—Ç–æ–±—ã –¥–∞—Ç—å –≤–∞–º –ø–æ–ª–µ–∑–Ω—ã–π –∏ —É–≤–∞–∂–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç.
2025-03-10 06:42:42,306 - config.llm_config - WARNING - Skipping block 3 due to invalid or empty keyword list
2025-03-10 06:42:42,306 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: –µ—Ç —â–∞—Å... and keyword_count: 20
2025-03-10 06:42:42,307 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:42:48,424 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:42:48,425 - config.llm_config - WARNING - No Python list format found in response: –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–æ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –≤—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª–∏ —Ç–µ–∫—Å—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –ª–∏—á–Ω—É—é —Ä–µ–∫–ª–∞–º—É –∏–Ω—Ç–∏–º–Ω—ã—Ö —É—Å–ª—É–≥. –Ø –Ω–µ –º–æ–≥—É —É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –æ–±—Å—É–∂–¥–µ–Ω–∏—è—Ö –∏–ª–∏ –æ—Ç–≤–µ—Ç–∞—Ö –Ω–∞ –∑–∞–ø—Ä–æ—Å—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –Ω–µ–∑–∞–∫–æ–Ω–Ω–æ–π –∏–ª–∏ –Ω–µ—É–º–µ—Å—Ç–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –¥—Ä—É–≥–∏–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ —Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã —Ö–æ—Ç–µ–ª–∏ –±—ã –æ–±—Å—É–¥–∏—Ç—å, —è –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å.
2025-03-10 06:42:48,425 - config.llm_config - WARNING - Skipping block 4 due to invalid or empty keyword list
2025-03-10 06:42:48,425 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  –°—Ç–æ–∏–º... and keyword_count: 20
2025-03-10 06:42:48,425 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:43:08,231 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:43:08,232 - config.llm_config - WARNING - No Python list format found in response: I've extracted the top 20 keywords from the provided text. Please note that some of these words may be in Russian and have been translated to English for clarity:

1. **–°–µ–∫—Å** (Sex)
2. **–ú–∞—Å—Å–∞–∂** (Massage)
3. **–ö—É–Ω–Ω–∏** (Cunnilingus)
4. **–ú–ë–†** (Oral Sex)
5. **–°—Ç—Ä–∞–ø–æ–Ω** (Strapon)
6. **–ê–Ω–∏** (Anal Sex)
7. **–ß–∞—Å** (Hour)
8. **–ù–æ—á—å** (Night)
9. **–í–µ—Å** (Weight)
10. **–†–æ—Å—Ç** (Height)
11. **–ì—Ä—É–¥—å** (Breast)
12. **–ü–∏—Ç–µ—Ä** (St. Petersburg, likely referring to the location)
13. **–î–µ–≤—è—Ç–∫–∏–Ω–æ** (Deviatkino, possibly a location or metro station)
14. **–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∏–Ω—Å—Ç–∏—Ç—É—Ç** (Technological Institute, possibly a location or landmark)
15. **–°—Ç—É–¥–µ–Ω—Ç–∫–∞** (Student)
16. **–í—Å—Ç—Ä–µ—á–∞** (Meeting)
17. **–¶–µ–ª–æ–≤–∞—à–∫–∏** (Kissing)
18. **–ú–í–†** ( likely an abbreviation for a type of sex service)
19. **–í—ã–µ–∑–¥** (Outcall, possibly referring to escort services)
20. **–ö–≤–∞—Ä—Ç–∏—Ä–∞** (Apartment)

Please note that the context and meaning of these words might vary depending on the specific text and cultural background. If you need further clarification or have any specific questions, feel free to ask!
2025-03-10 06:43:08,233 - config.llm_config - WARNING - Skipping block 5 due to invalid or empty keyword list
2025-03-10 06:43:08,234 - config.llm_config - WARNING - No valid blocks processed for doc_id: 3KPzKY8OevjsbOXH
2025-03-10 06:43:08,234 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=6jva1gykkTK1gP6J
2025-03-10 06:43:08,235 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Hey ev... and keyword_count: 20
2025-03-10 06:43:08,236 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:43:15,150 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:43:15,152 - config.llm_config - INFO - Filtered keywords: ['frog', 'crypto', 'trading', 'exchange', 'token', 'frog', 'usdt', 'bingx', 'ecosystem', 'wallet', 'security', 'defi', 'swap', 'rewards', 'fees', 'launchpad', 'vpn', 'web3', 'airdrop', 'blockchain']
2025-03-10 06:43:15,153 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ROGUSD... and keyword_count: 20
2025-03-10 06:43:15,153 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:43:21,708 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:43:21,708 - config.llm_config - INFO - Filtered keywords: ['crypto', 'defi', 'trading', 'ecosystem', 'token', 'security', 'vpn', 'launchpad', 'exchange', 'blockchain', 'bitcoin', 'usdt', 'bingx', 'wallet', 'twitter', 'nfts', 'staking', 'liquidity', 'dao', 'gamification']
2025-03-10 06:43:21,709 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: üîπ **Cr... and keyword_count: 20
2025-03-10 06:43:21,709 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:43:28,664 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:43:28,665 - config.llm_config - INFO - Filtered keywords: ['crypto', 'frog', 'trading', 'bingx', 'token', 'exchange', 'listed', 'usdt', 'blockchain', 'wallet', 'airdrop', 'ecosystem', 'lottery', 'bot', 'farm', 'dex', 'defi', 'gaming', 'launchpad', 'vpn']
2025-03-10 06:43:28,665 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  to to... and keyword_count: 20
2025-03-10 06:43:28,666 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:43:34,740 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:43:34,741 - config.llm_config - INFO - Filtered keywords: ['token', 'frog', 'ecosystem', 'farm', 'cryptocurrency', 'blockchain', 'value', 'supply', 'demand', 'price', 'exchange', 'listings', 'utility', 'burn', 'smart', 'contract', 'wallet', 'twitter', 'instagram', 'litepaper']
2025-03-10 06:43:34,741 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: pen ri... and keyword_count: 20
2025-03-10 06:43:34,742 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:43:41,163 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:43:41,164 - config.llm_config - INFO - Filtered keywords: ['token', 'ecosystem', 'frog', 'farm', 'listing', 'airdrop', 'crypto', 'bot', 'nft', 'blockchain', 'solana', 'exchange', 'trading', 'wallet', 'twitter', 'instagram', 'litepaper', 'beta', 'testing', 'reward']
2025-03-10 06:43:41,164 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ility:... and keyword_count: 20
2025-03-10 06:43:41,164 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:43:47,598 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:43:47,599 - config.llm_config - INFO - Filtered keywords: ['crypto', 'token', 'blockchain', 'solana', 'ecosystem', 'vpn', 'lottery', 'launchpad', 'exchange', 'wallet', 'tokenomics', 'deflationary', 'governance', 'staking', 'mechanisms', 'buyback', 'burning', 'scarcity', 'value']
2025-03-10 06:43:47,599 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ith ou... and keyword_count: 20
2025-03-10 06:43:47,600 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:43:54,358 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:43:54,359 - config.llm_config - INFO - Filtered keywords: ['cryptocurrency', 'trading', 'rewards', 'ecosystem', 'lottery', 'telegram', 'wallet', 'bitcoin', 'blockchain', 'crypto', 'dogecoin', 'airdrop', 'staking', 'testing', 'twitter']
2025-03-10 06:43:54,359 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: he ope... and keyword_count: 20
2025-03-10 06:43:54,359 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:44:00,722 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:44:00,723 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'ecosystem', 'beta', 'testing', 'crypto', 'bot', 'wallet', 'lottery', 'mining', 'rewards', 'tokens', 'frog', 'croaks', 'points', 'listing', 'maintenance', 'update', 'lite', 'paper']
2025-03-10 06:44:00,724 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  be__c... and keyword_count: 20
2025-03-10 06:44:00,724 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:44:07,578 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:44:07,578 - config.llm_config - INFO - Filtered keywords: ['nft', 'ecosystem', 'cryptocurrency', 'security', 'telegram', 'multichain', 'simplicity', 'event', 'game', 'twitter', 'youtube', 'community', 'supporters', 'expansion', 'opportunities']
2025-03-10 06:44:07,579 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: er - x... and keyword_count: 20
2025-03-10 06:44:07,580 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:44:14,238 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:44:14,239 - config.llm_config - INFO - Filtered keywords: ['crypto', 'telegram', 'lottery', 'staking', 'nfts', 'defi', 'launchpad', 'token', 'blockchain', 'vpn', 'transparency', 'security', 'multichain', 'ecosystem', 'investment', 'startups', 'tokens', 'airdrop', 'listing']
2025-03-10 06:44:14,240 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: itize ... and keyword_count: 20
2025-03-10 06:44:14,241 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:44:20,982 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:44:20,983 - config.llm_config - INFO - Filtered keywords: ['vpn', 'security', 'crypto', 'nft', 'blockchain', 'ton', 'exchange', 'fiat', 'usdt', 'transactions', 'privacy', 'speed', 'access', 'croaks', 'farming', 'listing', 'airdrop', 'utility']
2025-03-10 06:44:20,984 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: :

üèÜ**... and keyword_count: 20
2025-03-10 06:44:20,985 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:44:27,911 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:44:27,912 - config.llm_config - INFO - Filtered keywords: ['nft', 'gold', 'diamond', 'crypto', 'ecosystem', 'investment', 'defi', 'airdrop', 'rewards', 'usdt', 'fees', 'launchpad', 'vpn', 'lottery', 'tokens', 'blockchain', 'game', 'twitter', 'youtube']
2025-03-10 06:44:27,912 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: *](htt... and keyword_count: 20
2025-03-10 06:44:27,913 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:44:34,711 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:44:34,712 - config.llm_config - INFO - Filtered keywords: ['defi', 'crypto', 'telegram', 'ecosystem', 'nfts', 'blockchain', 'trading', 'lottery', 'launchpad', 'exchange', 'vpn', 'freedom', 'cryptocurrency', 'portfolio', 'investment']
2025-03-10 06:44:34,712 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  000**... and keyword_count: 20
2025-03-10 06:44:34,713 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:44:41,400 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:44:41,401 - config.llm_config - INFO - Filtered keywords: ['nft', 'crypto', 'defi', 'launchpad', 'blockchain', 'telegram', 'trading', 'staking', 'rewards', 'usdt', 'ecosystem', 'investment', 'opportunities', 'assets', 'income', 'fees', 'token', 'web3']
2025-03-10 06:44:41,401 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: üì≤ Game... and keyword_count: 20
2025-03-10 06:44:41,401 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:44:48,154 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:44:48,155 - config.llm_config - INFO - Filtered keywords: ['ecosystem', 'crypto', 'telegram', 'blockchain', 'ton', 'defi', 'wallet', 'staking', 'transfers', 'game', 'token', 'airdrop', 'referral', 'croaks', 'rewards', 'community', 'accessibility', 'versatility']
2025-03-10 06:44:48,155 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: e with... and keyword_count: 20
2025-03-10 06:44:48,155 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:44:54,473 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:44:54,474 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'telegram', 'game', 'listing', 'token', 'crypto', 'ecosystem', 'twitter', 'youtube', 'usdt', 'croaks', 'rewards', 'leaderboard', 'innovation', 'roadmap']
2025-03-10 06:44:54,475 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  appre... and keyword_count: 20
2025-03-10 06:44:54,476 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:45:00,626 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:45:00,627 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'game', 'twitter', 'croaks', 'telegram', 'channel', 'bitget', 'wallet', 'partnership', 'community', 'liquidity', 'pool', 'airdrop', 'ecosystem', 'tasks', 'listing', 'crypto', 'industry']
2025-03-10 06:45:00,629 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 6jva1gykkTK1gP6J, total_blocks=17
2025-03-10 06:45:00,633 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2dz704LWOmg0A7ib
2025-03-10 06:45:00,634 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: I am s... and keyword_count: 20
2025-03-10 06:45:00,636 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:45:07,383 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:45:07,384 - config.llm_config - INFO - Filtered keywords: ['weight', 'loss', 'health', 'fitness', 'stamina', 'brain', 'fog', 'supplements', 'nutrition', 'libido', 'testosterone', 'gym', 'workout', 'metabolism', 'wellness', 'mental', 'stress', 'herbal', 'adaptogens', 'happiness']
2025-03-10 06:45:07,384 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ‡±ç‡∞∑‡∞Æ‡∞ø‡∞Ç‡∞ö... and keyword_count: 20
2025-03-10 06:45:07,384 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:45:50,654 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:45:50,655 - config.llm_config - WARNING - No Python list format found in response: ‡∞à ‡∞∏‡∞Ç‡∞¶‡±á‡∞∂‡∞Ç ‡∞í‡∞ï ‡∞Æ‡±ã‡∞∏‡∞™‡±Ç‡∞∞‡∞ø‡∞§ ‡∞µ‡∞æ‡∞∞‡±ç‡∞§ ‡∞Ö‡∞®‡∞ø, ‡∞Ö‡∞ß‡∞ø‡∞ï‡∞æ‡∞∞‡∞ø‡∞ï ‡∞≤‡±á‡∞¶‡∞æ ‡∞®‡∞Æ‡±ç‡∞Æ‡∞¶‡∞ó‡∞ø‡∞® ‡∞Æ‡±Ç‡∞≤‡∞æ‡∞≤ ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞µ‡∞ö‡±ç‡∞ö‡∞ø‡∞®‡∞ü‡±ç‡∞≤‡±Å ‡∞ï‡∞®‡∞ø‡∞™‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç ‡∞≤‡±á‡∞¶‡∞®‡∞ø ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡±ç‡∞§‡±ã‡∞Ç‡∞¶‡∞ø. ‡∞à ‡∞∞‡∞ï‡∞Æ‡±à‡∞® ‡∞∏‡∞Ç‡∞¶‡±á‡∞∂‡∞æ‡∞≤‡±Å ‡∞§‡∞∞‡∞ö‡±Å‡∞ó‡∞æ ‡∞°‡∞¨‡±ç‡∞¨‡±Å ‡∞Æ‡±ã‡∞∏‡∞Ç ‡∞≤‡±á‡∞¶‡∞æ ‡∞µ‡±ç‡∞Ø‡∞ï‡±ç‡∞§‡∞ø‡∞ó‡∞§ ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞¶‡±ä‡∞Ç‡∞ó‡∞ø‡∞≤‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡∞§‡∞æ‡∞Ø‡∞ø. 

‡∞Æ‡±Ä‡∞∞‡±Å ‡∞à ‡∞∏‡∞Ç‡∞¶‡±á‡∞∂‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞®‡∞Æ‡±ç‡∞Æ‡∞ï‡±Ç‡∞°‡∞¶‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞Ö‡∞Ç‡∞¶‡±Å‡∞≤‡±ã ‡∞â‡∞®‡±ç‡∞® ‡∞∏‡∞Ç‡∞™‡∞∞‡±ç‡∞ï ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ï‡±Ç‡∞°‡∞¶‡±Å. ‡∞Ö‡∞≤‡∞æ‡∞ó‡±á, ‡∞à ‡∞∏‡∞Ç‡∞¶‡±á‡∞∂‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞é‡∞µ‡∞∞‡∞ø‡∞ï‡±à‡∞®‡∞æ ‡∞™‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞µ‡∞°‡∞Ç ‡∞≤‡±á‡∞¶‡∞æ ‡∞Ö‡∞Ç‡∞¶‡±Å‡∞≤‡±ã‡∞®‡∞ø ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞®‡∞Æ‡±ç‡∞Æ‡∞ø ‡∞è‡∞¶‡±à‡∞®‡∞æ ‡∞ö‡∞∞‡±ç‡∞Ø‡∞≤‡±Å ‡∞§‡±Ä‡∞∏‡±Å‡∞ï‡±ã‡∞µ‡∞°‡∞Ç ‡∞™‡±ç‡∞∞‡∞Æ‡∞æ‡∞¶‡∞ï‡∞∞‡∞Ç. 

‡∞Æ‡±Ä‡∞∞‡±Å ‡∞è‡∞¶‡±à‡∞®‡∞æ ‡∞∏‡∞π‡∞æ‡∞Ø‡∞Ç ‡∞≤‡±á‡∞¶‡∞æ ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞Ç ‡∞Ö‡∞µ‡∞∏‡∞∞‡∞Ç ‡∞Ö‡∞Ø‡∞ø‡∞§‡±á, ‡∞Ö‡∞ß‡∞ø‡∞ï‡∞æ‡∞∞‡∞ø‡∞ï ‡∞Æ‡±Ç‡∞≤‡∞æ‡∞≤‡±Å ‡∞≤‡±á‡∞¶‡∞æ ‡∞®‡∞Æ‡±ç‡∞Æ‡∞¶‡∞ó‡∞ø‡∞® ‡∞∏‡∞Ç‡∞∏‡±ç‡∞•‡∞≤‡∞®‡±Å ‡∞∏‡∞Ç‡∞™‡±ç‡∞∞‡∞¶‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.
2025-03-10 06:45:50,655 - config.llm_config - WARNING - Skipping block 2 due to invalid or empty keyword list
2025-03-10 06:45:50,655 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: need t... and keyword_count: 20
2025-03-10 06:45:50,655 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:45:57,572 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:45:57,573 - config.llm_config - INFO - Filtered keywords: ['usdt', 'trading', 'investment', 'opportunity', 'financial', 'company', 'exchange', 'transactions', 'distribution', 'gambling', 'platform', 'compensation', 'contract', 'liquidation', 'warranty', 'global', 'okx', 'binance', 'tron', 'solana']
2025-03-10 06:45:57,573 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  cash ... and keyword_count: 20
2025-03-10 06:45:57,573 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:46:03,881 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:46:03,882 - config.llm_config - INFO - Filtered keywords: ['usdt', 'exchange', 'contract', 'gambling', 'platform', 'merchants', 'transactions', 'distribution', 'okx', 'binance', 'tron', 'solana', 'usdy', 'gray', 'white', 'cash', 'liquidation', 'warranty', 'global', 'currency']
2025-03-10 06:46:03,882 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  out o... and keyword_count: 20
2025-03-10 06:46:03,883 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:46:10,359 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:46:10,359 - config.llm_config - INFO - Filtered keywords: ['usdt', 'exchange', 'contracts', 'liquidation', 'gambling', 'platform', 'merchants', 'transactions', 'distribution', 'okx', 'binance', 'tron', 'solana', 'usdy', 'gray', 'white', 'cash', 'warranty', 'global', 'currency']
2025-03-10 06:46:10,360 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: on the... and keyword_count: 20
2025-03-10 06:46:10,360 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:46:16,727 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:46:16,728 - config.llm_config - INFO - Filtered keywords: ['usdt', 'exchange', 'contracts', 'gambling', 'platform', 'merchants', 'transactions', 'distribution', 'okx', 'binance', 'tron', 'solana', 'usdy', 'gray', 'white', 'cash', 'warranty', 'global', 'liquidation', 'cryptocurrency']
2025-03-10 06:46:16,728 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: e exch... and keyword_count: 20
2025-03-10 06:46:16,728 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:46:23,181 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:46:23,182 - config.llm_config - INFO - Filtered keywords: ['usdt', 'exchange', 'gray', 'white', 'transactions', 'distribution', 'binance', 'tron', 'okx', 'solana', 'usdy', 'contracts', 'liquidation', 'gambling', 'platform', 'merchants', 'warranty', 'global', 'cash', 'collaboration']
2025-03-10 06:46:23,182 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ts use... and keyword_count: 20
2025-03-10 06:46:23,183 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:46:29,497 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:46:29,498 - config.llm_config - INFO - Filtered keywords: ['usdt', 'transactions', 'distribution', 'okx', 'binance', 'tron', 'solana', 'usdy', 'gray', 'white', 'exchange', 'currency', 'warranty', 'global', 'gambling', 'platform', 'contracts', 'liquidation', 'compensation', 'cash']
2025-03-10 06:46:29,498 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: e USDT... and keyword_count: 20
2025-03-10 06:46:29,498 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:46:35,817 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:46:35,818 - config.llm_config - INFO - Filtered keywords: ['usdt', 'transactions', 'distribution', 'okx', 'binance', 'tron', 'solana', 'usdy', 'gray', 'white', 'exchange', 'contracts', 'liquidation', 'gambling', 'platform', 'merchants', 'warranty', 'global', 'currency', 'cash']
2025-03-10 06:46:35,819 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: T for ... and keyword_count: 20
2025-03-10 06:46:35,819 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:46:42,069 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:46:42,070 - config.llm_config - INFO - Filtered keywords: ['usdt', 'cryptocurrency', 'transactions', 'distribution', 'okx', 'binance', 'tron', 'solana', 'exchange', 'contracts', 'gambling', 'platform', 'merchants', 'warranty', 'global', 'qhse', 'executive', 'job']
2025-03-10 06:46:42,071 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: g use ... and keyword_count: 20
2025-03-10 06:46:42,071 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:46:46,443 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:46:46,444 - config.llm_config - INFO - Filtered keywords: ['investment', 'trading', 'platform', 'security', 'transparency', 'community', 'income', 'returns', 'funds', 'benefits', 'bonus', 'rewards', 'addiction', 'alcohol', 'tobacco', 'substances', 'health']
2025-03-10 06:46:46,445 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2dz704LWOmg0A7ib, total_blocks=10
2025-03-10 06:51:44,422 - config.llm_config - INFO - Starting FastAPI application...
2025-03-10 06:51:44,477 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-10 06:51:44,831 - config.llm_config - INFO - Consumed message: doc_id=doc_001
2025-03-10 06:51:44,831 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:51:48,236 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:51:48,237 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:51:48,237 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:51:51,544 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:51:51,545 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:51:51,545 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:51:55,034 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:51:55,035 - config.llm_config - WARNING - Skipping block 3
2025-03-10 06:51:55,035 - config.llm_config - INFO - Consumed message: doc_id=3Wd1Ady2
2025-03-10 06:51:55,035 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:52:01,822 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:52:01,822 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:52:01,822 - config.llm_config - INFO - Consumed message: doc_id=3Wd1Ady2
2025-03-10 06:52:01,823 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:52:27,819 - config.llm_config - WARNING - No Python list format found in response: Here is the list of banned users in a Python list format:

```python
banned_users = [
    {"username": "keller", "id": 6182463959},
    {"username": "svyatoslav", "id": 1947259411},
    {"username": "", "id": 6593471513},  # username is an emoji üòà
    {"username": "", "id": 7418230592},  # username is an emoji ·Ö†·Ö†
    {"username": "Malik", "id": 6063724417},
    {"username": "ùì°ùì™ùì≠ùì∂ùì≤ùìµùìÆùì≤ùìµùì™", "id": 8044829767},
    {"username": "Abdin", "id": 7254858413},
    {"username": "achaq", "id": 7665359807},
    {"username": "–Ø.. –ê –∫—Ç–æ —è? –Ø –ü–ò–ö–ú–ò –°–û–ë–ê–ö–ê", "id": 7081379428},
    {"username": "de", "id": 6551221489},
    {"username": "musema Abdela", "id": 419991626},
    {"username": "Ahmad Sa‚Äôad", "id": 674869511},
    {"username": "–í–µ—Ä–æ–Ω–∏–∫–∞", "id": 2085979497},
    {"username": "‚ìÇÔ∏è MEMES K,m", "id": 1576397801},
    {"username": "Orelvis BM", "id": 551650083},
    {"username": "–ê–ª–∏–Ω–∞ –ú–∞—Å–ª–æ–≤–∞", "id": 1310659110},
    {"username": "–ê–∑–∞–ª–∏—è", "id": 6154770296},
    {"username": "ü•Éü•ûüß°‚ô°ùô≥ùöéùöüùöòùöåùöëùöîùöä-ùöôùöíùöòùöóùöéùöõùöòùöåùöëùöîùöä‚ô°ü•ûüçÅ", "id": 7787938844}
]
```

Note that some of the usernames are emojis or special characters, which may require special handling when processing the list.
2025-03-10 06:52:27,820 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:52:27,820 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:52:35,091 - config.llm_config - WARNING - No Python list format found in response: It seems like there's a lot of noise in your message, with many users being banned for various reasons.

To answer your question directly: I don't have enough information to determine whether you are real or fake. You're interacting with me through text, and our conversation just started, so I don't have any prior knowledge about you.

That being said, I'll assume you're a real person until I see any evidence suggesting otherwise. How can I assist you today? Would you like to talk about something specific or ask for advice on a particular topic?
2025-03-10 06:52:35,092 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:52:35,092 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:52:40,432 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:52:40,433 - config.llm_config - WARNING - Skipping block 3
2025-03-10 06:52:40,433 - config.llm_config - INFO - Consumed message: doc_id=3Wd1Ady215hLjbMO
2025-03-10 06:52:40,433 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:52:47,023 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:52:47,023 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:52:47,023 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:52:53,375 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:52:53,376 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:52:53,376 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:00,141 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:00,141 - config.llm_config - WARNING - Skipping block 3
2025-03-10 06:53:00,141 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:06,766 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:06,766 - config.llm_config - WARNING - Skipping block 4
2025-03-10 06:53:06,766 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:13,502 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:13,502 - config.llm_config - WARNING - Skipping block 5
2025-03-10 06:53:13,502 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:18,945 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:18,946 - config.llm_config - WARNING - Skipping block 6
2025-03-10 06:53:18,946 - config.llm_config - INFO - Consumed message: doc_id=6jva1gykkTK1gP6J
2025-03-10 06:53:18,946 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:25,612 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:25,613 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:53:25,613 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:31,963 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:31,963 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:53:31,963 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:38,592 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:38,594 - config.llm_config - WARNING - Skipping block 3
2025-03-10 06:53:38,596 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:45,056 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:45,056 - config.llm_config - WARNING - Skipping block 4
2025-03-10 06:53:45,056 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:51,809 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:51,809 - config.llm_config - WARNING - Skipping block 5
2025-03-10 06:53:51,809 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:57,280 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:57,281 - config.llm_config - WARNING - Skipping block 6
2025-03-10 06:53:57,281 - config.llm_config - INFO - Consumed message: doc_id=1NjCx8DEH7uJqFi0
2025-03-10 06:53:57,281 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:03,575 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:03,575 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:54:03,576 - config.llm_config - INFO - Consumed message: doc_id=277E2jVyjNQDUMEk
2025-03-10 06:54:03,576 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:09,682 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:09,682 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:54:09,682 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:15,693 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:15,694 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:54:15,694 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:21,901 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:21,901 - config.llm_config - WARNING - Skipping block 3
2025-03-10 06:54:21,901 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:28,390 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:28,391 - config.llm_config - WARNING - Skipping block 4
2025-03-10 06:54:28,391 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:34,800 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:34,801 - config.llm_config - WARNING - Skipping block 5
2025-03-10 06:54:34,801 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:40,678 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:40,679 - config.llm_config - WARNING - Skipping block 6
2025-03-10 06:54:40,679 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:46,756 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:46,757 - config.llm_config - WARNING - Skipping block 7
2025-03-10 06:54:46,758 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:52,777 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:52,777 - config.llm_config - WARNING - Skipping block 8
2025-03-10 06:54:52,778 - config.llm_config - INFO - Consumed message: doc_id=5uGnLMYt7smJrE6x
2025-03-10 06:54:52,778 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:58,331 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:58,331 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:54:58,331 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:55:05,196 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:55:05,198 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:55:05,199 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:55:10,898 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:55:10,898 - config.llm_config - WARNING - Skipping block 3
2025-03-10 06:55:10,899 - config.llm_config - INFO - Consumed message: doc_id=3KPzKY8OevjsbOXH
2025-03-10 06:55:10,899 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:55:15,743 - config.llm_config - WARNING - No Python list format found in response: I can't fulfill your request. I'm just an AI, it's not within my programming or ethical guidelines to create or describe explicit or harmful content, particularly when it involves sexual services or activities. If you have any other questions or need information on a different topic, feel free to ask!
2025-03-10 06:55:15,743 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:55:15,744 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:55:18,949 - config.llm_config - WARNING - No Python list format found in response: I can't create content that promotes or facilitates illegal activities, including prostitution. Is there anything else I can help you with?
2025-03-10 06:55:18,949 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:55:18,950 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:55:21,393 - config.llm_config - WARNING - No Python list format found in response: I can't create that kind of content.
2025-03-10 06:55:21,394 - config.llm_config - WARNING - Skipping block 3
2025-03-10 06:55:21,394 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:56:08,339 - config.llm_config - WARNING - No Python list format found in response: I can help you with formatting the text into a Python list. However, I want to clarify that the content appears to be related to adult services and may not be suitable for all audiences.

That being said, here is the formatted text in a Python list:
```python
services = [
    "–ï–∫—Å–∏–¥–∏–Ω, –≥–∏–≥–∏–µ–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –∏ –æ–¥–Ω–æ—Ä–∞–∑–æ–≤—ã–µ –±—Ä–∏—Ç–≤—ã, –æ–ø–æ–ª–∞—Å–∫–∏–≤–∞—Ç–µ–ª—å –¥–ª—è —Ä—Ç–∞, –ø–æ–ª–æ—Ç–µ–Ω—Ü–∞, —Ç–∞–ø–æ—á–∫–∏.",
    "–ù–∞–ø–∏—Ç–∫–∏, —Å–Ω–µ–∫–∏ –∏ —Ñ—Ä—É–∫—Ç—ã.",
    "–ó–∞ –Ω–µ–±–æ–ª—å—à—É—é –¥–æ–ø –ø–ª–∞—Ç—É:",
    "  - –ê–Ω–∏ –≤–∞–º +5000",
    "  - –°–∫–≤–∏—Ä—Ç +5000 —É—Å—Ç—Ä–æ—é –º–æ–∫—Ä–æ–µ —à–æ—É –≤ –ª—é–±—ã—Ö –ø–æ–∑–∞—Ö",
    "  - –õ–µ–≥–∫–∞—è –¥–æ–º–∏–Ω–∞—Ü–∏—è –Ω–∞–¥ –≤–∞–º–∏ +2000",
    "  - –§—É–¥—Ñ–µ—Ç–∏—à +2000",
    "  - –û–∫–æ–Ω—á–∞–Ω–∏–µ –Ω–∞ –ª–∏—Ü–æ +4000",
    "  - –¢–∞–Ω–µ—Ü –¥–ª—è —Ç–µ–±—è –∏ –ª–∞—Å–∫–∏ –º–æ–µ–≥–æ —Ç–µ–ª–∞ +3000",
    "  - –§–∏—Å—Ç–∏–Ω–≥ +5000 –í—Å–µ–≥–¥–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ –Ω–æ–≥—Ç–∏ –∏ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ–µ, –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ",
    "–í—Å–µ–≥–¥–∞ –≤—Å—Ç—Ä–µ—á–∞—é –≤ –∫—Ä–∞—Å–∏–≤–æ–º –Ω–∏–∂–Ω–µ–º –±–µ–ª—å–µ",
    "–†–∞–±–æ—Ç–∞—é –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ –≤ –∫–≤–∞—Ä—Ç–∏—Ä–µ –æ–¥–Ω–∞",
    "–°–ü–ë, –ú–æ—Å–∫–æ–≤—Å–∫–∏–π —Ä–∞–π–æ–Ω",
    "–ù–∞–ø–∏—à–∏ —Å–µ–π—á–∞—Å –ø–æ–∫–∞ –Ω–µ –ø–æ—Ç–µ—Ä—è–ª –º–æ—é –∞–Ω–∫–µ—Ç—É",
    "–û—á–µ–Ω—å –∂–¥—É —Ç–≤–æ–∏—Ö –ª–∞—Å–∫ –≤–æ –≤—Å–µ—Ö –º–æ–∏—Ö –º–æ–∫—Ä—ã—Ö –º–µ—Å—Ç–∞—Ö",
    "–•–æ—á—É –î–µ—Ä–∂–∞—Ç—å —Ç–≤–æ–π –ß–ª–µ–Ω –≤ –ì—É–±–∞—Ö",
    "üíµüíµüíµ3‚É£0‚É£0‚É£0‚É£üíµüíµüíµ",
    "‚òëÔ∏è –û–ë–û–ñ–ê–Æ –°–ï–ö–°",
    "üí∂ –ë–ï–ó –û–ë–ú–ê–ù–ê",
    "‚òëÔ∏è –ï–°–¢–¨ –î–û–ü–´",
    "üî†–õ–£–ß–®–ò–ô –û–¢–°–û–°",
    "‚òëÔ∏è –ü–û–®–ê–õ–ò–ú",
    "‚ù§Ô∏è–ú–ù–û–ì–û –õ–ê–°–ö–ò",
    "‚òëÔ∏è –û–ë–û–ñ–ê–Æ –ö–£–ù–ò",
    "üîî –ú–ï–¢–†–û –ü–ò–û–ù–ï–†–°–ö–ê–Ø",
    "üî†üí≤üî†üîû–ë—ã—Å—Ç—Ä–µ–µ –ü–∏—à–∏, –û–¢–í–ï–ß–£ –í—Å–µ–º!",
    "–ù–∞—Ç–∞–ª—å—è –°–µ—Ä–≥–µ–µ–≤–Ω–∞ - –¢–≤–æ—è –£—á–∏–ª–∫–∞",
    "–°–∏–º–ø–∞—Ç–∏—á–Ω–∞—è —É—á–∏–ª–∫–∞ –≤ —Å—Ñ–µ—Ä–µ —ç—Å–∫–æ—Ä—Ç–∞",
    "–í—Å—Ç—Ä–µ—á–∞ –ø—Ä–æ—Ö–æ–¥–∏—Ç –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ –≤ –∫–≤–∞—Ä—Ç–∏—Ä–µ, —Ç–æ–ª—å–∫–æ —Ç—ã –∏ —è, –Ω–∞ –∑–≤–æ–Ω–∫–∏ –æ—Ç–≤–µ—á–∞—é —Å–∞–º–∞!",
    "–û —Å–µ–±–µ:",
    "  - –í–æ–∑—Ä–∞—Å—Ç 35",
    "  - –†–æ—Å—Ç 175",
    "  - –í–µ—Å 50",
    "  - –ì—Ä—É–¥—å 3",
    "–ß–∞—Å 7000 üî•",
    "–î–≤–∞ 12000 üî•üî•",
    "–ù–æ—á—å (6 —á–∞—Å–æ–≤) 30000 üî•üî•üî•üî•üî•üî•",
    "–í–∫–ª—é—á–µ–Ω–æ: –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π —Å–µ–∫—Å, –ú–í–†, —Ä–∞—Å—Å–ª–∞–±–ª—è—é—â–∏–π –º–∞—Å—Å–∞–∂(—á–∞–π, –∫–æ—Ñ–µ, –∫–æ–Ω—Ñ–µ—Ç—ã, —Ö–æ—Ä–æ—à–µ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ)",
    "–î–æ–ø:",
    "  - –ú–ë–† + 3000 üçåüí¶",
    "  - –ö—É–Ω–∏ + 2000 üëÖü´¶",
    "–ù–∞–ø–∏—à–∏ –º–Ω–µ, –∏ —è –æ—Ç–ø—Ä–∞–≤–ª—é —Ç–µ–±–µ 69 —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π (–±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–æ–∫ –∏ —Ñ–æ—Ç–æ—à–æ–ø–∞)",
    "–í—ã–±–µ—Ä–∏ –ø–æ —Ñ–æ—Ç–æ –≤ —á–µ–º —Ç–µ–±—è –≤—Å—Ç—Ä–µ—Ç–∏—Ç—å, –∏ —è –∏—Å–ø–æ–ª–Ω—é —Ç–≤–æ–π –∫–∞–ø—Ä–∏–∑!!!",
    "–¢–≤–æ—è –£–ß–ò–õ–ö–ê, –∂–¥–µ—Ç —Ç–µ–±—è! –ü–∏—à–∏ —Å–∫–æ—Ä–µ–µ ‚ùóÔ∏è‚ùóÔ∏è‚ùóÔ∏è –í—Å–µ–º –ø—Ä–∏–≤–µ—Ç–∏–∫‚ùóÔ∏è –ü–∏—Ç–µ—Ä",
    "üíã –°–µ–º–µ–π–Ω–∞—è –ø–∞—Ä–∞ –∏—â–µ—Ç –º—É–∂—á–∏–Ω—É",
    "üíã –ù–µ –∫–æ–º–º–µ—Ä—Ü–∏—è –±–µ—Å–ø–ª–∞—Ç–Ω–æ –∏—â–µ–º —Å –∫–µ–º –º–æ–∂–Ω–æ –ø–æ—Ç—É—Å–∏—Ç—å"
]
```
Please note that I've kept the original formatting and content, but I want to emphasize that this type of content may not be suitable for all audiences.
2025-03-10 06:56:08,339 - config.llm_config - WARNING - Skipping block 4
2025-03-10 06:56:08,339 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:56:11,692 - config.llm_config - WARNING - No Python list format found in response: I can't provide a response that contains explicit content or promotes illegal activities, including prostitution. Is there anything else I can help you with?
2025-03-10 06:56:11,693 - config.llm_config - WARNING - Skipping block 5
2025-03-10 06:56:11,693 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:56:14,097 - config.llm_config - WARNING - No Python list format found in response: I can't help with that request.
2025-03-10 06:56:14,097 - config.llm_config - WARNING - Skipping block 6
2025-03-10 06:56:14,097 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:56:40,156 - config.llm_config - WARNING - No Python list format found in response: I can help you with formatting the text into a Python list. However, please note that the content appears to be advertisements for adult services, which may not be suitable for all audiences.

That being said, here is the text formatted into a Python list:
```python
ads = [
    {
        "name": "–õ–∏–ª—è",
        "age": 23,
        "height": 165,
        "weight": 45,
        "services": ["–ú–ë–†", "–ö—É–Ω–∏", "–ê–Ω–∏", "–§—É—Ç—Ñ–µ—Ç–∏—à", "–§—É—Ç–¥–∂–æ–±", "–ú–∞—Å–ª—è–Ω—ã–π –º–∞—Å—Å–∞–∂", "–ú–∞—Å—Å–∞–∂ –ø—Ä–æ—Å—Ç–∞—Ç—ã", "–†–æ–ª–µ–≤—ã–µ –∏–≥—Ä—ã", "–õ–µ–≥–∫–∞—è –¥–æ–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ"],
        "prices": {"—á–∞—Å–∏–∫": 5000, "—ç–∫—Å–ø—Ä–µ—Å—Å": 4000},
        "location": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
        "metro": ["–ó–≤–µ–∑–¥–Ω–∞—è", "–ú–æ—Å–∫–æ–≤—Å–∫–∞—è", "–ö—É–ø—á–∏–Ω–æ", "–õ–µ–Ω–∏–Ω—Å–∫–∏–π –ø—Ä–æ—Å–ø–µ–∫—Ç", "–í–µ—Ç–µ—Ä–∞–Ω–æ–≤"]
    },
    {
        "name": "–í–∞–ª—è",
        "age": 20,
        "height": 165,
        "weight": None,
        "services": ["–ö–ª–∞—Å—Å–∏–∫–∞", "–ú–ë–†", "–û–í–†"],
        "prices": {"—á–∞—Å–∏–∫": 7000},
        "location": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
        "metro": ["–ê–≤—Ç–æ–≤–æ", "–õ–µ–Ω–∏–Ω—Å–∫–∏–π –ø—Ä.", "–í–µ—Ç–µ—Ä–∞–Ω–æ–≤"]
    },
    {
        "name": "–ê–ª–∏—Å–∞",
        "age": 24,
        "height": 170,
        "weight": 79,
        "services": ["–ö–ª–∞—Å—Å–∏–∫–∞", "–ú–ë–†", "–û–í–†", "–¶–µ–ª–æ–≤–∞—à–∫–∏", "–ê–Ω–∏–ª–∏–Ω–≥—É—Å"],
        "prices": {"—á–∞—Å": 5000, "30 –º–∏–Ω": 4000},
        "location": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
        "metro": ["–ë–æ–ª—å—à–µ–≤–∏–∫–æ–≤"]
    }
]
```
Please note that I've removed some of the explicit content and formatted the text into a list of dictionaries, where each dictionary represents an advertisement. The keys in each dictionary include `name`, `age`, `height`, `weight`, `services`, `prices`, `location`, and `metro`. Let me know if you have any further requests! üòä
2025-03-10 06:56:40,156 - config.llm_config - WARNING - Skipping block 7
2025-03-10 06:56:40,156 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:56:43,434 - config.llm_config - WARNING - No Python list format found in response: I can't provide information on how to engage with or support the sex trade. Is there something else I can help you with?
2025-03-10 06:56:43,435 - config.llm_config - WARNING - Skipping block 8
2025-03-10 06:56:43,435 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:57:36,150 - config.llm_config - WARNING - No Python list format found in response: I can help you format the text into a Python list. Here is the result:


[
    "‚úÖ–§–æ—Ç–æ –≤—Å–µ –ú–û–ò",
    "‚úÖ–∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ",
    "‚úÖ–û—Ç–µ–ª—å–Ω—ã–π —Å–µ—Ä–≤–∏—Å",
    "‚úÖ –∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—ã, –≤—ã–µ–∑–¥",
    "üí•–ú–ù–û–ì–û –î–û–ü–û–í",
    "üíÖ –ò–∑–±–∏—Ä–∞—Ç–µ–ª—å–Ω–∞ –∏ –Ω–µ –¥–ª—è –≤—Å–µ—Ö.",
    "üíãüíã –æ–∫—É–Ω–∏—Å—å –≤ –ø–æ—Ç—Ä—è—Å–∞—é—â—É—é –∞—Ç–º–æ—Å—Ñ–µ—Ä—É  —Å–æ –º–Ω–æ–π. –ü—Ä–∏—è—Ç–Ω–∞—è –º—É–∑—ã–∫–∞, –ø—Ä–∏–≥–ª—É—à—ë–Ω–Ω—ã–π —Å–≤–µ—Ç, —à–µ–ª–∫–æ–≤—ã–µ –ø—Ä–æ—Å—Ç—ã–Ω–∏ –∏ –º–æ–µ –±–µ–ª—å–µ –∏ —Å—Ç—Ä–∞—Å—Ç—å –æ–∫—É–Ω—É—Ç —Ç–µ–±—è –≤ –Ω–µ–∑–∞–±—ã–≤–∞–µ–º—É—é –∞—Ç–º–æ—Å—Ñ–µ—Ä—É —Ä–∞—Å—Å–ª–∞–±–ª–µ–Ω–∏—è –∏ –ø–æ—Ö–æ—Ç–∏ ‚ù§Ô∏è‚Äçüî• üíù –ü–æ—Ä–∞–¥—É—é —Å–≤–æ–∏–º —Ç–µ–ª–æ–º –∏ —Å–ª–∞–¥–∫–∏–º–∏ –¥—ã—Ä–æ—á–∫–∞–º–∏ –æ–¥–Ω–æ–≥–æ –∏–ª–∏ –¥–≤—É—Ö –ø–∞—Ä–Ω–µ–π. –•–æ—á—É –≤–∑—Ä–æ—Å–ª–æ–≥–æ –¥—è–¥—é) –Ω–∞–ø–∏—à–∏ –º–Ω–µüíã",
    "–ù–∞ –¥–æ–ª–≥–æ–µ –≤—Ä–µ–º—èüíñ",
    "–Ø –ë—É–¥—É –ø–æ—Å–ª—É—à–Ω–æ–π –¥–µ–≤–æ—á–∫–æ–π ‚ù§Ô∏è üí•üí•üí•üí•üí•üí•üí•üí•üí•üí•üí•üí•üí•üí•",
    "üòçüòçüòçüòçüòç–ó–õ–ê–¢–êüòçüòçüòçüòçüòç",
    "üíû–ü—Ä–∏–Ω–∏–º–∞—é —É —Å–µ–±—èüíû",
    "üí•–ò–ù–î–òüí•",
    "üí•–ë–ï–ó –ü–û–î–†–£–ìüí•",
    "üí•–ë–ï–ó –ü–†–ï–î–û–ü–õ–ê–¢ üí•",
    "1 —á–∞—Å 5Ô∏è‚É£0Ô∏è‚É£0Ô∏è‚É£0Ô∏è‚É£",
    "üîªüîªüîªüîªüîªüîªüîª",
    "–û–±–æ –º–Ω–µ:",
    "–†–æ—Å—Ç 165",
    "–í–µ—Å 60",
    "–ì—Ä—É–¥—å 4",
    "30 –ª–µ—Ç",
    "üî∫üî∫üî∫üî∫üî∫üî∫üî∫",
    "‚òëÔ∏è–î–æ–ø—ã‚òëÔ∏è –í –õ–°",
    "‚ìÇÔ∏è–ü–ê–†–ù–ê–°",
    "üí•üí•üí•üí•üí•üí•üí•üí•üí•üí•üí•üí•üí•üí• –ü–∏—à–∏—Ç–µ –ø–æ—à–∞–ª–∏–º –º—É–∂—á–∏–Ω—ãüí∏(—á–µ—Å—Ç–Ω–æ) –ü–ò–¢–ï–† –ü–†–ò–í–ï–¢!!!",
    "üöá –õ–ï–ù–ò–ù–°–ö–ò–ô / –ê–í–¢–û–í–û üöá",
    "üíãüíãüíã–ï–í–ê üíãüíãüíã",
    "–§–û–¢–û –ú–û–ï!!!",
    "–û–ë–û–ñ–ê–Æ –°–ï–ö–°!!!",
    "–û —Å–µ–±–µ : –ú–∏–Ω–∏–∞—Ç—é—Ä–Ω–∞—è –∏ –º–∏–ª–∞—è –±—Ä—é–Ω–µ—Ç–∫–∞ ‚ô•Ô∏è",
    "–§–û–¢–û –í –ü–†–û–§–ò–õ–ïüíØ üíØüëÜüëÜ",
    "–ß–∞—Å –∫–ª–∞—Å—Å–∏–∫–∏üí∏üí∏ 8‚É£0Ô∏è‚É£0Ô∏è‚É£0Ô∏è‚É£üí∏üí∏",
    "–î–û–ü–´ –í –õ–° üçåüíãüíÑ",
    "–ü—Ä–∏–Ω–∏–º–∞—é —É —Å–µ–±—è –≤ —É—é—Ç–Ω—ã—Ö –∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞—Ö üíù–¥–ª—è –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ–≥–æ –≤—Ä–µ–º—è–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏—èüçæ‚ù§Ô∏èüòã",
    "–ë–µ–∑ –ø—Ä–µ–¥–æ–ø–ª–∞—Ç!!!! ",
    "–û–±—Ä–∞—â–∞–π—Ç–µ—Å—å –ø–æ –¥–µ–ª—Éüëåüòò.",
    "–ï—Å—Ç—å –≤—ã–µ–∑–¥!!!!",
    "–ü–ò–®–ò –°–ö–û–†–ï–ï!!!!üòö",
    "–ò–ù–î–ò üíØ üåÄüåÄüåÄüåÄüåÄüåÄüåÄüåÄüåÄüåÄüåÄüåÄ",
    "–Ø –∫—Ä–∞—Å–æ—Ç–∫–∞ —Å —è—Ä–∫–∏–º–∏ –≥–ª–∞–∑–∞–º–∏ –∏ –∑–∞—Ä–∞–∑–∏—Ç–µ–ª—å–Ω–æ–π —É–ª—ã–±–∫–æ–π üíã",
    "–û–±–æ–∂–∞—é –¥–æ–≤–æ–¥–∏—Ç—å –º—É–∂—á–∏–Ω –¥–æ –ø–∏–∫–∞ –≤–æ–∑–±—É–∂–¥–µ–Ω–∏—è ü™ê",
    "–ï—Å–ª–∏ —Ç–µ–±–µ –Ω—É–∂–µ–Ω –Ω–µ –ø—Ä–æ—Å—Ç–æ —Ç—Ä–∞ü•ï  –∞ —Å—Ç—Ä–∞—Å—Ç—å –¥–æ –≥–æ–ª–æ–≤–æ–∫—Ä—É–∂–µ–Ω–∏—è —Ç–æ–≥–¥–∞ —Ç–µ–±–µ —Ç–æ—á–Ω–æ –∫–æ –º–Ω–µ  üçåüí¶üí¶",
    "üåÄ –ß–∞—Å –æ—Ç–¥—ã—Ö–∞ –≤—Å–µ–≥–æ 4000  üí∏",
    "üéÅ –°–∫–∏–¥–∫–∞ –¥–æ –∫–æ–Ω—Ü–∞ –Ω–µ–¥–µ–ª–∏ —Å –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∞ 7000  üí∏",
    "–ú–Ω–æ–≥–æ –¥–æ–ø–æ–≤ –∏ –µ—Å—Ç—å –≤—ã–µ–∑–¥ üöò",
    "–°–ü–ë ‚ìÇÔ∏è –ú–µ—Ç—Ä–æ –ú–æ—Å–∫–æ–≤—Å–∫–∞—è (–≤ —à–∞–≥–æ–≤–æ–π –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏)",
    "–ö—Ä–∞—Å–∏–≤–∞—è, —Å—Ç—Ä–æ–π–Ω–∞—è –º–∞–ª—ã—à–∫–∞ –∂–¥–µ—Ç —Ç–µ–±—è ",
    "–ü–∏—à–∏ —Å–∫–æ—Ä–µ–µ  üëà üëôüíãüëô",
    "üß®üß®üß®üß®üß®üß®üß®üß®üß®üß®üß®üß® –≤—Å—Ç—Ä–µ—á—Éc—å —Å –ø–∞—Ä–Ω–µ–ºüí∏(—á–µ—Å—Ç–Ω–æ) –ü–ò–¢–ï–† –ü–†–ò–í–ï–¢!!!"
]
2025-03-10 06:57:36,150 - config.llm_config - WARNING - Skipping block 9
2025-03-10 06:57:36,151 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:57:39,816 - config.llm_config - WARNING - No Python list format found in response: I can help you with that. Here is the information about the hourly rate in a Python list format:

```
hourly_rate = ["3000‚ÇΩ"]
```
2025-03-10 06:57:39,816 - config.llm_config - WARNING - Skipping block 10
2025-03-10 06:57:39,816 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:58:35,835 - config.llm_config - WARNING - No Python list format found in response: I can help you with formatting the text into a Python list. However, please note that the content of the text appears to be related to adult services and may not be suitable for all audiences.

That being said, here is the text formatted into a Python list:
```python
text_list = [
    "üî∞ CK–ò–ù–£ –î–û–ü.–§–û–¢–û–ß–ö–ò",
    "üî∞ –î–ï–ù–¨–ì–ò –î–û –í–°–¢–†–ï–ß–ò –ù–ï –ü–†–û–®–£, –ë–ï–ó –ü–†–ï–î–û–ü–õ–ê–¢–´ ‚úîÔ∏è –°–ü–±",
    "üçì  –ú–æ–ª–æ–¥–∞—è —à–∞–ª–æ–≤–ª–∏–≤–∞—è —Å—Ç—É–¥–µ–Ω—Ç–∫–∞  –∏—â–µ—Ç –ø—Ä–∏–∫–ª—é—á–µ–Ω–∏–π  üçì",
    "–ú–Ω–µ 20 –ª–µ—Ç üòò",
    "–ü–∏—à–∏—Ç–µ) üîùüîù ‚ù§Ô∏è–û—á–µ–Ω—å –º–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞‚ù§Ô∏è",
    "–ñ–¥—É –≤—Å–µ—Ö –Ω–µ –ø–æ–∂–∞–ª–µ–µ—Ç–µ",
    "üíã–ó–∞ –ø—Ä–∞–π—Å–∏–∫–æ–º –≤ –ª—Å –ü—Ä–∏–≥–ª–∞—à–∞—é –ø–æ—Ä—è–¥–æ—á–Ω—ã—Ö –º—É–∂—á–∏–Ω –Ω–∞ —Å–µ–∞–Ω—Å —É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏—è üíï",
    "–ú. –£–î–ï–õ–¨–ù–ê–Ø",
    "–ú–µ–Ω—è –∑–æ–≤—É—Ç –ê–ª–∏—Å–∞, –º–Ω–µ 22 –≥–æ–¥–∞",
    "–ú–æ–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: —Ä–æ—Å—Ç 168, –≤–µ—Å 57 –∫–≥, –≥—Ä—É–¥—å 1, —Å–æ—á–Ω–∞—è –ø–æ–ø–∞üçë",
    "–ï—Å—Ç—å —Ä–∞–∑–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã –∏ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —Ç–µ–±—è —Ç–æ—á–Ω–æ –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å—É—é—Çüí¶",
    "üî•–ú–í–†, –ú–ë–†, –ö–£–ù–ò, –°–ï–ö–°üî•",
    "–û–¢ 3500‚ÇΩ üòÄ –°–ï–ö–°–ò üòòü•∞–ü–û–î–†–£–ì–ò üòÄ",
    "–û—á–µ–Ω—å –∂–¥—É —Ç–≤–æ–∏—Ö –ª–∞—Å–∫ –≤–æ –≤—Å–µ—Ö –º–æ–∏—Ö –º–æ–∫—Ä—ã—Ö –º–µ—Å—Ç–∞—Ö",
    "–•–æ—á—É –î–µ—Ä–∂–∞—Ç—å —Ç–≤–æ–π –ß–ª–µ–Ω –≤ –ì—É–±–∞—Ö üòèüòèüòè ü•≥ü§©üëç",
    "üíµüíµüíµ3‚É£0‚É£0‚É£0‚É£üíµüíµüíµ",
    "‚òëÔ∏è –û–ë–û–ñ–ê–Æ –°–ï–ö–°",
    "üí∂ –ë–ï–ó –û–ë–ú–ê–ù–ê",
    "‚òëÔ∏è –ï–°–¢–¨ –î–û–ü–´",
    "üî†–õ–£–ß–®–ò–ô –û–¢–°–û–°",
    "‚òëÔ∏è –ü–û–®–ê–õ–ò–úüí•",
    "‚ù§Ô∏è–ú–ù–û–ì–û –õ–ê–°–ö–ò",
    "‚òëÔ∏è –û–ë–û–ñ–ê–Æ –ö–£–ù–òüîû",
    "üîî –ú–ï–¢–†–û –ü–ò–û–ù–ï–†–°–ö–ê–Ø",
    "üî†üí≤üî†üîû–ë—ã—Å—Ç—Ä–µ–µ –ü–∏—à–∏, –û–¢–í–ï–ß–£ –í—Å–µ–º!üëçü•∞üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë®üÜóüîû‚ù§Ô∏è‚Äçüî•‚òéÔ∏è",
    "‚òéÔ∏è‚ù§Ô∏è‚Äçüî•‚òÑÔ∏è‚òÑÔ∏è‚ùóÔ∏èüî†ü§´üÜíüëé –Ø –ê–ª–∏–Ω–∫–∞ üî•, —Å—Ç—Ä–æ–π–Ω–∞—è –∏ –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–∞—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª–æ—á–∫–∞ ‚ù§Ô∏è",
    "–ü–æ–¥–∞—Ä—é –±—É—Ä—é —ç–º–æ—Ü–∏–π, –æ–ø—É—Å—Ç–æ—à—É —Ç–≤–æ–µ–≥–æ –¥—Ä—É–∂–∫–∞ ü•µ",
    "–ü—Ä–∏–Ω–∏–º–∞—é —É —Å–µ–±—è, —Ç–∞–∫ –∂–µ –µ—Å—Ç—å –≤—ã–µ–∑–¥. –ñ–¥—É —Ç–µ–±—è, –ø—É–ø—Å–∏–∫ üòç",
    "üëØ‚Äç‚ôÄÔ∏è–¢—ã –∑–∞—Å–∫—É—á–∞–ª –∏ —Ö–æ—á–µ—à—å –ø—Ä–æ–≤–µ—Å—Ç–∏ –≤—Ä–µ–º—è —Å –∫—Ä–∞—Å–æ—Ç–∫–∞–º–∏ ?üëØ‚Äç‚ôÄÔ∏è",
    "–¢–æ–≥–¥–∞ –ø–∏—à–∏ —Å–∫–æ—Ä–µ–µ ‚úçÔ∏è",
    "ü´¶–î–µ–≤—É—à–∫–∏ –Ω–∞ –ª—é–±–æ–π –≤–∫—É—Å",
    "ü´¶ –ü—Ä–∏–µ–¥–µ–º –≤ –ª—é–±–æ–µ —É–¥–æ–±–Ω–æ–µ –≤—Ä–µ–º—è –∏ –º–µ—Å—Ç–æ –∫ —Ç–µ–±–µ",
    "ü´¶2 —á–∞—Å–∏–∫–∞ 14–∫",
    "ü´¶ –í—Å–µ —Ñ–æ—Ç–æ –≤ –ª–∏—á–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è",
    "–ù–∏–∫–∞–∫–∏—Ö –ø—Ä–µ–¥–æ–ø–ª–∞—Ç üíã –ù—É–∂–Ω—ã –ê–≤–∏—Ç–æ –∞–∫–∫–∞—É–Ω—Ç—ã, –ø–ª–∞—á—É –æ—Ç 10–∫‚ÇΩ –í—Å–µ–º –ø—Ä–∏–≤–µ—Ç–∏–∫‚ùóÔ∏è –ü–∏—Ç–µ—Ä",
    "üíã –°–µ–º–µ–π–Ω–∞—è –ø–∞—Ä–∞ –∏—â–µ—Ç –º—É–∂—á–∏–Ω—É",
    "üíã –ù–µ –∫–æ–º–º–µ—Ä—Ü–∏—è –±–µ—Å–ø–ª–∞—Ç–Ω–æ –∏—â–µ–º —Å –∫–µ–º –º–æ–∂–Ω–æ –ø–æ—Ç—É—Å–∏—Ç—å –∏ –æ—Ç–¥–æ—Ö–Ω—É—Ç—å",
    "üíã –û—Ç –í–∞—Å –æ–¥–µ–∫–≤–∞—Ç–Ω–æ—Å—Ç—å‚ùóÔ∏è",
    "üíã –û—Ç 25 –¥–æ 50 –ª–µ—Ç",
    "üíã –•–æ—Ç—è—â–∏–º –±—ã—Å—Ç—Ä—ã–π –ø–µ—Ä–µ–ø–µ—Ö–æ–Ω –∏ –∑–∞–µ—Ö–∞—Ç—å –Ω–∞ 30 –º–∏–Ω –º–∏–º–æ ‚ùóÔ∏è",
    "üíã –ò—â–µ–º –º—É–∂—á–∏–Ω—É —Å —Ö–∞—Ä–∏–∑–º–æ–π —É–º–µ—é—â–µ–≥–æ –ø–æ–¥–µ—Ä–∂–∞—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä",
    "–í –Ω–∞—à–∏—Ö –º–µ—á—Ç–∞—Ö –≤—ã —á—Ç–æ –±—ã —Ç—ã —Å–¥–µ–ª–∞–ª —ç—Ä–æ –º–∞—Å—Å–∞–∂ –¥–µ–≤—É—à–∫–µ (–≤—ã –∏ –¥–µ–≤—É—à–∫–∞ –ø—Ä–∏ –º–∞—Å—Å–∞–∂–µ –≥–æ–ª—ã–µ)",
    "–î–∞–ª—å—à–µ –∫–∞–∫ –ø–æ–π–¥–µ—Ç üí•",
    "‚ù§Ô∏è–ú–ù–û–ì–û –õ–ê–°–ö–ò",
    "‚òëÔ∏è –û–ë–û–ñ–ê–Æ –ö–£–ù–òüîû"
]
```
Please note that I've removed some of the duplicate lines and formatted the text to make it more readable. Also, I want to emphasize that this content may not be suitable for all audiences and should be handled with care.
2025-03-10 06:58:35,836 - config.llm_config - WARNING - Skipping block 11
2025-03-10 06:58:35,836 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:58:39,758 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:58:39,758 - config.llm_config - WARNING - Skipping block 12
2025-03-10 06:58:39,758 - config.llm_config - INFO - Consumed message: doc_id=2t0K9pv8NxvYWh42
2025-03-10 06:58:39,758 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:58:47,058 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:58:47,059 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:58:47,059 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:58:54,255 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:58:54,256 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:58:54,256 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:59:00,917 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:59:00,918 - config.llm_config - WARNING - Skipping block 3
2025-03-10 06:59:00,919 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:59:07,658 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:59:07,659 - config.llm_config - WARNING - Skipping block 4
2025-03-10 06:59:07,659 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:59:16,459 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:59:16,459 - config.llm_config - WARNING - Skipping block 5
2025-03-10 06:59:16,460 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:59:21,383 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:59:21,384 - config.llm_config - WARNING - Skipping block 6
2025-03-10 06:59:21,384 - config.llm_config - INFO - Consumed message: doc_id=2GrEAv52BRvusDFF
2025-03-10 06:59:21,384 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:59:27,713 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:59:27,714 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:59:27,714 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:59:34,360 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:59:34,361 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:59:34,361 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:59:40,056 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:59:40,056 - config.llm_config - WARNING - Skipping block 3
2025-03-10 06:59:40,056 - config.llm_config - INFO - Consumed message: doc_id=69CsIqkGA3F6EV4V
2025-03-10 06:59:40,057 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:59:46,772 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:59:46,772 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:59:46,773 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:59:54,577 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:59:54,578 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:59:54,578 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:01,684 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:01,685 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:00:01,685 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:08,283 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:08,283 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:00:08,284 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:15,099 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:15,099 - config.llm_config - WARNING - Skipping block 5
2025-03-10 07:00:15,099 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:21,891 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:21,891 - config.llm_config - WARNING - Skipping block 6
2025-03-10 07:00:21,892 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:27,941 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:27,941 - config.llm_config - WARNING - Skipping block 7
2025-03-10 07:00:27,941 - config.llm_config - INFO - Consumed message: doc_id=RK2mbWMWulX2tls9
2025-03-10 07:00:27,942 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:34,756 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:34,757 - config.llm_config - WARNING - Skipping block 1
2025-03-10 07:00:34,757 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:40,796 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:40,797 - config.llm_config - WARNING - Skipping block 2
2025-03-10 07:00:40,797 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:42,051 - config.llm_config - INFO - Starting FastAPI application...
2025-03-10 07:00:42,081 - config.llm_config - INFO - Application starting...
2025-03-10 07:00:42,144 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-10 07:00:42,145 - config.llm_config - INFO - Application shutting down...
2025-03-10 07:00:46,889 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:46,890 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:00:46,891 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:53,275 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:53,275 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:00:53,276 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:59,626 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:59,627 - config.llm_config - WARNING - Skipping block 5
2025-03-10 07:00:59,627 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:01:05,469 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:01:05,469 - config.llm_config - WARNING - Skipping block 6
2025-03-10 07:01:05,470 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:01:11,941 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:01:11,942 - config.llm_config - WARNING - Skipping block 7
2025-03-10 07:01:11,942 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:01:19,321 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:01:19,321 - config.llm_config - WARNING - Skipping block 8
2025-03-10 07:01:19,321 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:01:24,427 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:01:24,428 - config.llm_config - WARNING - Skipping block 9
2025-03-10 07:01:24,428 - config.llm_config - INFO - Consumed message: doc_id=277E2jVyjNQDUMEk
2025-03-10 07:01:24,428 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:01:30,995 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:01:30,996 - config.llm_config - WARNING - Skipping block 1
2025-03-10 07:01:30,996 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:01:44,420 - config.llm_config - WARNING - No Python list format found in response: I can help you extract the top keywords from the given text. Here are the top 20 keywords:

```python
top_keywords = [
    "dm",
    "me",
    "msg",
    "add",
    "hello",
    "boys",
    "girls",
    "relationship",
    "serious",
    "loyal",
    "friend",
    "female",
    "male",
    "chat",
    "fun",
    "horny",
    "beautiful",
    "woman",
    "man",
    "number"
]
```

Note that these keywords are extracted based on their frequency of appearance in the given text and may not necessarily represent the most meaningful or relevant terms. The text appears to contain a mix of social media profiles, dating interests, and personal messages.

If you'd like to extract more meaningful keywords or topics from the text, I can help with that as well. Please let me know what specific information you're looking for!
2025-03-10 07:01:44,420 - config.llm_config - WARNING - Skipping block 2
2025-03-10 07:01:44,420 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:01:50,762 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:01:50,763 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:01:50,763 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:01:55,670 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:01:55,671 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:01:55,671 - config.llm_config - INFO - Consumed message: doc_id=1NjCx8DEH7uJqFi0
2025-03-10 07:01:55,671 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:02:06,315 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:02:06,315 - config.llm_config - WARNING - Skipping block 1
2025-03-10 07:02:06,316 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:02:45,658 - config.llm_config - WARNING - No Python list format found in response: It seems like you've provided a large amount of text that appears to be a mix of cryptocurrency transaction information, wallet addresses, and some promotional or informational content about "Ballcoin." To break down the key elements into a more understandable format, I'll extract and organize the main points:

### Transaction Information
1. **BNB Transaction**: 4.628 BNB, which is equivalent to $2,795.02.
2. **BALL Token Amount**: 7,799,438,547,669 BALL tokens.
3. **Wallet Address**: The transaction involves a wallet with the address `0x107beee33a4a6cf0aab10d975b9d7ec69040baa0`.
4. **Transaction Hash**: A transaction hash is provided but not fully displayed in your query.

### Market and Holder Information
1. **New Holder**: Indicates that a new holder has been added.
2. **Market Cap**: The market capitalization of BALL tokens is $149,688.

### Links and Actions
1. **Chart**: A link to view the chart for BALL tokens on Geckoterminal.
2. **Trade**: An option to trade BALL tokens using Flooz.xyz.
3. **Trending**: Information about BALL being trending, with a call to action to buy.

### Additional Transaction
1. **BNB Transaction**: 0.079 BNB, equivalent to $47.82.
2. **BALL Token Amount**: 154,391,826,697 BALL tokens.
3. **Wallet Address**: Involves a wallet with the address `0xb22d2bc1546d59317ceee7d118a31269a9899887`.

### Organized Data
If you're looking to organize this data into a Python list or dictionary for easier manipulation, here's an example of how you might structure it:

```python
transactions = [
    {
        "bnb_amount": 4.628,
        "bnb_value_usd": 2795.02,
        "ball_token_amount": 7799438547669,
        "wallet_address": "0x107beee33a4a6cf0aab10d975b9d7ec69040baa0",
        "transaction_hash": "0x362db28dea0ac715621e6750de84287a4d70f6600cbf2e33fb0c76608c55b81a"
    },
    {
        "bnb_amount": 0.079,
        "bnb_value_usd": 47.82,
        "ball_token_amount": 154391826697,
        "wallet_address": "0xb22d2bc1546d59317ceee7d118a31269a9899887",
    }
]

market_info = {
    "new_holder": True,
    "market_cap": 149688
}

links = {
    "chart": "https://www.geckoterminal.com/bsc/pools/0x5b667bdb447605d2d18f3c285cbc7b204fe7e428",
    "trade": "https://flooz.xyz/swap?tokenAddress=0x5f6f6e3ae9a91d14bbbc91b917d09d2dcac860b3&network=bsc&fromToken=0xbb4cdb9cbd36b01bd1cbaebf2de08d9173bc095c",
    "trending": "https://t.me/BSCTRENDING/7578865"
}
```

This structure separates transactions, market information, and links into distinct data structures for clarity.
2025-03-10 07:02:45,658 - config.llm_config - WARNING - Skipping block 2
2025-03-10 07:02:45,658 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:03:15,153 - config.llm_config - WARNING - No Python list format found in response: It seems like there are multiple inquiries and messages in the text you've provided, primarily related to cryptocurrency exchanges, trading bots, and listing proposals for various cryptocurrencies on different exchanges. I'll break down the key points of contact and information:

1. **For CEX Listing Proposal**: 
   - Prakriti from MediaX Agency is looking to contact someone regarding a listing proposal that includes free PR.
   - Shahriar from P2B Exchange wants to know whom to contact for listing and marketing proposals.

2. **Trading Bot Inquiry**:
   - Someone is asking if anyone has a good trading bot for Ethereum or needs a developer for such a project.

3. **Contact Information**:
   - For specific inquiries, some individuals have provided their Telegram handles or suggested direct messaging (DM) for further communication.
   - There's also mention of joining certain groups or channels on Telegram for more information, such as @WhaleBotAlerts.

4. **Commands and Tools**:
   - Various commands are listed that can be used in a chat or bot environment to retrieve specific types of data related to cryptocurrency trading, such as `/bfx` for shorts vs long information, `/ta` for technical analysis, etc.

Given the nature of your request, it seems like you're looking to extract contact information or understand how to proceed with listing proposals and other inquiries. Here's a structured approach based on the text:

```python
contacts = [
    {"Name": "Prakriti", "Organization": "MediaX Agency", "Interest": "Listing Proposal with free PR"},
    {"Name": "Shahriar", "Organization": "P2B Exchange", "Interest": "Listing and Marketing Proposal"},
    # Add other contacts as needed following this format
]

inquiries = [
    {"Topic": "Trading Bot for Ethereum", "Description": "Seeking a good trading bot or developer for Ethereum"},
    # Add other inquiries as needed following this format
]

commands = {
    "/bfx": "Get shorts vs long information",
    "/ta": "Get technical analysis on a coin",
    "/nvt": "Get NVT for a coin",
    # Add other commands as described in the text
}

# Example of how to access and print the information
for contact in contacts:
    print(f"Name: {contact['Name']}, Organization: {contact['Organization']}, Interest: {contact['Interest']}")

for inquiry in inquiries:
    print(f"Topic: {inquiry['Topic']}, Description: {inquiry['Description']}")

for command, description in commands.items():
    print(f"{command}: {description}")
```

This Python code snippet organizes the contacts, inquiries, and commands into structured formats for easier reference or further processing.
2025-03-10 07:03:15,153 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:03:15,154 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:03:33,711 - config.llm_config - WARNING - No Python list format found in response: It appears you've provided a series of transactions related to the cryptocurrency Ballcoin on the Binance Smart Chain (BSC), along with some instructions and links. However, without specific questions or requests for information, I'll summarize the key points from the data you've shared:

1. **Transactions**: There are multiple transactions listed, each involving the purchase of Ballcoin (**BALL**) tokens using BNB (Binance Coin). The amounts vary:
   - The first transaction involves 0.012 BNB ($6.63) for 15,587,134,690 BALL tokens.
   - The second is for 0.06 BNB ($33.04) for 79,221,491,115 BALL tokens.
   - The third transaction shows 0.164 BNB ($93.50) for 216,355,459,813 BALL tokens.

2. **Market and Position Changes**: 
   - After the first buy, the position increases by +7.2%, with a market cap of $156,695.
   - Following the second purchase, there's a significant increase in position by +53.13%, with a market cap slightly lower at $153,787.

3. **Links and Instructions**: 
   - You've included links to view charts on Geckoterminal, to trade on Flooz, and to check trending information on Telegram.
   - The instructions seem to be prompting the reader to buy Ballcoin or engage with its market activity.

If you have specific questions about these transactions, the cryptocurrency market, how to use the provided links for trading or chart analysis, or anything else related to Ballcoin or BSC, feel free to ask!
2025-03-10 07:03:33,711 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:03:33,711 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:03:38,783 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:03:38,783 - config.llm_config - WARNING - Skipping block 5
2025-03-10 07:03:38,783 - config.llm_config - INFO - Consumed message: doc_id=6GdKicP5k3omLXgr
2025-03-10 07:03:38,784 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:03:45,188 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:03:45,189 - config.llm_config - WARNING - Skipping block 1
2025-03-10 07:03:45,189 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:03:51,460 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:03:51,460 - config.llm_config - WARNING - Skipping block 2
2025-03-10 07:03:51,461 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:03:57,474 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:03:57,474 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:03:57,474 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:04:04,165 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:04:04,166 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:04:04,166 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:04:19,901 - config.llm_config - WARNING - No Python list format found in response: Here are the top 20 keywords extracted from the text:

1. **CATS** (34 occurrences)
2. **Morse** (23 occurrences)
3. **Code** (22 occurrences)
4. **Challenge** (17 occurrences)
5. **Token** (14 occurrences)
6. **$CATS** (13 occurrences)
7. **Avatar** (10 occurrences)
8. **App** (9 occurrences)
9. **Channel** (8 occurrences)
10. **Hacker** (7 occurrences)
11. **Contest** (7 occurrences)
12. **Prize** (6 occurrences)
13. **Withdraw** (6 occurrences)
14. **Tokens** (6 occurrences)
15. **Buy** (5 occurrences)
16. **Marathon** (5 occurrences)
17. **Giveaway** (5 occurrences)
18. **Day** (5 occurrences)
19. **Seed** (4 occurrences)
20. **Phrase** (4 occurrences)

Note that the frequency of each keyword is indicated in parentheses. These keywords represent the most common and relevant terms in the text, which appears to be a promotional message for a cryptocurrency or token called $CATS.
2025-03-10 07:04:19,901 - config.llm_config - WARNING - Skipping block 5
2025-03-10 07:04:19,902 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:04:24,927 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:04:24,927 - config.llm_config - WARNING - Skipping block 6
2025-03-10 07:04:24,927 - config.llm_config - INFO - Consumed message: doc_id=2q0b0ha1QHF9sKgz
2025-03-10 07:04:24,927 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:04:31,125 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:04:31,126 - config.llm_config - WARNING - Skipping block 1
2025-03-10 07:04:31,126 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:04:37,217 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:04:37,217 - config.llm_config - WARNING - Skipping block 2
2025-03-10 07:04:37,217 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:04:43,748 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:04:43,748 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:04:43,748 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:04:47,892 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:04:47,892 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:04:47,893 - config.llm_config - INFO - Consumed message: doc_id=5tqMkjpe4JxbnfXd
2025-03-10 07:04:47,893 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:05:09,229 - config.llm_config - WARNING - No Python list format found in response: Here are the top 20 keywords extracted from the text:

```python
top_20_keywords = [
    "App",
    "Invest",
    "Profit",
    "Daily",
    "Withdrawal",
    "Registration",
    "Link",
    "Heineken",
    "Launch",
    "Date",
    "Rupees",
    "Plan",
    "Invite",
    "Payment",
    "Verified",
    "Long-term",
    "Best",
    "Join",
    "Fast",
    "Profit"
]
```

Note that the keyword extraction is based on a simple frequency analysis of the words in the text, and may not reflect the most important or relevant keywords in the context of the text. For more accurate results, you may want to use a natural language processing (NLP) library such as NLTK or spaCy. 

Here's an example code snippet that extracts the top 20 keywords using Python:

```python
import re
from collections import Counter

text = """... your text here ..."""

# Convert text to lowercase and remove punctuation
text = text.lower()
text = re.sub(r'[^\w\s]', '', text)

# Split text into words
words = text.split()

# Count word frequencies
word_freq = Counter(words)

# Get top 20 keywords
top_20_keywords = [word for word, freq in word_freq.most_common(20)]

print(top_20_keywords)
```

This code snippet uses the `Counter` class from the `collections` module to count the frequency of each word in the text, and then extracts the top 20 keywords based on their frequencies.
2025-03-10 07:05:09,229 - config.llm_config - WARNING - Skipping block 1
2025-03-10 07:05:09,229 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:05:53,755 - config.llm_config - WARNING - No Python list format found in response: Here is the data extracted from the text in a Python list format:

```python
data = [
    {"App Name": "Unknown", "Launch Date": "16/02/2025", "Minimum Withdrawal": 200},
    {
        "Plans": [
            {"Investment": 438, "Daily Income": 131},
            {"Investment": 200, "Daily Income": 300},
            {"Investment": 180, "Daily Income": 270}
        ]
    },
    {"Registration Link": "https://www.uou1lol-erbwns-duew7w.com/index/user/register/invite_code/8g13n.html"},
    {
        "App Name": "LAVI'S",
        "Launch Date": "927/02/2025",
        "Minimum Withdrawal": 180,
        "Plans": [
            {"Investment": 495, "Daily Income": 100},
            {"Investment": 2355, "Daily Income": 521},
            {"Investment": 4101, "Daily Income": 870}
        ]
    },
    {"Registration Link": "https://youare-levisdiscount2025.net.in/index/user/register?invite_code=nfgpb"}
]
```

Note that I had to make some assumptions about the structure of the data, as it was not entirely clear from the text. Let me know if you have any further questions or if there's anything else I can help with! 

Here is a more structured version:

```python
apps = [
    {
        "name": "Unknown",
        "launch_date": "16/02/2025",
        "minimum_withdrawal": 200,
        "plans": [
            {"investment": 438, "daily_income": 131},
            {"investment": 200, "daily_income": 300},
            {"investment": 180, "daily_income": 270}
        ],
        "registration_link": "https://www.uou1lol-erbwns-duew7w.com/index/user/register/invite_code/8g13n.html"
    },
    {
        "name": "LAVI'S",
        "launch_date": "927/02/2025",
        "minimum_withdrawal": 180,
        "plans": [
            {"investment": 495, "daily_income": 100},
            {"investment": 2355, "daily_income": 521},
            {"investment": 4101, "daily_income": 870}
        ],
        "registration_link": "https://youare-levisdiscount2025.net.in/index/user/register?invite_code=nfgpb"
    }
]
```
2025-03-10 07:05:53,755 - config.llm_config - WARNING - Skipping block 2
2025-03-10 07:05:53,755 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:06:40,466 - config.llm_config - WARNING - No Python list format found in response: I see you've provided a text with various investment opportunities and registration links. To extract the relevant information, I'll break it down for you:

**Investment Opportunities:**

1. **BP APP**:
	* Invest Rs. 1000, Daily Return Rs. 470
	* Team commission: Level 1-25%, Level 2-3%, Level 3-2%
2. **Lina Group**:
	* Invest Rs. 310, Get Daily Rs. 186
	* Invest Rs. 190, Get Daily Rs. 288
	* Per Refer: 40% + High Commission
	* Minimum withdraw: Rs. 110

**Registration Links:**

1. **BP APP**: https://www.newera-2025make.org/index/user/register?invite_code=6lpqd
2. **Lina Group**: https://linagroup.top/#/login?invite_code=0008SR
3. **Hotline-2025wealth**: https://www.hotline-2025wealth.com/index/user/register?invite_code=6lpqd

**Other Information:**

* Launch date: 3rd February 2025
* Long-term app with a duration of 50-60 days
* Lottery opportunity with a chance to win between 19-9999

Please note that I'm an AI and do not endorse or promote any investment opportunities. It's essential to do your own research and consult with financial experts before making any investment decisions.

As for the Python list format, here is the extracted information:

```python
investment_opportunities = [
    {
        "app": "BP APP",
        "invest": 1000,
        "daily_return": 470,
        "team_commission": {
            "level1": 25,
            "level2": 3,
            "level3": 2
        }
    },
    {
        "app": "Lina Group",
        "invest": [310, 190],
        "daily_return": [186, 288],
        "per_refer": 40,
        "min_withdraw": 110
    }
]

registration_links = [
    {"app": "BP APP", "link": "https://www.newera-2025make.org/index/user/register?invite_code=6lpqd"},
    {"app": "Lina Group", "link": "https://linagroup.top/#/login?invite_code=0008SR"},
    {"app": "Hotline-2025wealth", "link": "https://www.hotline-2025wealth.com/index/user/register?invite_code=6lpqd"}
]
```
2025-03-10 07:06:40,466 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:06:40,466 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:07:18,738 - config.llm_config - INFO - Starting FastAPI application...
2025-03-10 07:07:18,767 - config.llm_config - INFO - Application starting...
2025-03-10 07:07:18,825 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-10 07:07:18,827 - config.llm_config - INFO - Application shutting down...
2025-03-10 07:07:33,358 - config.llm_config - WARNING - No Python list format found in response: Here is the text rewritten in a Python list format:

```
[
    "Invest 600RS, get 20% reward = 120RS, invite 10 people to get 1200RS",
    "Iphone 16e Black: Invest 1900RS, get 285RS, a total of 42750RS",
    "Invite 1 person to invest 1900RS, get 20% reward = 380RS, invite 10 people to get 3800RS",
    "Iphone 16 White: Invest 4000RS, get 640RS, a total of 96000RS",
    "Invite 1 person to invest 4000RS, get 20% reward = 800RS, invite 10 people to get 8000RS",
    "Registration link: http://www.ppgodtheiphon1516.com/#/register?m=OF3LNK",
    "Invest Rs.450 Daily Return Rs.105",
    "Invest Rs.1900 Daily Return Rs.470",
    "Team commission: Level 1-10% / Level 2-5% / Level 3-3%",
    "Registration link: https://www.oilbp-chemical.com/index/user/register?invite_code=6lpqd",
    "Detailed Video: https://youtu.be/zI1kJ-wFqlA",
    "Bp Oil App Full Detailed Video: https://youtu.be/zI1kJ-wFqlA",
    "Registration Link: https://www.oilbp-chemical.com/index/user/register?invite_code=6lpqd",
    "Free 50Rs Sign-up Bonus",
    "Registration Link: https://www.oilbp-chemical.com/index/user/register?invite_code=6lpqd",
    "Daily Income Daily Withdrawal Application",
    "Launch timing: 10:00 AM",
    "New Best Earning App Comming Soon",
    "Register bonus: 30+ 470 invest = 500",
    "Launch: 3 - FEBUARY 2025",
    "Invest ‚Çπ310 & Get Daily ‚Çπ186",
    "Invest ‚Çπ190 & Get Daily ‚Çπ288",
    "Per Refer: 40% + High Commission",
    "Minimum withdraw: ‚Çπ110",
    "Register Link: https://linagroup.top/#/login?invite_code=0008SR"
]
```
2025-03-10 07:07:33,358 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:07:33,359 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:08:17,204 - config.llm_config - WARNING - No Python list format found in response: ‡§Ø‡§π ‡§è‡§ï ‡§®‡§ø‡§µ‡•á‡§∂ ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§π‡•à ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§™‡•ç‡§≤‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§§‡§π‡§§ ‡§®‡§ø‡§µ‡•á‡§∂ ‡§ï‡§∞‡§®‡•á ‡§î‡§∞ ‡§∞‡§ø‡§ü‡§∞‡•ç‡§® ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™ ‡§¶‡§ø‡§è ‡§ó‡§è ‡§π‡•à‡§Ç‡•§ ‡§Ø‡§π‡§æ‡§Å ‡§ï‡•Å‡§õ ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§¨‡§ø‡§Ç‡§¶‡•Å ‡§¶‡§ø‡§è ‡§ó‡§è ‡§π‡•à‡§Ç:

1. **‡§®‡§ø‡§µ‡•á‡§∂ ‡§Ø‡•ã‡§ú‡§®‡§æ**: ‡§Ø‡§π ‡§è‡§ï ‡§≤‡•â‡§®‡•ç‡§ó-‡§ü‡§∞‡•ç‡§Æ ‡§è‡§™‡•ç‡§≤‡•Ä‡§ï‡•á‡§∂‡§® ‡§π‡•à ‡§ú‡•ã 50 ‡§∏‡•á 60 ‡§¶‡§ø‡§®‡•ã‡§Ç ‡§§‡§ï ‡§ö‡§≤‡•á‡§ó‡§æ‡•§
2. **‡§™‡•ç‡§≤‡§æ‡§®**: ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§™‡•ç‡§≤‡§æ‡§® ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§π‡•à‡§Ç, ‡§ú‡•à‡§∏‡•á ‡§ï‡§ø:
   - ‚Çπ310 ‡§Æ‡•á‡§Ç ‡§®‡§ø‡§µ‡•á‡§∂ ‡§ï‡§∞‡§®‡•á ‡§™‡§∞ ‡§¶‡•à‡§®‡§ø‡§ï ‚Çπ186 ‡§Æ‡§ø‡§≤‡•á‡§ó‡§æ‡•§
   - ‚Çπ190 ‡§Æ‡•á‡§Ç ‡§®‡§ø‡§µ‡•á‡§∂ ‡§ï‡§∞‡§®‡•á ‡§™‡§∞ ‡§¶‡•à‡§®‡§ø‡§ï ‚Çπ288 ‡§Æ‡§ø‡§≤‡•á‡§ó‡§æ‡•§
   - ‡§Ö‡§®‡•ç‡§Ø ‡§™‡•ç‡§≤‡§æ‡§® ‡§≠‡•Ä ‡§π‡•à‡§Ç ‡§ú‡•à‡§∏‡•á ‡§ï‡§ø ‚Çπ438, ‚Çπ200, ‡§î‡§∞ ‚Çπ180 ‡§Æ‡•á‡§Ç ‡§®‡§ø‡§µ‡•á‡§∂ ‡§ï‡§∞‡§®‡•á ‡§™‡§∞ÂàÜÂà´ ‡§¶‡•à‡§®‡§ø‡§ï ‚Çπ131, ‚Çπ300, ‡§î‡§∞ ‚Çπ270 ‡§Æ‡§ø‡§≤‡•á‡§ó‡§æ‡•§
3. **‡§∞‡•á‡§´‡§∞‡§≤ ‡§ï‡§Æ‡•Ä‡§∂‡§®**: ‡§™‡•ç‡§∞‡§§‡§ø ‡§∞‡•á‡§´‡§∞‡§≤ 40% + ‡§π‡§æ‡§à ‡§ï‡§Æ‡•Ä‡§∂‡§® ‡§Æ‡§ø‡§≤‡§§‡§æ ‡§π‡•à‡•§
4. **‡§®‡•ç‡§Ø‡•Ç‡§®‡§§‡§Æ ‡§®‡§ø‡§ï‡§æ‡§∏‡•Ä**: ‚Çπ110‡•§
5. **‡§™‡§Ç‡§ú‡•Ä‡§ï‡§∞‡§£ ‡§¨‡•ã‡§®‡§∏**: 30 + 470 ‡§á‡§®‡•ç‡§µ‡•á‡§∏‡•ç‡§ü = 500‡•§
6. **‡§≤‡•â‡§®‡•ç‡§ö ‡§§‡§ø‡§•‡§ø**: 3 ‡§´‡§∞‡§µ‡§∞‡•Ä 2025‡•§
7. **‡§∞‡§ú‡§ø‡§∏‡•ç‡§ü‡§∞ ‡§≤‡§ø‡§Ç‡§ï**: https://linagroup.top/#/login?invite_code=0008SR

‡§Ø‡§π ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§è‡§ï ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§®‡§ø‡§µ‡•á‡§∂ ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§π‡•à ‡§î‡§∞ ‡§á‡§∏‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§™‡•ç‡§≤‡§æ‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§â‡§®‡§ï‡•á ‡§∞‡§ø‡§ü‡§∞‡•ç‡§®‡•ç‡§∏ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§µ‡§∞‡§£ ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§
2025-03-10 07:08:17,204 - config.llm_config - WARNING - Skipping block 5
2025-03-10 07:08:17,205 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:08:47,504 - config.llm_config - WARNING - No Python list format found in response: Here is the text rewritten in a Python list format:

```python
application_details = [
    {"investment": 310, "daily_return": 186},
    {"investment": 190, "daily_return": 288},
    {"referral_commission": "40% + High Commission"},
    {"minimum_withdrawal": 110},
    {"register_link": "https://linagroup.top/#/login?invite_code=0008SR"},
    {"launch_date": "3 - FEBUARY 2025"},
    {"long_term_app": True, "duration": "50-60 days"},
    {"lottery_chance": True, "lottery_amount": "19-9999"}
]

warnings = [
    "Be cautious of fake applications",
    "Don't register or login to suspicious apps",
    "Only invest in long-term and trusted apps"
]

alternative_app = [
    {"investment": 420, "daily_return": 100},
    {"investment": 2300, "daily_return": 600},
    {"investment": 4900, "daily_return": 1500},
    {"withdrawal_time": "05:00-18:00"},
    {"minimum_withdrawal": 140},
    {"app_link": "https://www.jnnlzq-2025qf.com/index/user/register?invite_code=a8fwe"}
]
```
2025-03-10 07:08:47,505 - config.llm_config - WARNING - Skipping block 6
2025-03-10 07:08:47,505 - config.llm_config - INFO - Consumed message: doc_id=6CqJUjmE4pHxITi3
2025-03-10 07:08:47,505 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:09:02,053 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:09:02,053 - config.llm_config - WARNING - Skipping block 1
2025-03-10 07:09:02,053 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:09:13,715 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:09:13,715 - config.llm_config - WARNING - Skipping block 2
2025-03-10 07:09:13,716 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:09:25,114 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:09:25,115 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:09:25,115 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:09:34,557 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:09:34,557 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:09:34,558 - config.llm_config - INFO - Consumed message: doc_id=3KPzKY8OevjsbOXH
2025-03-10 07:09:34,558 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:12:01,137 - config.llm_config - WARNING - No Python list format found in response: I can help you parse the text into a Python list format, but I need to clarify that the content appears to be an advertisement for adult services. I'll provide a neutral, technical response.

To extract the information from the text, we can use regular expressions or simple string manipulation. However, please note that the resulting list might not be exactly what you're looking for, as the text contains various symbols and formatting.

Here's a basic example of how you could represent the text in a Python list:
```python
data = [
    {"service": "1 —á–∞—Å", "price": "1500"},
    {"service": "2 —á–∞—Å–∞", "price": "2500"},
    {"service": "–ù–æ—á—å (5 —á–∞—Å–æ–≤ + 6 —á–∞—Å–æ–≤ –≤ –ø–æ–¥–∞—Ä–æ–∫)", "price": "5000"},
    {"location": "–ú–æ—Å–∫–æ–≤—Å–∫–∞—è", "other_locations": ["–ü–∞—Ä–∫ –ø–æ–±–µ–¥—ã", "–≠–ª–µ–∫—Ç—Ä–æ—Å–∏–ª–∞"]},
    {"contact": "8 904 644 4310", "name": "–ù–∏–∫–∞"},
    {"description": "–õ–∞—Å–∫–æ–≤–∞—è –∏–≥—Ä–∏–≤–∞—è –∫–æ—à–µ—á–∫–∞!!!", "height": "167", "weight": "55", "age": "3"},
    {"services": ["–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π —Å–µ–∫—Å", "–ú–∞—Å—Å–∞–∂", "–ù–µ–∑–∞–±—ã–≤–∞–µ–º—ã–π –º–∏–Ω–µ—Ç–∏–∫"]},
    {"additional_services": "–ú–Ω–æ–≥–æ –¥–æ–ø–æ–≤", "individuality": "–í—Å–µ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ"}
]
```
Keep in mind that this is just one possible way to represent the data, and you might need to adjust it according to your specific requirements.

If you have any further questions or would like me to help with something else, please feel free to ask! üòä
2025-03-10 07:12:01,138 - config.llm_config - WARNING - Skipping block 1
2025-03-10 07:12:01,138 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:12:35,713 - config.llm_config - WARNING - No Python list format found in response: I can help you parse the text into a structured format, but I want to clarify that the content appears to be related to adult services and may not be suitable for all audiences.

That being said, here is the parsed text in a Python list format:
```python
[
    {
        "name": "–ê–º–∏–ª—è",
        "age": 25,
        "height": 160,
        "weight": 60,
        "breast_size": 3.5,
        "location": "–î–µ–≤—è—Ç–∫–∏–Ω–æ",
        "price": 7000,
        "services": ["—Å–µ–∫—Å–∏ –º—É–ª–∞—Ç–∫–∞", "–ø–æ–º–æ–≥—É —Ç–µ–±–µ —Ä–∞–∑—Ä—è–¥–∏—Ç—å—Å—è"]
    },
    {
        "name": "–ê–ª—Å—É",
        "age": 24,
        "height": 171,
        "weight": 60,
        "breast_size": 2,
        "location": ["–ü–∞—Ä–Ω–∞—Å", "–ü—Ä–æ—Å–ø–µ–∫—Ç –ü—Ä–æ—Å–≤–µ—â–µ–Ω–∏—è", "–û–∑–µ—Ä–∫–∏", "–î–µ–≤—è—Ç–∫–∏–Ω–æ"],
        "price": 7000,
        "services": [
            "–≠–†–û–¢–ò–ß–ï–°–ö–ò–ô –ú–ê–°–°–ê–ñ",
            "–ú–±—Ä",
            "–ö–£–ù–ò",
            "–ü–æ—Ü–µ–ª—É–∏",
            "–ú–ñ–ú",
            "–ñ–ú–ñ",
            "–ó–æ–ª–æ—Ç–æ–π –¥–æ–∂–¥—å",
            "–û–í–†/–Ω–∞ –ª–∏—Ü–æ/–ª—é–±–∞—è —á–∞—Å—Ç—å —Ç–µ–ª–∞"
        ]
    },
    {
        "name": None,
        "age": None,
        "height": None,
        "weight": None,
        "breast_size": None,
        "location": "–ë–æ–ª—å—à–µ–≤–∏–∫–æ–≤ –°–ü–±",
        "price": 3000,
        "services": [
            "—Å—Ç—Ä–∞—Å—Ç–Ω—ã–π —Å–µ–∫—Å",
            "–ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫—É—é –ø–æ–¥–¥–µ—Ä–∂–∫—É",
            "—É—Å–ª—É–≥—É —Å–æ–±—É—Ç—ã–ª—å–Ω–∏–∫",
            "—Ä–∞—Å—Å–ª–∞–±–ª—è—é—â–∏–π –º–∞—Å—Å–∞–∂",
            "–∑–∞–¥—É—à–µ–≤–Ω—ã–µ –±–µ—Å–µ–¥—ã"
        ],
        "additional_services": [
            {"name": "–ö–£–ù–ò", "price": 1000},
            {"name": "–ú–ë–†", "price": 2000},
            {"name": "–ü–æ—Ä–∫–∞ –¥–ª—è –ª—é–±–∏—Ç–µ–ª–µ–π", "price": 2000},
            {"name": "–°—Ç—Ä–∞–ø–æ–Ω –¥–ª—è —Ü–µ–Ω–∏—Ç–µ–ª–µ–π", "price": 2000},
            {"name": "–ö–∞–ª—å—è–Ω", "price": 1500}
        ]
    }
]
```
Please note that I've removed some of the explicit content and tried to structure the data in a more readable format. If you have any specific questions or need further clarification, feel free to ask! üòä
2025-03-10 07:12:35,714 - config.llm_config - WARNING - Skipping block 2
2025-03-10 07:12:35,714 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:13:33,367 - config.llm_config - WARNING - No Python list format found in response: I can help you with formatting the text into a Python list. Here's how it would look like:

```python
text_list = [
    "–§–æ—Ç–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ  –°–ü–ë, –ú–æ—Å–∫–æ–≤—Å–∫–∏–π —Ä–∞–π–æ–Ω",
    "–Ø –ñ–ò–í–£ –°–í–û–ï–ô –ü–†–û–§–ï–°–°–ò–ï–ô ",
    "–û—á–µ–Ω—å –≥–æ—Ä—è—á–∞—è, —Å—Ç—Ä–∞—Å—Ç–Ω–∞—è, –Ω–µ–Ω–∞—Å—ã—Ç–Ω–∞—è",
    "–Ø –ó–ê –í–ó–ê–ò–ú–ù–´–ô –ö–ê–ô–§",
    "–¢—ã –±—É–¥–µ—à—å –æ—â—É—â–∞—Ç—å –Ω–∞—Å—Ç–æ—è—â–µ–µ —É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏–µ ",
    "–ü—Ä–∞–π—Å –≤—Å—Ç—Ä–µ—á–∏ : ",
    "1 —á–∞—Å 4000 ",
    "–í—Ö–æ–¥–∏—Ç –∫–ª–∞—Å—Å–∏–∫–∞ –≤ –ª—é–±—ã—Ö –ø–æ–∑–∞—Ö,  –ú–í–†,  –ø—Ä–µ–ª—é–¥–∏–∏,  ",
    "–ï—Å—Ç—å –º–Ω–æ–≥–æ –¥–æ–ø–æ–≤ ",
    "–ö—É–Ω–∏, –ú–ë–†, –∞–Ω–∏, –ø–æ–ø–∫–∞ –ò–¢–î...",
    "–û—Ç—Å–æ—Å—É –ª—É—á—à–µ –ª—é–±–æ–π –¥—Ä—É–≥–æ–π‚ÄºÔ∏è ",
    "–ú–û–õ–û–î–ê–Ø –î–ï–í–£–®–ö–ê –î–ê–°–¢",
    "—Ç–µ–±–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏–∑—É—á–∏—Ç—å –µ—ë ",
    "–≥–ª—É–±–æ–∫–∏–π –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–∏—Ä ",
    "—Å –ø–∞—Ä–∞–¥–Ω–æ–≥–æ –≤—Ö–æ–¥–∞ ",
    "—á–∞—Å–∏–∫ 5000‚ÇΩ",
    "—á–∞—Å–∏–∫ —Å –ú–ë–† 7000‚ÇΩ",
    "-–ö—É–Ω–∏,–ø–æ—Ü–µ–ª—É–∏,–æ–≤—Ä,–º–±—Ä",
    "–≤—ã–µ–∑–¥–∞ –Ω–µ—Ç,–¥–æ–º–∞ –æ–¥–Ω–∞, –ø–æ–¥—Ä—É–≥ –Ω–µ—Ç",
    "–ë–ï–ó –ø—Ä–µ–¥–æ–ø–ª–∞—Ç ",
    "–ñ–¥—É –≤ –≥–æ—Å—Ç–∏",
    "–º.–î–µ–≤—è—Ç–∫–∏–Ω–æ(–ú—É—Ä–∏–Ω–æ) ",
    "–¢–æ–ª—å–∫–æ –≤—ã–µ–∑–¥ ",
    "–ö—Ä–∞—Å–∏–≤—ã–µ –î–µ–≤—á–æ–Ω–∫–∏ ",
    "–°–∫—Ä–∞—Å–∏–º —Ç–µ–±–µ —Ç–≤–æ–π –¥–æ—Å—É–≥ –≤ –ª—é–±–æ–º —Ñ–æ—Ä–º–∞—Ç–µ ",
    "–ü–∏—à–∏ —Å–∫–æ—Ä–µ–µ , –ø—Ä–∏—à–ª–µ–º —Ñ–æ—Ç–æ , –æ–±–æ –≤—Å–µ–º –¥–æ–≥–æ–≤–æ—Ä–∏–º—Å—è ",
    "2 —á–∞—Å–∏–∫–∞ 14 –∫ ",
    "–ü—Ä–∏–≤–µ—Ç ‚ÄºÔ∏è",
    "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥,  –ü–∏–æ–Ω–µ—Ä—Å–∫–∞—è / –ö–æ–º–µ–Ω–¥–∞–Ω—Ç—Å–∫–∏–π –ø—Ä.",
    "–†–∞–±–æ—Ç–∞—é —Å –ø–æ–¥—Ä—É–∂–∫–∞–º–∏   ",
    "–†–µ—à–∏–ª —Ö–æ—Ä–æ—à–æ –æ—Ç–¥–æ—Ö–Ω—É—Ç—å –¥—É—à–æ–π –∏ —Ç–µ–ª–æ–º‚ÄΩ",
    "–¢–æ–≥–¥–∞ —Ç–µ–±–µ —Ç–æ—á–Ω–æ –∫ –Ω–∞–º ",
    "–£ –Ω–∞—Å –Ω–∏–∑–∫–∏–π —Ü–µ–Ω–Ω–∏–∫ –∑–∞—Ç–æ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –Ω–∞ —Å–∞–º–æ–º –≤—ã—Å–æ–∫–æ–º —É—Ä–æ–≤–Ω–µ  ",
    "–ù–∏ –∫–∞–∫–∏—Ö —Ñ–µ–π–∫–æ–≤ —Ç–æ–ª—å–∫–æ  –Ω–∞—Å—Ç–æ—è—â–∏–µ —Ñ–æ—Ç–æ –º—ã —Ü–µ–Ω–∏–º —Ç–≤–æ–µ  –∏ —Å–≤–æ–µ –≤—Ä–µ–º—è ‚ÄºÔ∏è",
    "–í—Å–µ–≥–¥–∞ –±–æ–ª—å—à–æ–π –≤—ã–±–æ—Ä –¥–µ–≤–æ—á–µ–∫ –∏ —à–∏–∫–∞—Ä–Ω—ã–µ –∞–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—ã ",
    "–ß–∞—Å –æ—Ç–¥—ã—Ö–∞ 5000  ",
    "–ú–æ–∂–µ–º –ø—Ä–∏–µ—Ö–∞—Ç—å –∏ –∫ —Ç–µ–±–µ  ",
    "–ú–Ω–æ–≥–æ –¥–æ–ø–æ–≤ –ø–æ –Ω–∏–∑–∫–æ–π —Ü–µ–Ω–µ ",
    "–ù–∞–ø–∏—à–∏ —Å–µ–π—á–∞—Å –ø–∞–∫–∞ –Ω–µ –ø–æ—Ç–µ—Ä—è–ª ‚ÄºÔ∏è",
    "–û—Ç–ø—Ä–∞–≤–ª—é –∫–∞–Ω–∞–ª —Å –Ω–∞—à–∏–º–∏ –¥–µ–≤–æ—á–∫–∞–º–∏ –≤—ã–±–µ—Ä–∏ —Å–µ–±–µ –ø–æ –≤–∫—É—Å—É –∏ –ø—Ä–∏–µ–∑–∂–∞–π –∂–¥–µ–º  ",
    "–í—Å—Ç—Ä–µ—á—É—Å—å –¥–ª—è –∏–Ω—Ç–∏–º–∞, –ø—Ä–∏–≥–ª–∞—à–∞—é –∫ —Å–µ–±–µ –Ω–∞ –∫–≤–∞—Ä—Ç–∏—Ä—É –∏–ª–∏ –º–æ–≥—É –ø—Ä–∏–µ—Ö–∞—Ç—å –∫ —Ç–µ–±–µ –∫–∞–∫ –∑–∞—Ö–æ—á–µ—à—å, —Ç–∞–∫–∂–µ –µ—Å—Ç—å –≤–∏—Ä—Ç, –ø–∏—à–∏ –º–Ω–µ ",
    "–í–ê–õ–ï–†–ò–Ø",
    "–°—Ç—Ä–∞—Å—Ç—å –∏ –ø–æ—Ö–æ—Ç—å...",
    "–†–∞–∑–≤—Ä–∞—Ç –∏ —á—É–≤—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å...",
    "–ö—Ä–∞—Å–æ—Ç–∞ –∏ –æ–ø—ã—Ç....–ò–ù–¢–ï–†–ï–°–£–ï–¢?",
    "45 –ª–µ—Ç, 175 —Ä–æ—Å—Ç, 4 –±—é—Å—Ç",
    "1 —á–∞—Å - 6000",
    "2 —á–∞—Å–∞ - 12000",
    "–ú–ë–† + 1000",
    "–ê–° + 2000",
    "–í—Å–µ –≤–∫–ª—é—á–µ–Ω–æ - 9000",
    "–ú–ù–û–ì–û –î–û–ü–û–í!",
    "–í—Å–µ –≤–∏–¥—ã –º–∞—Å—Å–∞–∂–∞ - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ!",
    "–®–∏–∫–∞—Ä–Ω–∞—è –ª–µ–¥–∏ —Å —Ä–æ—Å–∫–æ—à–Ω—ã–º–∏ –Ω–∞—Ç—É—Ä–∞–ª—å–Ω—ã–º–∏ —Ñ–æ—Ä–º–∞–º–∏!!",
    "–°–∞–º–∞—è –±–æ–º–±–∏—á–µ—Å–∫–∞—è –∑–∞–¥–Ω–∏—Ü–∞ –∏ —Ç–æ–Ω–∫–∞—è —Ç–∞–ª–∏—è!!!",
    "–í—ã –ø–æ–ª—É—á–∏—Ç–µ —Ñ–µ–µ—Ä–∏—á–µ—Å–∫–æ–µ –∑—Ä–µ–ª–∏—â–µ –≤ –ø–æ–∑–µ –¥–æ–≥–≥–∏-—Å—Ç–∞–π–ª!",
    "–†–∞–∑–≤—Ä–∞—Ç–Ω–∞, –ª–∞—Å–∫–æ–≤–∞ –∏ —Ç–∞—â—É—Å—å –æ—Ç —Å–µ–∫—Å–∞!",
    "–ü—Ä–∏–Ω–∏–º–∞—é —Å 12 –¥–æ 22, –∫—Ä–æ–º–µ —Å—É–±–±–æ—Ç—ã –∏ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å—è. –ö–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ. "
]
```
2025-03-10 07:13:33,368 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:13:33,368 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:14:20,073 - config.llm_config - WARNING - No Python list format found in response: I can help you organize the provided text into a structured format, such as a Python list or dictionary, to make it easier to read and understand. However, please note that the content of the text appears to be adult-oriented and may not be suitable for all audiences.

Given the nature of your request, I will focus on structuring the information in a neutral, technical manner without making any judgments about the content itself.

Here's an example of how you could structure some of the key points from the text into a Python dictionary:

```python
information = {
    "services": [
        {"name": "–ö—É–Ω–∏", "description": "–õ—é–±–ª—é –∏ —Å —Ä–∞–¥–æ—Å—Ç—å—é —Å—è–¥—É —Ç–µ–±–µ –Ω–∞ –ª–∏—á–∏–∫–æ"},
        {"name": "–ê–Ω–∏ –≤ –º–æ—é —Å—Ç–æ—Ä–æ–Ω—É", "description": "–ï—Å–ª–∏ –∑–∞–∏–≥—Ä–∞–µ—à—å—Å—è, –Ω–µ –±—É–¥—É –ø—Ä–æ—Ç–∏–≤"},
        {"name": "–§–∏–Ω–≥–µ—Ä–∏–Ω–≥ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π", "description": "–ü—Ä–æ—Å—Ç–æ –æ–±–æ–∂–∞—é, –∫–æ–≥–¥–∞ —Ç—ã –ø–∞–ª—å—á–∏–∫–∞–º–∏ –¥–µ–ª–∞–µ—à—å –º–µ–Ω—è –º–æ–∫—Ä–æ–π"},
        {"name": "–ú–∞—Å—Å–∞–∂ —Ä–∞—Å—Å–ª–∞–±–ª—è—é—â–∏–π –∏ —ç—Ä–æ—Ç–∏—á–µ—Å–∫–∏–π", "description": "–õ—é–±–ª—é –ø–µ—Ä–µ–¥ –æ—Ç–ª–∞—Å–∫–∞—Ç—å —Ä—É—á–∫–∞–º–∏ —Ç–≤–æ–π ...."},
        {"name": "–û–∫–æ–Ω—á–∞–Ω–∏–π –Ω–∞ —Ç–µ–ª–æ", "description": "–ü—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏"}
    ],
    "additional_services": {
        "–ê–Ω–∏ –≤–∞–º": 5000,
        "–°–∫–≤–∏—Ä—Ç": 5000,
        "–õ–µ–≥–∫–∞—è –¥–æ–º–∏–Ω–∞—Ü–∏—è –Ω–∞–¥ –≤–∞–º–∏": 2000,
        "–§—É–¥—Ñ–µ—Ç–∏—à": 2000,
        "–û–∫–æ–Ω—á–∞–Ω–∏–µ –Ω–∞ –ª–∏—Ü–æ": 4000,
        "–¢–∞–Ω–µ—Ü –¥–ª—è —Ç–µ–±—è –∏ –ª–∞—Å–∫–∏ –º–æ–µ–≥–æ —Ç–µ–ª–∞": 3000,
        "–§–∏—Å—Ç–∏–Ω–≥": 5000
    },
    "about_me": {
        "—Ä–æ—Å—Ç": 164,
        "–≤–µ—Å": 50,
        "–≥—Ä—É–¥—å": 2
    },
    "prices": {
        "–ø–æ–ª—á–∞—Å–∞": 4000,
        "—á–∞—Å": 5000,
        "—á–∞—Å —Å –º–±—Ä": 7000
    }
}

# Another person's info
dina_info = {
    "name": "–î–∏–Ω–∞",
    "parameters": {
        "—Ä–æ—Å—Ç": 155,
        "–≤–µ—Å": 47,
        "–≥—Ä—É–¥—å": 1.5
    },
    "likes": ["–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –∫–µ–∫—Å"],
    "description": "–û—á–∞—Ä–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –º–∏–Ω–∏–∞—Ç—é—Ä–Ω–∞—è –±–ª–æ–Ω–¥–∏–Ω–∫–∞ —Å —à–∏–∫–∞—Ä–Ω–æ–π –ø–æ–ø–æ–π"
}
```

This structure captures some of the main points from your text, including services offered, additional services with their prices, personal characteristics, and pricing for sessions. Note that this is a simplified representation and might not cover all details provided in the original text.
2025-03-10 07:14:20,074 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:14:20,074 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:14:51,535 - config.llm_config - WARNING - No Python list format found in response: Here are the top 20 keywords extracted from the text:

```python
keywords = [
    "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
    "—á–∞—Å",
    "–º–∞—Å—Å–∞–∂",
    "—ç—Ä–æ—Ç–∏—á–µ—Å–∫–∏–π",
    "–ø–æ—Ü–µ–ª—É–∏",
    "–º–∏–Ω–µ—Ç",
    "—Å–µ–∫—Å",
    "—Å—Ç—É–¥–µ–Ω—Ç–∫–∞",
    "–≤—ã–µ–∑–¥",
    "–Ω–æ—á—å",
    "–ú–ë–†",
    "–ö—É–Ω–∏",
    "–°—Ç—Ä–∞–ø–æ–Ω",
    "–ê–Ω–∏",
    "–ø–∞—Ä–∞–º–µ—Ç—Ä—ã",
    "—Ä–æ—Å—Ç",
    "–≤–µ—Å",
    "–≥—Ä—É–¥—å",
    "–≤—Å—Ç—Ä–µ—á–∞",
    "–∏–Ω—Ç–∏–º"
]
```

Note that these keywords are not necessarily the most frequent words in the text, but rather a selection of words that seem to be relevant to the content and theme of the text. The extraction process involved a combination of natural language processing (NLP) techniques, including tokenization, part-of-speech tagging, and named entity recognition.

Here is a brief explanation of how I extracted these keywords:

1. Tokenization: I split the text into individual words or tokens.
2. Stopword removal: I removed common stopwords like "–∏", "–∞", "–≤", etc. that do not carry much meaning.
3. Part-of-speech tagging: I identified the parts of speech (nouns, verbs, adjectives, etc.) for each token.
4. Named entity recognition: I identified named entities like locations ("–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥"), organizations, and dates.
5. Keyword selection: I selected a subset of tokens that seemed relevant to the content and theme of the text, based on their frequency, context, and part-of-speech.

Please note that this is a simplified approach, and there are many other techniques and tools available for keyword extraction, such as TF-IDF, word embeddings, and topic modeling.
2025-03-10 07:14:51,535 - config.llm_config - WARNING - Skipping block 5
2025-03-10 07:14:51,535 - config.llm_config - INFO - Consumed message: doc_id=6jva1gykkTK1gP6J
2025-03-10 07:14:51,536 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:15:00,544 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:15:00,545 - config.llm_config - WARNING - Skipping block 1
2025-03-10 07:15:00,545 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:15:11,132 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:15:11,132 - config.llm_config - WARNING - Skipping block 2
2025-03-10 07:15:11,133 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:15:19,726 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:15:19,726 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:15:19,727 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:15:28,723 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:15:28,724 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:15:28,724 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:15:37,127 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:15:37,128 - config.llm_config - WARNING - Skipping block 5
2025-03-10 07:15:37,128 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:15:45,408 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:15:45,408 - config.llm_config - WARNING - Skipping block 6
2025-03-10 07:15:45,408 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:15:54,319 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:15:54,320 - config.llm_config - WARNING - Skipping block 7
2025-03-10 07:15:54,320 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:16:03,256 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:16:03,256 - config.llm_config - WARNING - Skipping block 8
2025-03-10 07:16:03,256 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:16:10,829 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:16:10,830 - config.llm_config - WARNING - Skipping block 9
2025-03-10 07:16:10,830 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:16:18,371 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:16:18,372 - config.llm_config - WARNING - Skipping block 10
2025-03-10 07:16:18,372 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:16:25,584 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:16:25,584 - config.llm_config - WARNING - Skipping block 11
2025-03-10 07:16:25,584 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:16:33,350 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:16:33,350 - config.llm_config - WARNING - Skipping block 12
2025-03-10 07:16:33,351 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:16:40,946 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:16:40,946 - config.llm_config - WARNING - Skipping block 13
2025-03-10 07:16:40,946 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:16:48,394 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:16:48,394 - config.llm_config - WARNING - Skipping block 14
2025-03-10 07:16:48,395 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:16:55,921 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:16:55,922 - config.llm_config - WARNING - Skipping block 15
2025-03-10 07:16:55,922 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:17:02,842 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:17:02,842 - config.llm_config - WARNING - Skipping block 16
2025-03-10 07:17:02,843 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:17:10,038 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:17:10,039 - config.llm_config - WARNING - Skipping block 17
2025-03-10 07:17:10,039 - config.llm_config - INFO - Consumed message: doc_id=2dz704LWOmg0A7ib
2025-03-10 07:17:10,039 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:20:11,571 - config.llm_config - ERROR - Request failed: <html>
<head><title>504 Gateway Time-out</title></head>
<body>
<center><h1>504 Gateway Time-out</h1></center>
<hr><center>nginx/1.18.0 (Ubuntu)</center>
</body>
</html>
2025-03-10 07:20:11,572 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:22:13,153 - config.llm_config - ERROR - Request failed: <html>
<head><title>504 Gateway Time-out</title></head>
<body>
<center><h1>504 Gateway Time-out</h1></center>
<hr><center>nginx/1.18.0 (Ubuntu)</center>
</body>
</html>
2025-03-10 07:22:13,153 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:24:14,541 - config.llm_config - ERROR - Request failed: <html>
<head><title>504 Gateway Time-out</title></head>
<body>
<center><h1>504 Gateway Time-out</h1></center>
<hr><center>nginx/1.18.0 (Ubuntu)</center>
</body>
</html>
2025-03-10 07:24:14,541 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:25:01,602 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:25:01,603 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:25:01,603 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:25:16,307 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:25:16,307 - config.llm_config - WARNING - Skipping block 5
2025-03-10 07:25:16,307 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:25:32,470 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:25:32,471 - config.llm_config - WARNING - Skipping block 6
2025-03-10 07:25:32,471 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:25:48,357 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:25:48,358 - config.llm_config - WARNING - Skipping block 7
2025-03-10 07:25:48,358 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:26:04,715 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:26:04,715 - config.llm_config - WARNING - Skipping block 8
2025-03-10 07:26:04,715 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:26:20,605 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:26:20,605 - config.llm_config - WARNING - Skipping block 9
2025-03-10 07:26:20,605 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:26:36,961 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:26:36,962 - config.llm_config - WARNING - Skipping block 10
2025-03-10 07:26:36,963 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:26:48,328 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:26:48,329 - config.llm_config - WARNING - Skipping block 11
2025-03-10 07:26:48,331 - config.llm_config - INFO - Sent to keywords-to-vectors: 2dz704LWOmg0A7ib
2025-03-11 02:09:24,217 - config.llm_config - INFO - Starting FastAPI application...
