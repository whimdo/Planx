2025-03-03 06:35:24,830 - config.config - INFO - Received request: text length=823, keyword_count=20
2025-03-03 06:35:24,831 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Cookin... and keyword_count: 20
2025-03-03 06:35:24,831 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:35:29,006 - config.config - INFO - AI response received successfully
2025-03-03 06:35:29,007 - config.config - INFO - Insufficient keywords (10/20): ['meal', 'food', 'recipe', 'ingredients', 'cuisine', 'flavors', 'dishes', 'cooking', 'chefs', 'restaurant']
2025-03-03 06:35:29,007 - config.config - INFO - Filtered keywords: ['meal', 'food', 'recipe', 'ingredients', 'cuisine', 'flavors', 'dishes', 'cooking', 'chefs', 'restaurant', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:35:29,008 - config.config - INFO - Returning keywords: ['meal', 'food', 'recipe', 'ingredients', 'cuisine', 'flavors', 'dishes', 'cooking', 'chefs', 'restaurant', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:37:32,426 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 06:37:32,427 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 06:37:32,427 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:37:33,022 - config.config - INFO - AI response received successfully
2025-03-03 06:37:33,023 - config.config - INFO - Filtered keywords: ['recipe', 'meal', 'food', 'ingredients', 'dish', 'flavors', 'cuisine', 'techniques', 'taste', 'presentation']
2025-03-03 06:37:33,024 - config.config - INFO - Returning keywords: ['recipe', 'meal', 'food', 'ingredients', 'dish', 'flavors', 'cuisine', 'techniques', 'taste', 'presentation']
2025-03-03 06:41:27,356 - config.config - INFO - Received request: text length=7241, keyword_count=10
2025-03-03 06:41:27,356 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Hi. Do... and keyword_count: 10
2025-03-03 06:41:27,357 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:41:28,386 - config.config - INFO - AI response received successfully
2025-03-03 06:41:28,387 - config.config - INFO - Filtered keywords: ['crypto', 'com', 'scammer', 'reminder', 'telegram', 'cro', 'price', 'investment', 'advice', 'scams']
2025-03-03 06:41:28,388 - config.config - INFO - Returning keywords: ['crypto', 'com', 'scammer', 'reminder', 'telegram', 'cro', 'price', 'investment', 'advice', 'scams']
2025-03-03 06:41:49,725 - config.config - INFO - Received request: text length=7241, keyword_count=20
2025-03-03 06:41:49,726 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Hi. Do... and keyword_count: 20
2025-03-03 06:41:49,726 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:41:50,705 - config.config - INFO - AI response received successfully
2025-03-03 06:41:50,706 - config.config - INFO - Insufficient keywords (10/20): ['crypto', 'com', 'scammer', 'reminder', 'important', 'message', 'private', 'telegram', 'channel', 'announcements']
2025-03-03 06:41:50,707 - config.config - INFO - Filtered keywords: ['crypto', 'com', 'scammer', 'reminder', 'important', 'message', 'private', 'telegram', 'channel', 'announcements', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:41:50,707 - config.config - INFO - Returning keywords: ['crypto', 'com', 'scammer', 'reminder', 'important', 'message', 'private', 'telegram', 'channel', 'announcements', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:42:04,245 - config.config - INFO - Received request: text length=7241, keyword_count=10
2025-03-03 06:42:04,245 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Hi. Do... and keyword_count: 10
2025-03-03 06:42:04,246 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:42:05,230 - config.config - INFO - AI response received successfully
2025-03-03 06:42:05,232 - config.config - INFO - Filtered keywords: ['crypto', 'scammer', 'reminder', 'group', 'investment', 'price', 'prediction', 'telegram', 'announcements', 'channel']
2025-03-03 06:42:05,232 - config.config - INFO - Returning keywords: ['crypto', 'scammer', 'reminder', 'group', 'investment', 'price', 'prediction', 'telegram', 'announcements', 'channel']
2025-03-03 06:42:36,161 - config.config - INFO - Received request: text length=7241, keyword_count=10
2025-03-03 06:42:36,162 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Hi. Do... and keyword_count: 10
2025-03-03 06:42:36,163 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-03 06:42:41,696 - config.config - INFO - AI response received successfully
2025-03-03 06:42:41,697 - config.config - INFO - Filtered keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'scams', 'bitcoin', 'ethereum']
2025-03-03 06:42:41,697 - config.config - INFO - Returning keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'scams', 'bitcoin', 'ethereum']
2025-03-03 06:43:02,085 - config.config - INFO - Received request: text length=7241, keyword_count=20
2025-03-03 06:43:02,086 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Hi. Do... and keyword_count: 20
2025-03-03 06:43:02,086 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-03 06:43:07,196 - config.config - INFO - AI response received successfully
2025-03-03 06:43:07,197 - config.config - INFO - Insufficient keywords (10/20): ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'group', 'official', 'important', 'reminder']
2025-03-03 06:43:07,197 - config.config - INFO - Filtered keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'group', 'official', 'important', 'reminder', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:43:07,198 - config.config - INFO - Returning keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'group', 'official', 'important', 'reminder', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:43:35,514 - config.config - INFO - Received request: text length=7241, keyword_count=50
2025-03-03 06:43:35,515 - config.config - INFO - Querying LLM with prompt: Extract the top 50 keywords from this text: Hi. Do... and keyword_count: 50
2025-03-03 06:43:35,516 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-03 06:43:40,671 - config.config - INFO - AI response received successfully
2025-03-03 06:43:40,672 - config.config - INFO - Insufficient keywords (10/50): ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'scams', 'group', 'official']
2025-03-03 06:43:40,672 - config.config - INFO - Filtered keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'scams', 'group', 'official', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:43:40,672 - config.config - INFO - Returning keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'scams', 'group', 'official', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:43:47,592 - config.config - INFO - Received request: text length=7241, keyword_count=50
2025-03-03 06:43:47,592 - config.config - INFO - Querying LLM with prompt: Extract the top 50 keywords from this text: Hi. Do... and keyword_count: 50
2025-03-03 06:43:47,592 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-03 06:43:49,484 - config.config - INFO - AI response received successfully
2025-03-03 06:43:49,485 - config.config - INFO - Insufficient keywords (10/50): ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'group', 'official', 'important', 'reminder', 'scams']
2025-03-03 06:43:49,485 - config.config - INFO - Filtered keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'group', 'official', 'important', 'reminder', 'scams', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:43:49,486 - config.config - INFO - Returning keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'group', 'official', 'important', 'reminder', 'scams', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:44:35,501 - config.config - INFO - Received request: text length=7241, keyword_count=15
2025-03-03 06:44:35,502 - config.config - INFO - Querying LLM with prompt: Extract the top 15 keywords from this text: Hi. Do... and keyword_count: 15
2025-03-03 06:44:35,502 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-03 06:44:40,634 - config.config - INFO - AI response received successfully
2025-03-03 06:44:40,635 - config.config - INFO - Insufficient keywords (10/15): ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'investment', 'price', 'scams', 'group', 'official']
2025-03-03 06:44:40,636 - config.config - INFO - Filtered keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'investment', 'price', 'scams', 'group', 'official', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:44:40,636 - config.config - INFO - Returning keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'investment', 'price', 'scams', 'group', 'official', 'default', 'default', 'default', 'default', 'default']
2025-03-03 06:45:44,286 - config.config - INFO - Received request: text length=7241, keyword_count=15
2025-03-03 06:45:44,286 - config.config - INFO - Querying LLM with prompt: Extract the top 15 keywords from this text: Hi. Do... and keyword_count: 15
2025-03-03 06:45:44,286 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-03 06:45:51,629 - config.config - INFO - AI response received successfully
2025-03-03 06:45:51,631 - config.config - INFO - Filtered keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'scams', 'group', 'official', 'announcements', 'channel', 'news', 'updates', 'insights', 'security', 'tips', 'reminder', 'team', 'support', 'ambassadors', 'moderators']
2025-03-03 06:45:51,631 - config.config - INFO - Returning keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'scams', 'group', 'official', 'announcements', 'channel', 'news', 'updates', 'insights']
2025-03-03 06:46:26,749 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 06:46:26,749 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 06:46:26,749 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:46:27,349 - config.config - INFO - AI response received successfully
2025-03-03 06:46:27,349 - config.config - INFO - Filtered keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'aroma']
2025-03-03 06:46:27,351 - config.config - INFO - Returning keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'aroma']
2025-03-03 06:46:28,896 - config.config - INFO - Received request: text length=7241, keyword_count=25
2025-03-03 06:46:28,896 - config.config - INFO - Querying LLM with prompt: Extract the top 25 keywords from this text: Hi. Do... and keyword_count: 25
2025-03-03 06:46:28,896 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-03 06:46:39,848 - config.config - INFO - AI response received successfully
2025-03-03 06:46:39,849 - config.config - INFO - Filtered keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'group', 'official', 'reminder', 'important', 'scams', 'protect', 'pinned', 'messages', 'buy', 'sell', 'earn', 'defi', 'bitcoin', 'ethereum', 'finance', 'lending', 'polkadot', 'trust', 'upgrade', 'revenue', 'trading', 'volume', 'spread', 'brokerage', 'service', 'xrp', 'prices', 'announcements', 'channel', 'news', 'updates', 'insights', 'onchain', 'wallet', 'lcro', 'delisted']
2025-03-03 06:46:39,849 - config.config - INFO - Returning keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'group', 'official', 'reminder', 'important', 'scams', 'protect', 'pinned', 'messages', 'buy', 'sell', 'earn', 'defi', 'bitcoin', 'ethereum', 'finance', 'lending', 'polkadot', 'trust']
2025-03-03 06:46:40,057 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 06:46:40,057 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 06:46:40,057 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:46:40,586 - config.config - INFO - AI response received successfully
2025-03-03 06:46:40,587 - config.config - INFO - Filtered keywords: ['food', 'meal', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'aroma']
2025-03-03 06:46:40,587 - config.config - INFO - Returning keywords: ['food', 'meal', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'aroma']
2025-03-03 06:47:06,073 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 06:47:06,074 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 06:47:06,074 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:47:06,606 - config.config - INFO - AI response received successfully
2025-03-03 06:47:06,606 - config.config - INFO - Filtered keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma']
2025-03-03 06:47:06,607 - config.config - INFO - Returning keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma']
2025-03-03 06:47:09,446 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 06:47:09,446 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 06:47:09,446 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:47:09,984 - config.config - INFO - AI response received successfully
2025-03-03 06:47:09,985 - config.config - INFO - Filtered keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques']
2025-03-03 06:47:09,985 - config.config - INFO - Returning keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques']
2025-03-03 06:47:13,212 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 06:47:13,212 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 06:47:13,213 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:47:13,756 - config.config - INFO - AI response received successfully
2025-03-03 06:47:13,757 - config.config - INFO - Filtered keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma']
2025-03-03 06:47:13,757 - config.config - INFO - Returning keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma']
2025-03-03 06:48:40,277 - config.config - INFO - Received request: text length=7241, keyword_count=18
2025-03-03 06:48:40,277 - config.config - INFO - Querying LLM with prompt: Extract the top 18 keywords from this text: Hi. Do... and keyword_count: 18
2025-03-03 06:48:40,277 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-03 06:48:50,529 - config.config - INFO - AI response received successfully
2025-03-03 06:48:50,531 - config.config - INFO - Filtered keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'scams', 'group', 'official', 'announcements', 'channel', 'news', 'updates', 'insights', 'security', 'tips', 'finance', 'decentralized', 'bitcoin', 'ethereum', 'defi', 'lending', 'polkadot', 'trust', 'pectra', 'upgrade', 'brokerage', 'service', 'revenue', 'trading', 'volume', 'xrp', 'prices', 'spread', 'buy', 'sell', 'cdc']
2025-03-03 06:48:50,531 - config.config - INFO - Returning keywords: ['crypto', 'scammer', 'cro', 'telegram', 'crypto', 'price', 'investment', 'scams', 'group', 'official', 'announcements', 'channel', 'news', 'updates', 'insights', 'security', 'tips', 'finance']
2025-03-03 06:55:31,010 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 06:55:31,010 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 06:55:31,010 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:55:31,538 - config.config - INFO - AI response received successfully
2025-03-03 06:55:31,539 - config.config - INFO - Filtered keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'presentation']
2025-03-03 06:55:31,539 - config.config - INFO - Returning keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'presentation']
2025-03-03 06:58:05,325 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 06:58:05,327 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 06:58:05,328 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 06:58:05,974 - config.config - INFO - AI response received successfully
2025-03-03 06:58:05,975 - config.config - INFO - Filtered keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'aroma']
2025-03-03 06:58:05,975 - config.config - INFO - Returning keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'aroma']
2025-03-03 08:47:55,815 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 08:47:55,817 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 08:47:55,817 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 08:47:59,759 - config.config - INFO - AI response received successfully
2025-03-03 08:47:59,761 - config.config - INFO - Filtered keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'restaurant']
2025-03-03 08:47:59,761 - config.config - INFO - Returning keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'restaurant']
2025-03-03 08:51:34,884 - config.config - INFO - Received request: text length=823, keyword_count=20
2025-03-03 08:51:34,885 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Cookin... and keyword_count: 20
2025-03-03 08:51:34,885 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 08:51:35,791 - config.config - INFO - AI response received successfully
2025-03-03 08:51:35,792 - config.config - INFO - Filtered keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma', 'texture', 'presentation', 'restaurants', 'dining', 'kitchen', 'meat', 'vegetable', 'seasonal']
2025-03-03 08:51:35,792 - config.config - INFO - Returning keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma', 'texture', 'presentation', 'restaurants', 'dining', 'kitchen', 'meat', 'vegetable', 'seasonal']
2025-03-03 08:52:14,268 - config.config - INFO - Received request: text length=823, keyword_count=20
2025-03-03 08:52:14,268 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Cookin... and keyword_count: 20
2025-03-03 08:52:14,268 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 08:52:15,132 - config.config - INFO - AI response received successfully
2025-03-03 08:52:15,133 - config.config - INFO - Filtered keywords: ['recipe', 'meal', 'food', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma', 'texture', 'presentation', 'restaurants', 'dining', 'kitchens', 'cooks', 'meats', 'vegetables', 'herbs']
2025-03-03 08:52:15,133 - config.config - INFO - Returning keywords: ['recipe', 'meal', 'food', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma', 'texture', 'presentation', 'restaurants', 'dining', 'kitchens', 'cooks', 'meats', 'vegetables', 'herbs']
2025-03-03 08:53:17,024 - config.config - INFO - Received request: text length=823, keyword_count=20
2025-03-03 08:53:17,024 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Cookin... and keyword_count: 20
2025-03-03 08:53:17,025 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 08:53:17,886 - config.config - INFO - AI response received successfully
2025-03-03 08:53:17,888 - config.config - INFO - Filtered keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma', 'texture', 'presentation', 'restaurants', 'dining', 'cooks', 'kitchens', 'family', 'dinner', 'restaurant']
2025-03-03 08:53:17,888 - config.config - INFO - Returning keywords: ['meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma', 'texture', 'presentation', 'restaurants', 'dining', 'cooks', 'kitchens', 'family', 'dinner', 'restaurant']
2025-03-03 10:28:54,976 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 10:28:54,977 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 10:28:54,977 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 10:28:58,839 - config.config - INFO - AI response received successfully
2025-03-03 10:28:58,840 - config.config - INFO - Filtered keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques']
2025-03-03 10:28:58,840 - config.config - INFO - Returning keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques']
2025-03-03 10:29:04,571 - config.config - INFO - Received request: text length=823, keyword_count=10
2025-03-03 10:29:04,571 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Cookin... and keyword_count: 10
2025-03-03 10:29:04,572 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 10:29:05,098 - config.config - INFO - AI response received successfully
2025-03-03 10:29:05,099 - config.config - INFO - Filtered keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'restaurant']
2025-03-03 10:29:05,099 - config.config - INFO - Returning keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'restaurant']
2025-03-03 10:31:28,330 - config.config - INFO - Received request: text length=458, keyword_count=10
2025-03-03 10:31:28,330 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Bruise... and keyword_count: 10
2025-03-03 10:31:28,330 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 10:31:28,927 - config.config - INFO - AI response received successfully
2025-03-03 10:31:28,928 - config.config - INFO - Filtered keywords: ['zelensky', 'ukrainian', 'trump', 'vance', 'stansted', 'airport', 'british', 'summit', 'leaders', 'president']
2025-03-03 10:31:28,928 - config.config - INFO - Returning keywords: ['zelensky', 'ukrainian', 'trump', 'vance', 'stansted', 'airport', 'british', 'summit', 'leaders', 'president']
2025-03-03 10:33:21,041 - config.config - INFO - Received request: text length=4519, keyword_count=10
2025-03-03 10:33:21,042 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Bruise... and keyword_count: 10
2025-03-03 10:33:21,042 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 10:33:21,814 - config.config - INFO - AI response received successfully
2025-03-03 10:33:21,815 - config.config - INFO - Filtered keywords: ['zelensky', 'ukraine', 'trump', 'macron', 'uk', 'us', 'russia', 'putin', 'nato', 'war']
2025-03-03 10:33:21,815 - config.config - INFO - Returning keywords: ['zelensky', 'ukraine', 'trump', 'macron', 'uk', 'us', 'russia', 'putin', 'nato', 'war']
2025-03-03 10:39:30,864 - config.config - INFO - Received request: text length=2115, keyword_count=10
2025-03-03 10:39:30,864 - config.config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: BREAKI... and keyword_count: 10
2025-03-03 10:39:30,864 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-03 10:39:31,536 - config.config - INFO - AI response received successfully
2025-03-03 10:39:31,536 - config.config - INFO - Filtered keywords: ['cryptocurrency', 'tokens', 'governance', 'market', 'economy', 'investors', 'gdp', 'bitcoin', 'ethereum', 'blockchain']
2025-03-03 10:39:31,537 - config.config - INFO - Returning keywords: ['cryptocurrency', 'tokens', 'governance', 'market', 'economy', 'investors', 'gdp', 'bitcoin', 'ethereum', 'blockchain']
2025-03-04 06:29:06,515 - config.config - INFO - Received request: text length=823, keyword_count=20
2025-03-04 06:29:06,516 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Cookin... and keyword_count: 20
2025-03-04 06:29:06,516 - config.config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-04 06:29:10,953 - config.config - INFO - AI response received successfully
2025-03-04 06:29:10,954 - config.config - INFO - Filtered keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma', 'texture', 'presentation', 'restaurants', 'dining', 'kitchens', 'home', 'cooks', 'meat']
2025-03-04 06:29:10,954 - config.config - INFO - Returning keywords: ['cooking', 'meal', 'food', 'recipe', 'ingredients', 'dish', 'chefs', 'cuisine', 'flavors', 'techniques', 'taste', 'aroma', 'texture', 'presentation', 'restaurants', 'dining', 'kitchens', 'home', 'cooks', 'meat']
2025-03-04 09:28:27,047 - config.config - INFO - Received request: text length=6, keyword_count=20
2025-03-04 09:28:27,048 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: string... and keyword_count: 20
2025-03-04 09:28:27,049 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-04 09:29:24,234 - config.config - INFO - AI response received successfully
2025-03-04 09:29:24,236 - config.config - INFO - Insufficient keywords (1/20): ['string']
2025-03-04 09:29:24,236 - config.config - INFO - Filtered keywords: ['string', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-04 09:29:24,237 - config.config - INFO - Returning keywords: ['string', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 02:26:31,836 - config.config - INFO - Produced data to Kafka topic doc2kywrd: doc_001
2025-03-05 02:26:31,839 - config.config - INFO - Starting Kafka consumer for topic: doc2kywrd
2025-03-05 02:26:31,839 - config.config - INFO - Starting FastAPI application...
2025-03-05 02:26:32,186 - config.config - INFO - Consumed message from Kafka topic doc2kywrd: doc_id=doc_001
2025-03-05 02:26:32,186 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: AI and... and keyword_count: 20
2025-03-05 02:26:32,186 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 02:28:01,325 - config.config - INFO - AI response received successfully
2025-03-05 02:28:01,327 - config.config - INFO - Filtered keywords: ['ai', 'machine', 'learning', 'transforming', 'tech', 'and', 'are', 'technology', 'artificial', 'intelligence', 'innovation', 'digital', 'future', 'industry', 'automation', 'data', 'science', 'computing', 'algorithms', 'systems']
2025-03-05 02:28:01,328 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Machin... and keyword_count: 20
2025-03-05 02:28:01,328 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 02:28:04,603 - config.config - INFO - AI response received successfully
2025-03-05 02:28:04,603 - config.config - INFO - Filtered keywords: ['machine', 'learning', 'news', 'trending', 'today', 'technology', 'artificial', 'intelligence', 'industry', 'innovation', 'data', 'science', 'computing', 'algorithm', 'model', 'training', 'neural', 'networks', 'deep', 'ai']
2025-03-05 02:28:04,604 - config.config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Tech d... and keyword_count: 20
2025-03-05 02:28:04,604 - config.config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 02:28:05,527 - config.config - INFO - AI response received successfully
2025-03-05 02:28:05,527 - config.config - INFO - Insufficient keywords (4/20): ['tech', 'data', 'innovation', 'drives']
2025-03-05 02:28:05,528 - config.config - INFO - Filtered keywords: ['tech', 'data', 'innovation', 'drives', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 02:28:05,649 - config.config - INFO - Processed and sent to Kafka topic kywrd 2vec: doc_001
2025-03-05 03:43:55,031 - config.llm_config - INFO - Produced data to Kafka topic document-to-keywords: doc_001
2025-03-05 03:43:55,032 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-05 03:43:55,033 - config.llm_config - INFO - Starting FastAPI application...
2025-03-05 03:43:55,406 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady2
2025-03-05 03:43:55,407 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Yeah b... and keyword_count: 20
2025-03-05 03:43:55,407 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 03:45:30,099 - config.llm_config - INFO - AI response received successfully
2025-03-05 03:45:30,102 - config.llm_config - INFO - Filtered keywords: ['crypto', 'cro', 'token', 'price', 'supply', 'demand', 'market', 'bitcoin', 'blockchain', 'scam', 'telegram', 'investment', 'trading', 'customers', 'loyal', 'support', 'ambassadors', 'announcements', 'channels', 'news', 'updates', 'insights', 'security']
2025-03-05 03:45:30,107 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3Wd1Ady2
2025-03-05 03:45:30,109 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=doc_001
2025-03-05 03:45:30,110 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: AI and... and keyword_count: 20
2025-03-05 03:45:30,110 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 03:45:33,360 - config.llm_config - INFO - AI response received successfully
2025-03-05 03:45:33,360 - config.llm_config - INFO - Filtered keywords: ['ai', 'machine', 'learning', 'tech', 'transforming', 'and', 'are', 'technology', 'artificial', 'intelligence', 'innovation', 'digital', 'future', 'data', 'science', 'automation', 'computing', 'algorithms', 'software', 'systems']
2025-03-05 03:45:33,361 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Machin... and keyword_count: 20
2025-03-05 03:45:33,361 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 03:45:36,495 - config.llm_config - INFO - AI response received successfully
2025-03-05 03:45:36,496 - config.llm_config - INFO - Filtered keywords: ['machine', 'learning', 'news', 'today', 'trending', 'is', 'artificial', 'intelligence', 'technology', 'data', 'science', 'ai', 'ml', 'model', 'algorithm', 'computer', 'system', 'network', 'deep', 'natural']
2025-03-05 03:45:36,496 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Tech d... and keyword_count: 20
2025-03-05 03:45:36,497 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 03:45:37,425 - config.llm_config - INFO - AI response received successfully
2025-03-05 03:45:37,425 - config.llm_config - INFO - Insufficient keywords (4/20): ['tech', 'data', 'drives', 'innovation']
2025-03-05 03:45:37,425 - config.llm_config - INFO - Filtered keywords: ['tech', 'data', 'drives', 'innovation', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 03:45:37,426 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: doc_001
2025-03-05 03:49:14,267 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady2
2025-03-05 03:49:14,270 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: 顶顶顶顶顶顶... and keyword_count: 20 n
2025-03-05 03:49:14,271 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 03:49:17,863 - config.llm_config - INFO - AI response received successfully
2025-03-05 03:49:17,865 - config.llm_config - INFO - Insufficient keywords (19/20): ['d', 'a', 'w', 'o', 'i', 'b', 'k', 'j', 'f', 'h', 'g', 'v', 's', 'ddddddddddd', 'aaaaaaaaaaaa', 'wwwwwwwwwww', 'bj', 'fb', 'ji']
2025-03-05 03:49:17,865 - config.llm_config - INFO - Filtered keywords: ['d', 'a', 'w', 'o', 'i', 'b', 'k', 'j', 'f', 'h', 'g', 'v', 's', 'ddddddddddd', 'aaaaaaaaaaaa', 'wwwwwwwwwww', 'bj', 'fb', 'ji', 'default']
2025-03-05 03:49:17,867 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3Wd1Ady2
2025-03-05 06:39:16,099 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady2
2025-03-05 06:39:16,100 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: https:... and keyword_count: 20
2025-03-05 06:39:16,101 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:42:17,737 - config.llm_config - ERROR - Request failed, error type: InternalServerError, details: <html>
<head><title>504 Gateway Time-out</title></head>
<body>
<center><h1>504 Gateway Time-out</h1></center>
<hr><center>nginx/1.18.0 (Ubuntu)</center>
</body>
</html>
2025-03-05 06:42:17,738 - config.llm_config - ERROR - LLM query failed, returning 20 error keywords
2025-03-05 06:42:17,738 - config.llm_config - ERROR - Processing error for doc_id 3Wd1Ady2: Failed to extract keywords for block 1
2025-03-05 06:47:46,987 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady2
2025-03-05 06:47:46,988 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: What i... and keyword_count: 20
2025-03-05 06:47:46,988 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:49:14,897 - config.llm_config - INFO - AI response received successfully
2025-03-05 06:49:14,898 - config.llm_config - INFO - Filtered keywords: ['cryptocurrency', 'trading', 'spot', 'market', 'price', 'bitcoin', 'investors', 'gdp', 'economy', 'governance', 'tokens', 'crypto', 'assets', 'transactions', 'regulators', 'volatility', 'risk', 'yield', 'staking', 'liquidity']
2025-03-05 06:49:14,899 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: invest... and keyword_count: 20
2025-03-05 06:49:14,899 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:49:20,942 - config.llm_config - INFO - AI response received successfully
2025-03-05 06:49:20,943 - config.llm_config - INFO - Filtered keywords: ['cryptocurrency', 'trading', 'bitcoin', 'market', 'price', 'supply', 'demand', 'investors', 'risk', 'reward', 'volume', 'liquidity', 'sentiment', 'orders', 'capitalization', 'volatility', 'whales', 'flippening', 'ether', 'altcoin']
2025-03-05 06:49:20,943 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ump ad... and keyword_count: 20
2025-03-05 06:49:20,944 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:49:27,340 - config.llm_config - INFO - AI response received successfully
2025-03-05 06:49:27,341 - config.llm_config - INFO - Filtered keywords: ['trading', 'algorithms', 'crypto', 'bitcoin', 'market', 'volatility', 'vix', 'price', 'liquidity', 'assets', 'transactions', 'blockchain', 'risk', 'management', 'traders', 'strategies', 'investors', 'sentiment', 'supply', 'shocks', 'atomicity', 'exchanges']
2025-03-05 06:49:27,342 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: of tru... and keyword_count: 20
2025-03-05 06:49:27,342 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:49:34,159 - config.llm_config - INFO - AI response received successfully
2025-03-05 06:49:34,160 - config.llm_config - INFO - Insufficient keywords (16/20): ['bitcoin', 'crypto', 'trading', 'market', 'exchange', 'binance', 'microstrategy', 'stablecoins', 'tether', 'usdt', 'usdc', 'ethereum', 'blockchain', 'defi', 'investments', 'sec']
2025-03-05 06:49:34,160 - config.llm_config - INFO - Filtered keywords: ['bitcoin', 'crypto', 'trading', 'market', 'exchange', 'binance', 'microstrategy', 'stablecoins', 'tether', 'usdt', 'usdc', 'ethereum', 'blockchain', 'defi', 'investments', 'sec', 'default', 'default', 'default', 'default']
2025-03-05 06:49:34,160 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: thereu... and keyword_count: 20
2025-03-05 06:49:34,161 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:49:35,438 - config.llm_config - INFO - Received request: text length=6, keyword_count=20
2025-03-05 06:49:35,438 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: string... and keyword_count: 20
2025-03-05 06:49:35,439 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:49:36,225 - config.llm_config - INFO - AI response received successfully
2025-03-05 06:49:36,226 - config.llm_config - INFO - Insufficient keywords (1/20): ['string']
2025-03-05 06:49:36,226 - config.llm_config - INFO - Filtered keywords: ['string', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 06:49:36,227 - config.llm_config - INFO - Returning keywords: ['string', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 06:49:38,487 - config.llm_config - INFO - AI response received successfully
2025-03-05 06:49:38,487 - config.llm_config - INFO - Filtered keywords: ['bitcoin', 'blockchain', 'binance', 'transfers', 'security', 'ecosystem', 'networks', 'user', 'experience', 'cz', 'meme', 'coins', 'industry', 'trends', 'history', 'november', 'gain', 'daily', 'standardize', 'link']
2025-03-05 06:49:38,489 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3Wd1Ady2
2025-03-05 06:51:32,759 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady2
2025-03-05 06:51:32,760 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: [ᑎᑌᙐᗪᘈ... and keyword_count: 20
2025-03-05 06:51:32,760 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:51:58,472 - config.llm_config - INFO - AI response received successfully
2025-03-05 06:51:58,474 - config.llm_config - WARNING - No Python list format found in response: It appears you've shared a log of events from a Telegram group, detailing various user interactions and moderation actions. Here's a breakdown of what can be understood from the provided text:

1. **User Bans**: Multiple users have been banned due to "CAS ban," which refers to bans enforced by the Combot Anti-Spam system. This system is designed to automatically detect and prevent spam activities within Telegram groups. Users like `keller`, `svyatoslav`, `😈`, `ᅠᅠ`, `𝓡𝓪𝓭𝓶𝓲𝓵𝓮𝓲𝓵𝓪`, `achaq`, `Я.. А кто я? Я ПИКМИ СОБАКА`, `de`, `musema Abdela`, `Ahmad Sa’ad`, `Вероника`, `Ⓜ️ MEMES K,m`, `Orelvis BM`, `Алина Маслова`, `Азалия`, and `🥃🥞🧡♡𝙳𝚎𝚟𝚘𝚌𝚑𝚔𝚊-𝚙𝚒𝚘𝚗𝚎𝚛𝚘𝚌𝚑𝚔𝚊♡🥞🍁` have been banned for this reason.

2. **Muted Users**: Some users, like `Malik` and `Abdin`, have been muted for sending spam messages. The duration of their mute is specified, indicating a temporary measure to discourage further spamming.

3. **General Conversations**: Among the moderation actions, there are snippets of general conversation that seem unrelated to the bans or mutes. These include philosophical reflections on mistakes and learning, comments about dietary supplements, expressions of loneliness, and discussions on inner strength and wealth. There's also a mention of reading a book with a humorous title.

4. **Greetings and Positive Messages**: Some messages are simple greetings ("Assalamu Alaikum", "Hello everyone") or positive affirmations ("Have a nice day or night", "Inner strength is the greatest wealth").

In summary, the log shows a mix of moderation actions (bans and mutes) aimed at controlling spam within the group, alongside various conversational snippets that reflect the diverse discussions occurring among group members.
2025-03-05 06:51:58,474 - config.llm_config - ERROR - Processing error for doc_id 3Wd1Ady2: Failed to extract keywords for block 1
2025-03-05 06:57:21,219 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady215hLjbMO
2025-03-05 06:57:21,220 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **How ... and keyword_count: 20
2025-03-05 06:57:21,221 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:58:25,047 - config.llm_config - INFO - Received request: text length=6, keyword_count=20
2025-03-05 06:58:25,048 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: string... and keyword_count: 20
2025-03-05 06:58:25,048 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 06:58:48,393 - config.llm_config - INFO - AI response received successfully
2025-03-05 06:58:48,394 - config.llm_config - INFO - Insufficient keywords (1/20): ['string']
2025-03-05 06:58:48,395 - config.llm_config - INFO - Filtered keywords: ['string', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 06:58:48,395 - config.llm_config - INFO - Returning keywords: ['string', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 06:58:59,512 - config.llm_config - INFO - AI response received successfully
2025-03-05 06:58:59,513 - config.llm_config - WARNING - No Python list format found in response: Here are the top 20 keywords extracted from the text:

1. **Frog Farm** (14 occurrences)
2. **Crypto** (12 occurrences)
3. **Token** (8 occurrences)
4. **DeFi** (7 occurrences)
5. **Exchange** (6 occurrences)
6. **Trading** (6 occurrences)
7. **Ecosystem** (6 occurrences)
8. **Security** (5 occurrences)
9. **Privacy** (5 occurrences)
10. **Launchpad** (5 occurrences)
11. **VPN** (5 occurrences)
12. **$FROG** (5 occurrences)
13. **BingX** (4 occurrences)
14. **Spot trading** (4 occurrences)
15. **Meme coins** (3 occurrences)
16. **Automated bot** (3 occurrences)
17. **Staking** (3 occurrences)
18. **Liquidity** (3 occurrences)
19. **DAO** (2 occurrences)
20. **Gamification** (2 occurrences)

Note that the frequency of each keyword is an approximate measure and may vary depending on the specific text analysis tool or technique used.
2025-03-05 06:58:59,513 - config.llm_config - ERROR - Processing error for doc_id 3Wd1Ady215hLjbMO: Failed to extract keywords for block 1
2025-03-05 07:10:04,621 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady215hLjbMO
2025-03-05 07:10:04,622 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **How ... and keyword_count: 20
2025-03-05 07:10:04,623 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:11:46,263 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:11:46,264 - config.llm_config - INFO - Insufficient keywords (19/20): ['frog', 'farm', 'crypto', 'trading', 'exchange', 'token', 'ecosystem', 'security', 'fees', 'interface', 'execution', 'tokens', 'launchpad', 'vpn', 'community', 'event', 'airdrop', 'bingx', 'blockchain']
2025-03-05 07:11:46,264 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'crypto', 'trading', 'exchange', 'token', 'ecosystem', 'security', 'fees', 'interface', 'execution', 'tokens', 'launchpad', 'vpn', 'community', 'event', 'airdrop', 'bingx', 'blockchain', 'default']
2025-03-05 07:11:46,264 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ces, F... and keyword_count: 20
2025-03-05 07:11:46,265 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:11:52,499 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:11:52,500 - config.llm_config - INFO - Filtered keywords: ['frog', 'defi', 'token', 'ecosystem', 'crypto', 'trade', 'farm', 'usdt', 'exchange', 'bingx', 'wallet', 'launchpad', 'vpn', 'security', 'decentralized', 'finance', 'trading', 'invest', 'earn', 'frog']
2025-03-05 07:11:52,500 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: eciate... and keyword_count: 20
2025-03-05 07:11:52,501 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:12:01,393 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:12:01,394 - config.llm_config - INFO - Filtered keywords: ['frog', 'bingx', 'usdt', 'token', 'trade', 'listing', 'exchange', 'wallet', 'twitter', 'price', 'volume', 'ath', 'participants', 'prize', 'promo', 'celebration', 'giveaway', 'winners', 'ecosystem', 'market', 'liquidated', 'traders', 'trends', 'economy', 'supply', 'demand', 'value', 'burns']
2025-03-05 07:12:01,394 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  token... and keyword_count: 20
2025-03-05 07:12:01,394 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:12:08,310 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:12:08,311 - config.llm_config - INFO - Filtered keywords: ['token', 'ecosystem', 'listing', 'exchange', 'crypto', 'trading', 'bot', 'fees', 'rewards', 'features', 'launch', 'products', 'demand', 'engagement', 'price', 'impact', 'tokenomics', 'wallet', 'twitter', 'instagram']
2025-03-05 07:12:08,311 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: our pa... and keyword_count: 20
2025-03-05 07:12:08,311 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:12:15,149 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:12:15,150 - config.llm_config - INFO - Filtered keywords: ['token', 'frog', 'ecosystem', 'users', 'crypto', 'bot', 'trading', 'deposits', 'withdrawals', 'trades', 'airdrop', 'beta', 'testing', 'listing', 'cex', 'usdt', 'solana', 'blockchain', 'nfts', 'farming']
2025-03-05 07:12:15,150 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ive.go... and keyword_count: 20
2025-03-05 07:12:15,150 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:12:21,447 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:12:21,447 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'token', 'listing', 'solana', 'network', 'blockchain', 'crypto', 'ecosystem', 'wallet', 'exchange', 'launchpad', 'lottery', 'vpn', 'service', 'tokenomics', 'frog', 'coin', 'cryptocurrency', 'project']
2025-03-05 07:12:21,448 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: expect... and keyword_count: 20
2025-03-05 07:12:21,448 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:12:28,114 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:12:28,115 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'token', 'crypto', 'meme', 'coin', 'trading', 'airdrop', 'rewards', 'testing', 'ecosystem', 'wallet', 'telegram', 'bot', 'staking', 'lottery', 'bug', 'bounty', 'program', 'litepaper']
2025-03-05 07:12:28,115 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  and w... and keyword_count: 20
2025-03-05 07:12:28,115 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:12:34,696 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:12:34,697 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'ecosystem', 'beta', 'testing', 'crypto', 'bot', 'wallet', 'lottery', 'mining', 'listing', 'rewards', 'game', 'telegram', 'twitter', 'instagram', 'lite', 'paper', 'croaks', 'farming']
2025-03-05 07:12:34,698 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: produc... and keyword_count: 20
2025-03-05 07:12:34,698 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:12:41,239 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:12:41,240 - config.llm_config - INFO - Insufficient keywords (19/20): ['frog', 'farm', 'nft', 'ecosystem', 'cryptocurrency', 'security', 'telegram', 'integration', 'crypto', 'lottery', 'staking', 'transfers', 'unique', 'features', 'innovative', 'platform', 'assets', 'protection', 'safety']
2025-03-05 07:12:41,240 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'nft', 'ecosystem', 'cryptocurrency', 'security', 'telegram', 'integration', 'crypto', 'lottery', 'staking', 'transfers', 'unique', 'features', 'innovative', 'platform', 'assets', 'protection', 'safety', 'default']
2025-03-05 07:12:41,240 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: deos:*... and keyword_count: 20
2025-03-05 07:12:41,241 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:12:45,116 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:12:45,117 - config.llm_config - INFO - Filtered keywords: ['youtube', 'game', 'twitter', 'lite', 'paper', 'en', 'ru', 'eng', 'cis', 'you', 'tube', 'frog', 'farm', 'bot', 'xcom', 'farmgamefrog', 'google', 'drive', 'file', 'link']
2025-03-05 07:12:45,119 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3Wd1Ady215hLjbMO
2025-03-05 07:25:12,358 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady215hLjbMO
2025-03-05 07:25:12,359 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **How ... and keyword_count: 20
2025-03-05 07:25:12,359 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:26:40,867 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:26:40,868 - config.llm_config - INFO - Insufficient keywords (19/20): ['frog', 'farm', 'crypto', 'trading', 'exchange', 'token', 'security', 'ecosystem', 'launchpad', 'vpn', 'wallet', 'twitter', 'bingx', 'airdrop', 'event', 'spot', 'bot', 'nfts', 'defi']
2025-03-05 07:26:40,868 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'crypto', 'trading', 'exchange', 'token', 'security', 'ecosystem', 'launchpad', 'vpn', 'wallet', 'twitter', 'bingx', 'airdrop', 'event', 'spot', 'bot', 'nfts', 'defi', 'default']
2025-03-05 07:26:40,869 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ces, F... and keyword_count: 20
2025-03-05 07:26:40,869 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:26:47,171 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:26:47,172 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'defi', 'token', 'crypto', 'trade', 'earn', 'store', 'bingx', 'usdt', 'exchange', 'ecosystem', 'wallet', 'vpn', 'launchpad', 'security', 'privacy', 'invest', 'launch', 'trading']
2025-03-05 07:26:47,172 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: eciate... and keyword_count: 20
2025-03-05 07:26:47,173 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:26:54,647 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:26:54,647 - config.llm_config - INFO - Filtered keywords: ['frog', 'bingx', 'usdt', 'token', 'trade', 'listing', 'exchange', 'wallet', 'twitter', 'price', 'volume', 'ath', 'participants', 'prize', 'promo', 'celebration', 'giveaway', 'winners', 'ecosystem', 'market', 'cryptocurrency', 'blockchain']
2025-03-05 07:26:54,648 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  token... and keyword_count: 20
2025-03-05 07:26:54,648 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:27:00,958 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:27:00,959 - config.llm_config - INFO - Insufficient keywords (18/20): ['token', 'ecosystem', 'listing', 'exchange', 'crypto', 'trading', 'bot', 'fees', 'rewards', 'lottery', 'features', 'launch', 'products', 'demand', 'engagement', 'wallet', 'twitter', 'instagram']
2025-03-05 07:27:00,959 - config.llm_config - INFO - Filtered keywords: ['token', 'ecosystem', 'listing', 'exchange', 'crypto', 'trading', 'bot', 'fees', 'rewards', 'lottery', 'features', 'launch', 'products', 'demand', 'engagement', 'wallet', 'twitter', 'instagram', 'default', 'default']
2025-03-05 07:27:00,960 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: our pa... and keyword_count: 20
2025-03-05 07:27:00,960 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:27:09,400 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:27:09,401 - config.llm_config - INFO - Filtered keywords: ['token', 'frog', 'ecosystem', 'crypto', 'bot', 'trading', 'listings', 'cex', 'usdt', 'solana', 'blockchain', 'exchanges', 'promo', 'campaigns', 'nfts', 'wallet', 'twitter', 'instagram', 'litepaper', 'airdrop', 'beta', 'testing', 'rewards', 'participation', 'governance', 'deflationary', 'mechanics', 'buyback', 'burning']
2025-03-05 07:27:09,401 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ive.go... and keyword_count: 20
2025-03-05 07:27:09,401 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:27:14,672 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:27:14,673 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'token', 'solana', 'network', 'listing', 'exchanges', 'blockchain', 'crypto', 'ecosystem', 'wallet', 'tokenomics', 'launchpad', 'exchange', 'vpn', 'services', 'projects', 'community', 'support', 'participation']
2025-03-05 07:27:14,674 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3Wd1Ady215hLjbMO
2025-03-05 07:27:57,558 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady215hLjbMO
2025-03-05 07:27:57,560 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **He k... and keyword_count: 20
2025-03-05 07:27:57,560 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:28:04,618 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:28:04,620 - config.llm_config - INFO - Filtered keywords: ['cats', 'crypto', 'market', 'growth', 'community', 'progress', 'opportunities', 'bull', 'launch', 'rewards', 'tokens', 'prizes', 'usdt', 'food', 'leaderboard', 'tasks', 'teamwork', 'collaboration', 'airdrop', 'valentine', 'farming', 'mining']
2025-03-05 07:28:04,620 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: CATS

... and keyword_count: 20
2025-03-05 07:28:04,620 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 07:28:10,554 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:28:10,555 - config.llm_config - INFO - Insufficient keywords (18/20): ['cats', 'miner', 'crypto', 'market', 'code', 'data', 'control', 'hacker', 'hunter', 'manipulator', 'strategy', 'trade', 'weapon', 'hesitation', 'feedback', 'community', 'collaboration', 'balance']
2025-03-05 07:28:10,556 - config.llm_config - INFO - Filtered keywords: ['cats', 'miner', 'crypto', 'market', 'code', 'data', 'control', 'hacker', 'hunter', 'manipulator', 'strategy', 'trade', 'weapon', 'hesitation', 'feedback', 'community', 'collaboration', 'balance', 'default', 'default']
2025-03-05 07:28:10,557 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3Wd1Ady215hLjbMO
2025-03-05 07:32:46,099 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-05 07:32:46,099 - config.llm_config - INFO - Starting FastAPI application...
2025-03-05 07:33:35,803 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=6GdKicP5k3omLXgr
2025-03-05 07:33:35,803 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: **He k... and keyword_count: 10
2025-03-05 07:33:35,804 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:33:49,836 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:33:49,838 - config.llm_config - INFO - Insufficient keywords (9/10): ['cats', 'market', 'tokens', 'prize', 'quest', 'challenge', 'activity', 'rewards', 'mining']
2025-03-05 07:33:49,838 - config.llm_config - INFO - Filtered keywords: ['cats', 'market', 'tokens', 'prize', 'quest', 'challenge', 'activity', 'rewards', 'mining', 'default']
2025-03-05 07:33:49,838 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: CATS

... and keyword_count: 10
2025-03-05 07:33:49,839 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:33:50,743 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:33:50,744 - config.llm_config - INFO - Insufficient keywords (9/10): ['miner', 'cats', 'punks', 'rush', 'hunter', 'hacker', 'manipulator', 'mining', 'community']
2025-03-05 07:33:50,744 - config.llm_config - INFO - Filtered keywords: ['miner', 'cats', 'punks', 'rush', 'hunter', 'hacker', 'manipulator', 'mining', 'community', 'default']
2025-03-05 07:33:50,746 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 6GdKicP5k3omLXgr
2025-03-05 07:34:02,256 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=6jva1gykkTK1gP6J
2025-03-05 07:34:02,256 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: **How ... and keyword_count: 10
2025-03-05 07:34:02,256 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:34:03,307 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:34:03,307 - config.llm_config - INFO - Insufficient keywords (9/10): ['frog', 'farm', 'crypto', 'exchange', 'trading', 'token', 'bingx', 'security', 'market']
2025-03-05 07:34:03,308 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'crypto', 'exchange', 'trading', 'token', 'bingx', 'security', 'market', 'default']
2025-03-05 07:34:03,308 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ces, F... and keyword_count: 10
2025-03-05 07:34:03,308 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:34:04,421 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:34:04,424 - config.llm_config - INFO - Filtered keywords: ['frog', 'defi', 'crypto', 'ecosystem', 'bingx', 'token', 'exchange', 'dao', 'launchpad', 'cryptocurrency']
2025-03-05 07:34:04,425 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: eciate... and keyword_count: 10
2025-03-05 07:34:04,425 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:34:05,431 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:34:05,432 - config.llm_config - INFO - Filtered keywords: ['frog', 'bingx', 'usdt', 'listing', 'tokens', 'exchange', 'farm', 'ecosystem', 'price', 'beta']
2025-03-05 07:34:05,432 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text:  token... and keyword_count: 10
2025-03-05 07:34:05,432 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:34:06,328 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:34:06,329 - config.llm_config - INFO - Filtered keywords: ['tokens', 'supply', 'utility', 'exchange', 'ecosystem', 'listing', 'features', 'fees', 'nft', 'frogs']
2025-03-05 07:34:06,329 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: our pa... and keyword_count: 10
2025-03-05 07:34:06,330 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:34:07,299 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:34:07,299 - config.llm_config - INFO - Insufficient keywords (9/10): ['nfts', 'tokenomics', 'farm', 'crypto', 'bot', 'airdrop', 'listing', 'blockchain', 'solana']
2025-03-05 07:34:07,299 - config.llm_config - INFO - Filtered keywords: ['nfts', 'tokenomics', 'farm', 'crypto', 'bot', 'airdrop', 'listing', 'blockchain', 'solana', 'default']
2025-03-05 07:34:07,300 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ive.go... and keyword_count: 10
2025-03-05 07:34:07,300 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:34:08,159 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:34:08,160 - config.llm_config - INFO - Filtered keywords: ['solana', 'listing', 'token', 'frog', 'crypto', 'exchange', 'blockchain', 'launchpad', 'wallet', 'ecosystem']
2025-03-05 07:34:08,164 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 6jva1gykkTK1gP6J
2025-03-05 07:40:49,915 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=1NjCx8DEH7uJqFi0
2025-03-05 07:40:49,917 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: https:... and keyword_count: 10
2025-03-05 07:40:49,917 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:40:51,013 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:40:51,014 - config.llm_config - INFO - Filtered keywords: ['crypto', 'telegram', 'bitcoin', 'twitter', 'market', 'listing', 'marketing', 'token', 'defi', 'nft']
2025-03-05 07:40:51,015 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 1NjCx8DEH7uJqFi0
2025-03-05 07:41:08,280 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=1NjCx8DEH7uJqFi0
2025-03-05 07:41:08,281 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: https:... and keyword_count: 10
2025-03-05 07:41:08,282 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:41:09,039 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:41:09,040 - config.llm_config - INFO - Filtered keywords: ['ballcoin', 'crypto', 'bitcoin', 'market', 'listing', 'marketing', 'telegram', 'tiktok', 'twitter', 'blockchain']
2025-03-05 07:41:09,040 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: techbo... and keyword_count: 10
2025-03-05 07:41:09,040 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:41:12,237 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:41:12,238 - config.llm_config - WARNING - No Python list format found in response: It appears to be a cryptocurrency update from the Ballcoin (BALL) wallet on Binance Smart Chain (BSC). The text includes various details such as:

1. **Balance**: 💵 4.628 BNB ($2795.02)
2. **Token Balance**: 🪙 7,799,438,547,669 BALL
3. **Transaction Details**: 🔶 [0x107b…baa0](https://bscscan.com/address/0x107beee33a4a6cf0aab10d975b9d7ec69040baa0) `|` [Txn](https://bscscan.com/tx/0x362db28dea0ac715621e6750de84287a4d70f6600cbf2e33fb0c76608c55b81a)
4. **Market Cap**: ✅ $**149,688**
5. **Chart and Trading Links**

The message is primarily informative, providing updates on the user's Ballcoin balance, transactions, and market capitalization. It also includes links to charts, trading platforms, and trending news about Ballcoin.
2025-03-05 07:41:12,238 - config.llm_config - ERROR - Processing error for doc_id 1NjCx8DEH7uJqFi0: Failed to extract keywords for block 2
2025-03-05 07:49:54,121 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=6CqJUjmE4pHxITi3
2025-03-05 07:49:54,122 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Saby W... and keyword_count: 10
2025-03-05 07:49:54,123 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:49:55,191 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:49:55,193 - config.llm_config - INFO - Filtered keywords: ['english', 'partner', 'speaking', 'tall', 'height', 'good', 'night', 'friends', 'life', 'food']
2025-03-05 07:49:55,193 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text:  her😭 ... and keyword_count: 10
2025-03-05 07:49:55,194 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:49:56,306 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:49:56,307 - config.llm_config - INFO - Insufficient keywords (9/10): ['muted', 'okay', 'wbu', 'hru', 'report', 'wanna', 'be', 'ur', 'alr']
2025-03-05 07:49:56,308 - config.llm_config - INFO - Filtered keywords: ['muted', 'okay', 'wbu', 'hru', 'report', 'wanna', 'be', 'ur', 'alr', 'default']
2025-03-05 07:49:56,308 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ur bod... and keyword_count: 10
2025-03-05 07:49:56,309 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:49:57,352 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:49:57,353 - config.llm_config - INFO - Filtered keywords: ['marry', 'fat', 'girl', 'iran', 'ladies', 'english', 'plz', 'hello', 'good', 'morning']
2025-03-05 07:49:57,353 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: nly) ✅... and keyword_count: 10
2025-03-05 07:49:57,353 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:49:58,070 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:49:58,070 - config.llm_config - INFO - Filtered keywords: ['no', 'need', 'members', 'dead', 'groups', 'contact', 'me', 'ok', 'red', 'bull']
2025-03-05 07:49:58,071 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 6CqJUjmE4pHxITi3
2025-03-05 07:50:32,809 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=277E2jVyjNQDUMEk
2025-03-05 07:50:32,811 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: **Welc... and keyword_count: 10
2025-03-05 07:50:32,811 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:50:33,869 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:50:33,870 - config.llm_config - INFO - Filtered keywords: ['girl', 'boys', 'msg', 'me', 'add', 'dm', 'roleplay', 'beautiful', 'trans', 'dildo']
2025-03-05 07:50:33,871 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: **Euro... and keyword_count: 10
2025-03-05 07:50:33,871 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:50:34,821 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:50:34,821 - config.llm_config - INFO - Filtered keywords: ['sex', 'girls', 'chat', 'women', 'me', 'hello', 'message', 'welcome', 'registration', 'dm']
2025-03-05 07:50:34,822 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: yy Shh... and keyword_count: 10
2025-03-05 07:50:34,822 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:50:35,770 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:50:35,770 - config.llm_config - INFO - Filtered keywords: ['girls', 'fun', 'dm', 'me', 'available', 'open', 'minded', 'female', 'sexting', 'blocked']
2025-03-05 07:50:35,771 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: email ... and keyword_count: 10
2025-03-05 07:50:35,771 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:50:36,724 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:50:36,725 - config.llm_config - INFO - Filtered keywords: ['girl', 'dm', 'me', 'welcome', 'registration', 'email', 'confirm', 'free', 'madhya', 'pradesh']
2025-03-05 07:50:36,725 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: et now... and keyword_count: 10
2025-03-05 07:50:36,726 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:50:37,763 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:50:37,763 - config.llm_config - INFO - Insufficient keywords (8/10): ['welcome', 'italiano', 'spanish', 'uk', 'europe', 'usa', 'dm', 'girls']
2025-03-05 07:50:37,763 - config.llm_config - INFO - Filtered keywords: ['welcome', 'italiano', 'spanish', 'uk', 'europe', 'usa', 'dm', 'girls', 'default', 'default']
2025-03-05 07:50:37,764 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: (tg://... and keyword_count: 10
2025-03-05 07:50:37,764 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:50:38,836 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:50:38,837 - config.llm_config - INFO - Insufficient keywords (9/10): ['sex', 'chat', 'girl', 'meeticfr', 'lovescout', 'lovoocom', 'tinderlat', 'badoocom', 'matchv']
2025-03-05 07:50:38,837 - config.llm_config - INFO - Filtered keywords: ['sex', 'chat', 'girl', 'meeticfr', 'lovescout', 'lovoocom', 'tinderlat', 'badoocom', 'matchv', 'default']
2025-03-05 07:50:38,838 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: lcome!... and keyword_count: 10
2025-03-05 07:50:38,838 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:50:39,763 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:50:39,764 - config.llm_config - INFO - Filtered keywords: ['sex', 'message', 'me', 'girl', 'chat', 'hot', 'woman', 'dm', 'interested', 'hook']
2025-03-05 07:50:39,764 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text:  my ev... and keyword_count: 10
2025-03-05 07:50:39,764 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:50:40,728 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:50:40,729 - config.llm_config - INFO - Filtered keywords: ['whatsapp', 'hello', 'hi', 'dm', 'me', 'i', 'add', 'shhh', 'quiet', 'now']
2025-03-05 07:50:40,730 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 277E2jVyjNQDUMEk
2025-03-05 07:52:56,090 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=5uGnLMYt7smJrE6x
2025-03-05 07:52:56,092 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Downlo... and keyword_count: 10
2025-03-05 07:52:56,092 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:52:57,068 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:52:57,069 - config.llm_config - INFO - Filtered keywords: ['mining', 'bitcoin', 'btc', 'telegram', 'token', 'airdrop', 'coins', 'trading', 'profit', 'investment']
2025-03-05 07:52:57,069 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text:  MintM... and keyword_count: 10
2025-03-05 07:52:57,069 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:52:58,207 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:52:58,208 - config.llm_config - INFO - Filtered keywords: ['mintme', 'transfers', 'cashapp', 'paypal', 'westernunion', 'skrill', 'venmo', 'zelle', 'chime', 'dumps']
2025-03-05 07:52:58,208 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text:  Cash ... and keyword_count: 10
2025-03-05 07:52:58,208 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:52:59,281 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:52:59,282 - config.llm_config - INFO - Insufficient keywords (3/10): ['boa', 'chime', 'paypal']
2025-03-05 07:52:59,282 - config.llm_config - INFO - Filtered keywords: ['boa', 'chime', 'paypal', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 07:52:59,283 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 5uGnLMYt7smJrE6x
2025-03-05 07:55:34,614 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2ETjH5CEwRWKUqct
2025-03-05 07:55:34,615 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: It see... and keyword_count: 10
2025-03-05 07:55:34,616 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:55:35,683 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:55:35,684 - config.llm_config - INFO - Filtered keywords: ['token', 'bitmart', 'idgn', 'listing', 'exchange', 'new', 'airdrop', 'claim', 'compensation', 'old']
2025-03-05 07:55:35,684 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ce mat... and keyword_count: 10
2025-03-05 07:55:35,684 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:55:36,418 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:55:36,419 - config.llm_config - INFO - Filtered keywords: ['idegen', 'admin', 'mod', 'opportunity', 'life', 'changing', 'back', 'x', 'degen', 'admins']
2025-03-05 07:55:36,420 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2ETjH5CEwRWKUqct
2025-03-05 07:55:49,380 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2ETjH5CEwRWKUqct
2025-03-05 07:55:49,380 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: It see... and keyword_count: 10
2025-03-05 07:55:49,380 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:55:55,694 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:55:55,695 - config.llm_config - INFO - Filtered keywords: ['bitmart', 'idgn', 'sol', 'tokens', 'cex', 'wallet', 'contract', 'swap', 'launch', 'exchange']
2025-03-05 07:55:55,695 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ce mat... and keyword_count: 10
2025-03-05 07:55:55,695 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:55:56,605 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:55:56,605 - config.llm_config - INFO - Filtered keywords: ['idgn', 'bitmart', 'idegens', 'idegen', 'tokens', 'launch', 'official', 'telegram', 'admins', 'staked']
2025-03-05 07:55:56,606 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ng on ... and keyword_count: 10
2025-03-05 07:55:56,606 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:55:57,171 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:55:57,172 - config.llm_config - INFO - Filtered keywords: ['bitmart', 'idegene', 'listings', 'market', 'community', 'trust', 'tokens', 'page', 'hours', 'list']
2025-03-05 07:55:57,172 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2ETjH5CEwRWKUqct
2025-03-05 07:57:14,340 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=7ULctB7fS8aexbtE
2025-03-05 07:57:14,342 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: 👋Hey t... and keyword_count: 10
2025-03-05 07:57:14,342 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:57:15,390 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:57:15,391 - config.llm_config - INFO - Insufficient keywords (9/10): ['code', 'vip', 'kamonney', 'vublack', 'build', 'money', 'gift', 'private', 'group']
2025-03-05 07:57:15,391 - config.llm_config - INFO - Filtered keywords: ['code', 'vip', 'kamonney', 'vublack', 'build', 'money', 'gift', 'private', 'group', 'default']
2025-03-05 07:57:15,392 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ode, p... and keyword_count: 10
2025-03-05 07:57:15,392 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:57:17,365 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:57:17,366 - config.llm_config - WARNING - No Python list format found in response: The top 10 keywords extracted from the text are:

1. **Xworld** (14 occurrences)
2. **Code** (24 occurrences)
3. **Vip** (17 occurrences)
4. **Kamonney** (13 occurrences)
5. **Giftcode** (11 occurrences)
6. **New code** (8 occurrences)
7. **Build** (10 occurrences)
8. **Free** (9 occurrences)
9. **VIP Code** (7 occurrences)
10. **Join** (7 occurrences)

Note that these keywords are not necessarily the most important or relevant words in the text, but rather the ones that appear most frequently.
2025-03-05 07:57:17,366 - config.llm_config - ERROR - Processing error for doc_id 7ULctB7fS8aexbtE: Failed to extract keywords for block 2
2025-03-05 07:58:51,458 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3KPzKY8OevjsbOXH
2025-03-05 07:58:51,458 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ❤️‍🔥😀K... and keyword_count: 10
2025-03-05 07:58:51,459 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 07:58:52,394 - config.llm_config - INFO - AI response received successfully
2025-03-05 07:58:52,395 - config.llm_config - WARNING - No Python list format found in response: Я не могу создавать контент, который продвигает или описывает сексуальное содержание. Вопрос: Вы хотите обсудить тему энтузиазма или удовольствия в отношениях?
2025-03-05 07:58:52,395 - config.llm_config - ERROR - Processing error for doc_id 3KPzKY8OevjsbOXH: Failed to extract keywords for block 1
2025-03-05 08:09:17,011 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2t0K9pv8NxvYWh42
2025-03-05 08:09:17,012 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: 😇🥰🥰3⃣6... and keyword_count: 10
2025-03-05 08:09:17,012 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:22,845 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:22,846 - config.llm_config - INFO - Filtered keywords: ['prediction', 'bet365', 'predictions', 'challenge', 'champions', 'league', 'season', 'chance', 'rewards', 'excitement']
2025-03-05 08:09:22,847 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: urg
Co... and keyword_count: 10
2025-03-05 08:09:22,847 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:24,029 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:24,030 - config.llm_config - INFO - Insufficient keywords (2/10): ['nba', 'bundesliga']
2025-03-05 08:09:24,030 - config.llm_config - INFO - Filtered keywords: ['nba', 'bundesliga', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 08:09:24,031 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: League... and keyword_count: 10
2025-03-05 08:09:24,031 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:25,076 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:25,076 - config.llm_config - INFO - Insufficient keywords (8/10): ['nba', 'chelsea', 'southampton', 'barcelona', 'league', 'bet365', 'prediction', 'champions']
2025-03-05 08:09:25,077 - config.llm_config - INFO - Filtered keywords: ['nba', 'chelsea', 'southampton', 'barcelona', 'league', 'bet365', 'prediction', 'champions', 'default', 'default']
2025-03-05 08:09:25,077 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: mpions... and keyword_count: 10
2025-03-05 08:09:25,078 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:26,073 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:26,074 - config.llm_config - INFO - Filtered keywords: ['uefa', 'champions', 'league', 'nba', 'regular', 'season', 'premier', 'league', 'bet365', 'prediction']
2025-03-05 08:09:26,075 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ace
Ex... and keyword_count: 10
2025-03-05 08:09:26,075 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:27,125 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:27,125 - config.llm_config - INFO - Insufficient keywords (9/10): ['nba', 'premier', 'league', 'champions', 'cup', 'serie', 'a', 'efl', 'coupe']
2025-03-05 08:09:27,126 - config.llm_config - INFO - Filtered keywords: ['nba', 'premier', 'league', 'champions', 'cup', 'serie', 'a', 'efl', 'coupe', 'default']
2025-03-05 08:09:27,127 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: . Roma... and keyword_count: 10
2025-03-05 08:09:27,127 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:28,132 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:28,133 - config.llm_config - INFO - Filtered keywords: ['roma', 'nba', 'regular', 'season', 'copa', 'del', 'rey', 'serie', 'a', 'matchday']
2025-03-05 08:09:28,133 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ton Vi... and keyword_count: 10
2025-03-05 08:09:28,134 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:29,092 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:29,093 - config.llm_config - INFO - Filtered keywords: ['prediction', 'challenge', 'league', 'teams', 'rewards', 'sign', 'up', 'join', 'basketball', 'football']
2025-03-05 08:09:29,093 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Piston... and keyword_count: 10
2025-03-05 08:09:29,093 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:30,099 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:30,100 - config.llm_config - INFO - Filtered keywords: ['nba', 'premier', 'league', 'uefa', 'champions', 'serie', 'a', 'la', 'liga', 'bundesliga']
2025-03-05 08:09:30,100 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text:  vs. T... and keyword_count: 10
2025-03-05 08:09:30,100 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:30,957 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:30,958 - config.llm_config - INFO - Insufficient keywords (4/10): ['serie', 'nba', 'premier', 'bundesliga']
2025-03-05 08:09:30,958 - config.llm_config - INFO - Filtered keywords: ['serie', 'nba', 'premier', 'bundesliga', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 08:09:30,959 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: llenge... and keyword_count: 10
2025-03-05 08:09:30,959 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:32,074 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:32,075 - config.llm_config - INFO - Insufficient keywords (5/10): ['nba', 'egame', 'team', 'win', 'predict']
2025-03-05 08:09:32,075 - config.llm_config - INFO - Filtered keywords: ['nba', 'egame', 'team', 'win', 'predict', 'default', 'default', 'default', 'default', 'default']
2025-03-05 08:09:32,075 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: lanta
... and keyword_count: 10
2025-03-05 08:09:32,076 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:33,161 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:33,162 - config.llm_config - INFO - Insufficient keywords (6/10): ['nba', 'bundesliga', 'leagues', 'teams', 'prediction', 'egame']
2025-03-05 08:09:33,162 - config.llm_config - INFO - Filtered keywords: ['nba', 'bundesliga', 'leagues', 'teams', 'prediction', 'egame', 'default', 'default', 'default', 'default']
2025-03-05 08:09:33,162 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: 
Barce... and keyword_count: 10
2025-03-05 08:09:33,163 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:34,388 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:34,389 - config.llm_config - INFO - Insufficient keywords (3/10): ['nba', 'bundesliga', 'uecl']
2025-03-05 08:09:34,389 - config.llm_config - INFO - Filtered keywords: ['nba', 'bundesliga', 'uecl', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 08:09:34,389 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: A East... and keyword_count: 10
2025-03-05 08:09:34,390 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:35,645 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:35,646 - config.llm_config - INFO - Insufficient keywords (2/10): ['nba', 'bundesliga']
2025-03-05 08:09:35,646 - config.llm_config - INFO - Filtered keywords: ['nba', 'bundesliga', 'default', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 08:09:35,646 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text:  

✅✅*... and keyword_count: 10
2025-03-05 08:09:35,646 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:36,763 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:36,764 - config.llm_config - INFO - Insufficient keywords (8/10): ['egame', 'prediction', 'time', 'teams', 'win', 'rewards', 'nba', 'bundesliga']
2025-03-05 08:09:36,764 - config.llm_config - INFO - Filtered keywords: ['egame', 'prediction', 'time', 'teams', 'win', 'rewards', 'nba', 'bundesliga', 'default', 'default']
2025-03-05 08:09:36,764 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: 

Prem... and keyword_count: 10
2025-03-05 08:09:36,765 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:37,783 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:37,784 - config.llm_config - INFO - Filtered keywords: ['premier', 'league', 'round', 'la', 'liga', 'ligue', '1', 'nba', 'regular', 'season']
2025-03-05 08:09:37,784 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: up A: ... and keyword_count: 10
2025-03-05 08:09:37,784 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:38,806 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:38,807 - config.llm_config - INFO - Insufficient keywords (9/10): ['nba', 'regular', 'season', 'eastern', 'conference', 'tournament', 'western', 'conference', 'uefa']
2025-03-05 08:09:38,807 - config.llm_config - INFO - Filtered keywords: ['nba', 'regular', 'season', 'eastern', 'conference', 'tournament', 'western', 'conference', 'uefa', 'default']
2025-03-05 08:09:38,807 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: Bucks
... and keyword_count: 10
2025-03-05 08:09:38,808 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:39,969 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:39,970 - config.llm_config - INFO - Filtered keywords: ['nba', 'bucks', 'knicks', 'warriors', 'lakers', 'raptors', 'pacers', 'pelicans', 'jazz', 'timberwolves']
2025-03-05 08:09:39,970 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: eghlal... and keyword_count: 10
2025-03-05 08:09:39,971 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:41,077 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:41,078 - config.llm_config - INFO - Filtered keywords: ['football', 'teams', 'matchday', 'league', 'champions', 'prediction', 'win', 'big', 'rewards', 'bundesliga']
2025-03-05 08:09:41,078 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: n Big!... and keyword_count: 10
2025-03-05 08:09:41,078 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:42,200 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:42,200 - config.llm_config - INFO - Insufficient keywords (9/10): ['nba', 'prediction', 'leagues', 'bundesliga', 'serie', 'ligue', 'premier', 'egame', 'sign']
2025-03-05 08:09:42,201 - config.llm_config - INFO - Filtered keywords: ['nba', 'prediction', 'leagues', 'bundesliga', 'serie', 'ligue', 'premier', 'egame', 'sign', 'default']
2025-03-05 08:09:42,201 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ue 1, ... and keyword_count: 10
2025-03-05 08:09:42,201 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:43,378 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:43,379 - config.llm_config - INFO - Insufficient keywords (8/10): ['el', 'yamal', 'barcelona', 'real', 'madrid', 'champions', 'league', 'nba']
2025-03-05 08:09:43,379 - config.llm_config - INFO - Filtered keywords: ['el', 'yamal', 'barcelona', 'real', 'madrid', 'champions', 'league', 'nba', 'default', 'default']
2025-03-05 08:09:43,379 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text:  VfB S... and keyword_count: 10
2025-03-05 08:09:43,380 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:44,622 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:44,623 - config.llm_config - INFO - Filtered keywords: ['sporting', 'cp', 'bologna', 'aston', 'villa', 'stuttgart', 'girona', 'slovan', 'bratislava', 'sturm']
2025-03-05 08:09:44,623 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: =invit... and keyword_count: 10
2025-03-05 08:09:44,624 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:45,781 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:45,781 - config.llm_config - INFO - Filtered keywords: ['uefa', 'nations', 'league', 'prediction', 'time', 'team', 'supporting', 'egame', 'win', 'rewards']
2025-03-05 08:09:45,782 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text:  Now &... and keyword_count: 10
2025-03-05 08:09:45,782 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:09:48,982 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:09:48,983 - config.llm_config - WARNING - No Python list format found in response: Here are the top 10 keywords extracted from the text:

1. **Egame** (7 mentions)
2. **Prediction** (6 mentions)
3. **Win Big** (5 mentions)
4. **League** (23 mentions, but often used in combination with specific league names, e.g. "Serie A League")
5. **Team** (14 mentions, including specific team names like Juventus and Barcelona)
6. **Match** (13 mentions, including specific match results and fixtures)
7. **Football** (4 mentions, although not explicitly stated as the primary focus)
8. **UEFA** (11 mentions, referring to European football competitions)
9. **Round** (12 mentions, often used in combination with specific round numbers, e.g. "Round 2")
10. **Matchday** (6 mentions, referring to league match fixtures)

Note that these keywords are not mutually exclusive and often appear together in the text.
2025-03-05 08:09:48,983 - config.llm_config - ERROR - Processing error for doc_id 2t0K9pv8NxvYWh42: Failed to extract keywords for block 23
2025-03-05 08:09:58,966 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2t0K9pv8NxvYWh42
2025-03-05 08:09:58,968 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: 😇🥰🥰3⃣6... and keyword_count: 10
2025-03-05 08:09:58,968 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:00,083 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:00,084 - config.llm_config - INFO - Filtered keywords: ['bet365', 'prediction', 'champions', 'league', 'uefa', 'nba', 'regular', 'season', 'matchday', 'manchester']
2025-03-05 08:10:00,084 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: urg
Co... and keyword_count: 10
2025-03-05 08:10:00,084 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:01,255 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:01,256 - config.llm_config - INFO - Insufficient keywords (3/10): ['nba', 'bundesliga', 'nfl']
2025-03-05 08:10:01,256 - config.llm_config - INFO - Filtered keywords: ['nba', 'bundesliga', 'nfl', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 08:10:01,256 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: League... and keyword_count: 10
2025-03-05 08:10:01,256 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:02,228 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:02,229 - config.llm_config - INFO - Insufficient keywords (9/10): ['league', 'nba', 'regular', 'season', 'chelsea', 'southampton', 'barcelona', 'madrid', 'bet365']
2025-03-05 08:10:02,229 - config.llm_config - INFO - Filtered keywords: ['league', 'nba', 'regular', 'season', 'chelsea', 'southampton', 'barcelona', 'madrid', 'bet365', 'default']
2025-03-05 08:10:02,229 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: mpions... and keyword_count: 10
2025-03-05 08:10:02,229 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:03,428 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:03,429 - config.llm_config - INFO - Insufficient keywords (4/10): ['bet365', 'nba', 'uefa', 'bundesliga']
2025-03-05 08:10:03,429 - config.llm_config - INFO - Filtered keywords: ['bet365', 'nba', 'uefa', 'bundesliga', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 08:10:03,429 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ace
Ex... and keyword_count: 10
2025-03-05 08:10:03,429 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:04,559 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:04,559 - config.llm_config - INFO - Insufficient keywords (6/10): ['soccer', 'nba', 'nfl', 'bet365', 'egame', 'leagues']
2025-03-05 08:10:04,559 - config.llm_config - INFO - Filtered keywords: ['soccer', 'nba', 'nfl', 'bet365', 'egame', 'leagues', 'default', 'default', 'default', 'default']
2025-03-05 08:10:04,560 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: . Roma... and keyword_count: 10
2025-03-05 08:10:04,560 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:05,593 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:05,594 - config.llm_config - WARNING - No Python list format found in response: ['Roma', 'Matchday', 'Round', 'Leagues', 'Prediction', 'Challenge', 'Team', 'League', 'Serie', 'Leg]
2025-03-05 08:10:05,594 - config.llm_config - ERROR - Processing error for doc_id 2t0K9pv8NxvYWh42: Failed to extract keywords for block 6
2025-03-05 08:10:18,288 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2t0K9pv8NxvYWh42
2025-03-05 08:10:18,288 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: 😇🥰🥰3⃣6... and keyword_count: 10
2025-03-05 08:10:18,289 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:19,413 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:19,414 - config.llm_config - INFO - Filtered keywords: ['bet365', 'league', 'champions', 'liga', 'nba', 'europe', 'cup', 'prediction', 'soccer', 'matchday']
2025-03-05 08:10:19,414 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: urg
Co... and keyword_count: 10
2025-03-05 08:10:19,414 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:20,634 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:20,635 - config.llm_config - INFO - Insufficient keywords (3/10): ['nba', 'bundesliga', 'bet365']
2025-03-05 08:10:20,635 - config.llm_config - INFO - Filtered keywords: ['nba', 'bundesliga', 'bet365', 'default', 'default', 'default', 'default', 'default', 'default', 'default']
2025-03-05 08:10:20,635 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: League... and keyword_count: 10
2025-03-05 08:10:20,635 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:21,782 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:21,783 - config.llm_config - INFO - Insufficient keywords (5/10): ['chelsea', 'southampton', 'barcelona', 'nba', 'bet365']
2025-03-05 08:10:21,783 - config.llm_config - INFO - Filtered keywords: ['chelsea', 'southampton', 'barcelona', 'nba', 'bet365', 'default', 'default', 'default', 'default', 'default']
2025-03-05 08:10:21,783 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: mpions... and keyword_count: 10
2025-03-05 08:10:21,783 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:22,913 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:22,914 - config.llm_config - INFO - Insufficient keywords (8/10): ['bet365', 'nba', 'europe', 'league', 'football', 'bet', 'prediction', 'champions']
2025-03-05 08:10:22,914 - config.llm_config - INFO - Filtered keywords: ['bet365', 'nba', 'europe', 'league', 'football', 'bet', 'prediction', 'champions', 'default', 'default']
2025-03-05 08:10:22,914 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: ace
Ex... and keyword_count: 10
2025-03-05 08:10:22,915 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:24,049 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:24,050 - config.llm_config - INFO - Insufficient keywords (7/10): ['soccer', 'basketball', 'nba', 'bet', 'challenge', 'prediction', 'competition']
2025-03-05 08:10:24,050 - config.llm_config - INFO - Filtered keywords: ['soccer', 'basketball', 'nba', 'bet', 'challenge', 'prediction', 'competition', 'default', 'default', 'default']
2025-03-05 08:10:24,051 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 10 keywords from this text: . Roma... and keyword_count: 10
2025-03-05 08:10:24,051 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 08:10:24,880 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:10:24,880 - config.llm_config - INFO - Insufficient keywords (7/10): ['nba', 'arsenal', 'quarterfinal', 'semifinal', 'leganes', 'barcelona', 'valencia']
2025-03-05 08:10:24,880 - config.llm_config - INFO - Filtered keywords: ['nba', 'arsenal', 'quarterfinal', 'semifinal', 'leganes', 'barcelona', 'valencia', 'default', 'default', 'default']
2025-03-05 08:10:24,881 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2t0K9pv8NxvYWh42
2025-03-05 08:37:19,454 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-05 08:37:19,455 - config.llm_config - INFO - Starting FastAPI application...
2025-03-05 08:38:33,367 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-05 08:38:33,368 - config.llm_config - INFO - Starting FastAPI application...
2025-03-05 08:43:49,621 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2t0K9pv8NxvYWh42
2025-03-05 08:43:49,622 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: 😇🥰🥰3⃣6... and keyword_count: 20
2025-03-05 08:43:49,623 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:45:17,327 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:45:17,329 - config.llm_config - INFO - Filtered keywords: ['league', 'champions', 'prediction', 'challenge', 'bet365', 'team', 'season', 'win', 'rewards', 'event', 'premier', 'bundesliga', 'nba', 'regular', 'matchday', 'telegram', 'bot', 'registration', 'access', 'excitement', 'predictions', 'sports', 'football', 'basketball']
2025-03-05 08:45:17,329 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: urg
Co... and keyword_count: 20
2025-03-05 08:45:17,329 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:45:23,792 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:45:23,793 - config.llm_config - INFO - Insufficient keywords (19/20): ['nba', 'regular', 'season', 'league', 'matchday', 'premier', 'la', 'ligue', 'serie', 'bundesliga', 'round', 'vs', 'madrid', 'paris', 'liverpool', 'juventus', 'milan', 'barcelona', 'manchester']
2025-03-05 08:45:23,794 - config.llm_config - INFO - Filtered keywords: ['nba', 'regular', 'season', 'league', 'matchday', 'premier', 'la', 'ligue', 'serie', 'bundesliga', 'round', 'vs', 'madrid', 'paris', 'liverpool', 'juventus', 'milan', 'barcelona', 'manchester', 'default']
2025-03-05 08:45:23,794 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: League... and keyword_count: 20
2025-03-05 08:45:23,794 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:45:30,396 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:45:30,397 - config.llm_config - INFO - Insufficient keywords (19/20): ['champions', 'league', 'barcelona', 'madrid', 'nba', 'chelsea', 'southampton', 'bet365', 'prediction', 'challenge', 'europa', 'mls', 'serie', 'premier', 'bundesliga', 'ligue', 'afc', 'concacaf', 'uefa']
2025-03-05 08:45:30,397 - config.llm_config - INFO - Filtered keywords: ['champions', 'league', 'barcelona', 'madrid', 'nba', 'chelsea', 'southampton', 'bet365', 'prediction', 'challenge', 'europa', 'mls', 'serie', 'premier', 'bundesliga', 'ligue', 'afc', 'concacaf', 'uefa', 'default']
2025-03-05 08:45:30,397 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: mpions... and keyword_count: 20
2025-03-05 08:45:30,398 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:45:36,976 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:45:36,977 - config.llm_config - INFO - Filtered keywords: ['league', 'uefa', 'champions', 'europa', 'round', 'vs', 'team', 'football', 'basketball', 'nba', 'regular', 'season', 'premier', 'bundesliga', 'ligue', 'serie', 'la', 'prediction', 'challenge', 'bet365', 'telegram']
2025-03-05 08:45:36,977 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ace
Ex... and keyword_count: 20
2025-03-05 08:45:36,977 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:45:44,427 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:45:44,428 - config.llm_config - INFO - Filtered keywords: ['nba', 'regular', 'season', 'vs', 'premier', 'league', 'la', 'liga', 'round', 'uefa', 'champions', 'league', 'playoff', 'copa', 'del', 'rey', 'quarterfinal', 'coupe', 'de', 'france', 'german', 'cup', 'italian', 'cup']
2025-03-05 08:45:44,428 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: . Roma... and keyword_count: 20
2025-03-05 08:45:44,428 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:45:48,958 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:45:48,959 - config.llm_config - INFO - Insufficient keywords (18/20): ['madrid', 'arsenal', 'bucks', 'cavaliers', 'spurs', 'wizards', 'heat', 'grizzlies', 'bulls', 'warriors', 'pelicans', 'suns', 'magic', 'kings', 'osasuna', 'fiorentina', 'liverpool', 'barcelona']
2025-03-05 08:45:48,959 - config.llm_config - INFO - Filtered keywords: ['madrid', 'arsenal', 'bucks', 'cavaliers', 'spurs', 'wizards', 'heat', 'grizzlies', 'bulls', 'warriors', 'pelicans', 'suns', 'magic', 'kings', 'osasuna', 'fiorentina', 'liverpool', 'barcelona', 'default', 'default']
2025-03-05 08:45:48,960 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2t0K9pv8NxvYWh42
2025-03-05 08:45:48,970 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2q0b0ha1QHF9sKgz
2025-03-05 08:45:48,971 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: 📣 Want... and keyword_count: 20
2025-03-05 08:45:48,972 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:45:53,646 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:45:53,647 - config.llm_config - INFO - Insufficient keywords (19/20): ['scammers', 'telegram', 'cro', 'security', 'privacy', 'settings', 'account', 'support', 'ambassadors', 'team', 'crypto', 'vote', 'campaign', 'trading', 'investment', 'blockchain', 'ccc', 'channels', 'messages']
2025-03-05 08:45:53,647 - config.llm_config - INFO - Filtered keywords: ['scammers', 'telegram', 'cro', 'security', 'privacy', 'settings', 'account', 'support', 'ambassadors', 'team', 'crypto', 'vote', 'campaign', 'trading', 'investment', 'blockchain', 'ccc', 'channels', 'messages', 'default']
2025-03-05 08:45:53,648 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2q0b0ha1QHF9sKgz
2025-03-05 08:50:30,589 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2dz704LWOmg0A7ib
2025-03-05 08:50:30,591 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: I wasn... and keyword_count: 20
2025-03-05 08:50:30,591 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:50:34,490 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:50:34,491 - config.llm_config - INFO - Filtered keywords: ['weight', 'loss', 'health', 'stamina', 'herbal', 'teas', 'coffee', 'gut', 'mood', 'supplements', 'adult', 'eating', 'focus', 'brain', 'fog', 'pills', 'scam', 'unwind', 'neighor', 'crush']
2025-03-05 08:50:34,492 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2dz704LWOmg0A7ib
2025-03-05 08:50:44,813 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2dz704LWOmg0A7ib
2025-03-05 08:50:44,813 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: I wasn... and keyword_count: 20
2025-03-05 08:50:44,814 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:50:51,074 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:50:51,075 - config.llm_config - INFO - Filtered keywords: ['weight', 'loss', 'health', 'fitness', 'body', 'mind', 'stamina', 'energy', 'supplements', 'nutrition', 'wellness', 'gym', 'workout', 'motivation', 'inspiration', 'mental', 'focus', 'libido', 'testosterone', 'brain']
2025-03-05 08:50:51,076 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ీట్ మె... and keyword_count: 20
2025-03-05 08:50:51,076 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:51:36,295 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:51:36,296 - config.llm_config - WARNING - No Python list format found in response: చూస్తున్నారు డాక్టర్ గారు. 
విషయం ఏమిటంటే, 8 సంవత్సరాల బాలిక ఉంది. 
ఆమెకు చిన్నప్పటి నుండి అనేక వ్యాధులు ఉన్నాయి.
ఆమెకు 'MPS' (మ్యూకో పాలీ సక్కరైడోసిస్) అనే వ్యాధి ఉంది.
దీనికి చికిత్స చెయ్యడానికి, మేము అనేక హాస్పటల్స్‌కు వెళ్లాం.
డబ్బు ఖర్చు చేశాం. 
కానీ, స్పష్టమైన ఫలితాలు అందలేదు.
చివరగా, డాక్టర్లు ఆమె బోన్‌మ్యారో మార్పిడి చేయాలని, దీని ధర 25 లక్షల రూపాయలు అని సలహా ఇచ్చారు.
ఈ వ్యాధి కోసం, మీరు ఏదైనా సహాయం చేయగలరు.
అప్పుడు, మీకు ఆర్థిక సహాయం ఉంటే, నేను దానిని అనుమతిస్తాను.
ఈ వ్యాధి కోసం, మీరు ఏదైనా డబ్బు ఇస్తే, నేను ఆశిస్తాను.
ధన్యవాదాలు.
2025-03-05 08:51:36,296 - config.llm_config - ERROR - Processing error for doc_id 2dz704LWOmg0A7ib: Failed to extract keywords for block 2
2025-03-05 08:57:11,123 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2GrEAv52BRvusDFF
2025-03-05 08:57:11,124 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ⛩ Welc... and keyword_count: 20
2025-03-05 08:57:11,125 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:57:17,705 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:57:17,706 - config.llm_config - INFO - Filtered keywords: ['soratopia', 'game', 'telegram', 'invitation', 'code', 'samurai', 'rewards', 'quests', 'explore', 'announcements', 'chat', 'invite', 'codes', 'season', 'fighting', 'style', 'power', 'peril', 'stranger', 'teachings']
2025-03-05 08:57:17,706 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  plz n... and keyword_count: 20
2025-03-05 08:57:17,707 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:57:24,172 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:57:24,173 - config.llm_config - INFO - Insufficient keywords (19/20): ['soratopia', 'ritual', 'blade', 'discipline', 'weapon', 'legacy', 'choices', 'reward', 'temple', 'agility', 'katana', 'mastery', 'precision', 'protection', 'samurai', 'village', 'illness', 'meditate', 'strength']
2025-03-05 08:57:24,173 - config.llm_config - INFO - Filtered keywords: ['soratopia', 'ritual', 'blade', 'discipline', 'weapon', 'legacy', 'choices', 'reward', 'temple', 'agility', 'katana', 'mastery', 'precision', 'protection', 'samurai', 'village', 'illness', 'meditate', 'strength', 'default']
2025-03-05 08:57:24,173 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ord.
*... and keyword_count: 20
2025-03-05 08:57:24,173 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:57:29,416 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:57:29,417 - config.llm_config - INFO - Filtered keywords: ['soratopia', 'game', 'challenge', 'announcements', 'chat', 'invite', 'codes', 'mastery', 'battle', 'mind', 'victory', 'samurai', 'musashi', 'strategy', 'philosophy', 'legend', 'spirit', 'ritual', 'season', 'token']
2025-03-05 08:57:29,418 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2GrEAv52BRvusDFF
2025-03-05 08:58:37,961 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=49iZyQcFxyAnzSlm
2025-03-05 08:58:37,961 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **🗣️ V... and keyword_count: 20
2025-03-05 08:58:37,961 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:58:47,452 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:58:47,453 - config.llm_config - INFO - Filtered keywords: ['spotify', 'crack', 'android', 'ios', 'windows', 'mod', 'guida', 'installazione', 'aggiornamento', 'versione', 'nuovo', 'metodo', 'avvertenze', 'fonte', 'canale', 'gruppo', 'cazzeggio', 'wrapped', '2024', 'link', 'condividi', 'news', 'novembre', 'rockmods', 'eeveespotify', 'powershell', 'antivirus', 'disinstallazione']
2025-03-05 08:58:47,453 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: @Spoti... and keyword_count: 20
2025-03-05 08:58:47,453 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 08:59:09,737 - config.llm_config - INFO - AI response received successfully
2025-03-05 08:59:09,738 - config.llm_config - WARNING - No Python list format found in response: Sembra che tu abbia fornito un messaggio di installazione e informazioni su una versione cracked di Spotify. Tuttavia, è importante notare che utilizzare software crackato o modifiche non ufficiali può violare i termini di servizio dell'applicazione e potrebbe esporti a rischi per la sicurezza dei dati.

Se stai cercando informazioni su come installare Spotify in modo legale, posso fornirti una guida generica:

1. **Disinstalla eventuali versioni precedenti**: Assicurati di disinstallare qualsiasi versione precedente di Spotify dal tuo dispositivo per evitare conflitti.

2. **Scarica l'ultima versione ufficiale**: Visita il sito web ufficiale di Spotify e scarica l'ultima versione del software. Questo ti assicurerà di avere le funzionalità più recenti e gli aggiornamenti di sicurezza.

3. **Segui le istruzioni di installazione**: Una volta scaricato il file, segui le istruzioni per l'installazione. Di solito, questo implica eseguire il file eseguibile (per Windows) o aprire il file DMG e trascinare l'icona di Spotify nella cartella "Applicazioni" (per macOS).

4. **Accedi o crea un account**: Dopo l'installazione, avvia Spotify e accedi con il tuo account esistente o crea un nuovo account se non ne hai già uno.

Per quanto riguarda le funzionalità di cui hai parlato, come skip illimitati, no ads, e qualità alta, queste sono tipicamente disponibili con un abbonamento a Spotify Premium. L'abbonamento premium offre molte altre funzionalità esclusive rispetto alla versione gratuita.

Se hai domande specifiche su come utilizzare Spotify o sui suoi servizi, sarò felice di aiutarti.
2025-03-05 08:59:09,738 - config.llm_config - ERROR - Processing error for doc_id 49iZyQcFxyAnzSlm: Failed to extract keywords for block 2
2025-03-05 09:00:02,686 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=RK2mbWMWulX2tls9
2025-03-05 09:00:02,687 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Walk-i... and keyword_count: 20
2025-03-05 09:00:02,687 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:00:10,480 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:00:10,481 - config.llm_config - INFO - Filtered keywords: ['uae', 'jobs', 'dubai', 'interview', 'healthcare', 'nmc', 'hospital', 'driver', 'licenses', 'certificate', 'experience', 'salary', 'benefits', 'visa', 'accommodation', 'cv', 'resume', 'seha', 'clinics', 'ambulatory', 'services', 'medical', 'nursing', 'therapist', 'technician', 'engineering']
2025-03-05 09:00:10,482 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ai is ... and keyword_count: 20
2025-03-05 09:00:10,482 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:00:17,296 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:00:17,297 - config.llm_config - INFO - Filtered keywords: ['jobs', 'uae', 'dubai', 'abudhabi', 'healthcare', 'nursing', 'hr', 'talentacquisition', 'callcenter', 'documentcontroller', 'administration', 'recruitment', 'hiring', 'career', 'employment', 'opportunities', 'vacancies', 'positions', 'uaejobs', 'ajiranawe', 'dubaijobs', 'abudhabijobs', 'healthcarejobs']
2025-03-05 09:00:17,297 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: g gree... and keyword_count: 20
2025-03-05 09:00:17,297 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:00:24,926 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:00:24,927 - config.llm_config - INFO - Filtered keywords: ['uaejobs', 'dubaijobs', 'ajiranawe', 'healthcarejobs', 'teacher', 'receptionist', 'customer', 'service', 'career', 'interview', 'job', 'positions', 'requirements', 'salary', 'location', 'company', 'name', 'email', 'cv', 'application', 'hospital', 'nurse', 'technician', 'engineer', 'assistant', 'manager', 'dubai', 'abu', 'dhabi', 'ajman']
2025-03-05 09:00:24,928 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  Chill... and keyword_count: 20
2025-03-05 09:00:24,928 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:00:30,958 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:00:30,960 - config.llm_config - INFO - Filtered keywords: ['jobs', 'uae', 'dubai', 'abu', 'dhabi', 'hiring', 'career', 'vacancy', 'employment', 'opportunity', 'recruitment', 'position', 'application', 'resume', 'interview', 'salary', 'experience', 'location', 'company', 'industry']
2025-03-05 09:00:30,960 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: visor
... and keyword_count: 20
2025-03-05 09:00:30,960 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:00:37,633 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:00:37,634 - config.llm_config - INFO - Filtered keywords: ['uae', 'jobs', 'dubai', 'ajiranawe', 'hiring', 'career', 'vacancy', 'employment', 'opportunity', 'resume', 'cv', 'interview', 'recruitment', 'job', 'position', 'available', 'apply', 'work', 'employee', 'company', 'hr', 'management', 'staff', 'team', 'member']
2025-03-05 09:00:37,634 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: bs We'... and keyword_count: 20
2025-03-05 09:00:37,634 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:00:43,193 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:00:43,194 - config.llm_config - INFO - Filtered keywords: ['dubai', 'jobs', 'uae', 'call', 'center', 'agent', 'security', 'guards', 'telesales', 'customer', 'service', 'representative', 'hr', 'receptionist', 'admin', 'interview', 'hiring', 'recruitment', 'career', 'employment']
2025-03-05 09:00:43,194 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: s and ... and keyword_count: 20
2025-03-05 09:00:43,194 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:00:50,338 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:00:50,339 - config.llm_config - INFO - Filtered keywords: ['uae', 'jobs', 'dubai', 'hr', 'assistant', 'receptionist', 'administration', 'customer', 'service', 'english', 'hindi', 'ms', 'office', 'organizational', 'communication', 'team', 'management', 'operations', 'healthcare', 'hospital', 'education', 'teacher', 'school', 'exchange', 'industry', 'banking', 'shipping', 'logistics', 'business', 'development']
2025-03-05 09:00:50,339 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ENCE i... and keyword_count: 20
2025-03-05 09:00:50,339 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:00:57,363 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:00:57,364 - config.llm_config - INFO - Insufficient keywords (19/20): ['uaejobs', 'ajiranawe', 'healthcare', 'nurse', 'hospital', 'dubai', 'job', 'career', 'walkininterview', 'housekeeping', 'laundry', 'drivers', 'cleaner', 'salesman', 'medical', 'licensure', 'recruitment', 'hr', 'administration']
2025-03-05 09:00:57,364 - config.llm_config - INFO - Filtered keywords: ['uaejobs', 'ajiranawe', 'healthcare', 'nurse', 'hospital', 'dubai', 'job', 'career', 'walkininterview', 'housekeeping', 'laundry', 'drivers', 'cleaner', 'salesman', 'medical', 'licensure', 'recruitment', 'hr', 'administration', 'default']
2025-03-05 09:00:57,364 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ing fo... and keyword_count: 20
2025-03-05 09:00:57,364 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:01:02,753 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:01:02,754 - config.llm_config - INFO - Filtered keywords: ['jobs', 'uae', 'teacher', 'pharmacist', 'cleaner', 'manager', 'interview', 'dubai', 'sharjah', 'hotel', 'restaurant', 'finance', 'accounting', 'sales', 'engineering', 'carpenter', 'electrician', 'plumber', 'mechanic', 'technician']
2025-03-05 09:01:02,756 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: RK2mbWMWulX2tls9
2025-03-05 09:01:52,782 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=j5INqzo5dXs8N2j0
2025-03-05 09:01:52,783 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: the ne... and keyword_count: 20
2025-03-05 09:01:52,784 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:01:58,208 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:01:58,209 - config.llm_config - INFO - Filtered keywords: ['python', 'learn', 'numpy', 'library', 'coding', 'help', 'question', 'problem', 'code', 'install', 'module', 'error', 'framework', 'django', 'flask', 'telegram', 'bot', 'aiogram', 'pandas', 'mathematics']
2025-03-05 09:01:58,210 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: viideo... and keyword_count: 20
2025-03-05 09:01:58,210 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:02:03,667 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:02:03,668 - config.llm_config - INFO - Insufficient keywords (19/20): ['python', 'django', 'tutorial', 'code', 'learn', 'beginner', 'resource', 'library', 'project', 'roadmap', 'node', 'database', 'model', 'javascript', 'visualization', 'matplotlib', 'seaborn', 'numpy', 'pandas']
2025-03-05 09:02:03,668 - config.llm_config - INFO - Filtered keywords: ['python', 'django', 'tutorial', 'code', 'learn', 'beginner', 'resource', 'library', 'project', 'roadmap', 'node', 'database', 'model', 'javascript', 'visualization', 'matplotlib', 'seaborn', 'numpy', 'pandas', 'default']
2025-03-05 09:02:03,668 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ns str... and keyword_count: 20
2025-03-05 09:02:03,669 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:02:09,378 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:02:09,378 - config.llm_config - INFO - Filtered keywords: ['python', 'input', 'string', 'integer', 'print', 'clouded', 'compiled', 'language', 'interpreted', 'executable', 'kotlin', 'android', 'app', 'library', 'error', 'zlib', 'headers', 'termux', 'apk', 'kivy', 'pandas']
2025-03-05 09:02:09,379 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: n be d... and keyword_count: 20
2025-03-05 09:02:09,379 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:02:13,127 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:02:13,128 - config.llm_config - INFO - Filtered keywords: ['python', 'learn', 'beginner', 'app', 'development', 'mobile', 'kivy', 'library', 'basics', 'project', 'telegram', 'bots', 'frameworks', 'resources', 'tutorials', 'courses', 'books', 'apps', 'images', 'data']
2025-03-05 09:02:13,129 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: j5INqzo5dXs8N2j0
2025-03-05 09:09:01,788 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-05 09:09:01,789 - config.llm_config - INFO - Starting FastAPI application...
2025-03-05 09:28:34,129 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=69CsIqkGA3F6EV4V
2025-03-05 09:28:34,132 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **🌟 WE... and keyword_count: 20
2025-03-05 09:28:34,132 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 09:28:45,042 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:28:45,044 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'pst2', 'airdrop', 'nft', 'eve', 'hxc', 'hexacore', 'ago', 'pass', 'ugc', 'platform', 'gameplay', 'video', 'contest', 'leaderboard', 'rewards', 'gaming', 'community', 'update', 'ama']
2025-03-05 09:28:45,044 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ic War... and keyword_count: 20
2025-03-05 09:28:45,044 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 09:28:46,239 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:28:46,240 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'ago', 'passes', 'steel', 'agocoin', 'telegram', 'app', 'presale', 'ton', 'wallet', 'revolution', 'gaming', 'ecosystem', 'community', 'challenge', 'web3', 'mars', 'crypto']
2025-03-05 09:28:46,240 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: asses:... and keyword_count: 20
2025-03-05 09:28:46,241 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 09:28:47,491 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:28:47,492 - config.llm_config - INFO - Filtered keywords: ['passes', 'ago', 'hexacore', 'ton', 'presale', 'wallet', 'steel', 'bronze', 'revolution', 'heroes', 'lootbox', 'tonkeeper', 'telegram', 'app', 'username', 'comment', 'transaction', 'guide']
2025-03-05 09:28:47,492 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: gra.ph... and keyword_count: 20
2025-03-05 09:28:47,492 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 09:28:48,741 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:28:48,741 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'ago', 'passes', 'presale', 'tokens', 'nft', 'character', 'generation', 'ai', 'platform', 'rewards', 'benefits', 'staking', 'options', 'raffle', 'szn', 'ii', 'grand', 'finale', 'hexacoin']
2025-03-05 09:28:48,742 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: SHARE ... and keyword_count: 20
2025-03-05 09:28:48,742 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 09:28:50,077 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:28:50,078 - config.llm_config - INFO - Filtered keywords: ['telegram', 'hexacore', 'ago', 'pst2', 'airdrop', 'raffle', 'tickets', 'leaderboard', 'presale', 'gaming', 'experience', 'stars', 'level', 'upgrades', 'taps', 'claims', 'points', 'boost', 'tokens', 'passes']
2025-03-05 09:28:50,078 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: rience... and keyword_count: 20
2025-03-05 09:28:50,078 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 09:28:51,348 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:28:51,349 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'ago', 'pass', 'characters', 'platform', 'airdrop', 'token', 'users', 'community', 'holders', 'hxc', 'token', 'airdrop', 'level', 'ago', 'earnings', 'ton', 'wallet']
2025-03-05 09:28:51,349 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: NDS ON... and keyword_count: 20
2025-03-05 09:28:51,349 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 09:28:52,537 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:28:52,538 - config.llm_config - INFO - Filtered keywords: ['web3', 'games', 'bnbchain', 'leaderboard', 'rewards', 'ugc', 'platform', 'tournament', 'prizes', 'ago', 'airdrop', 'points', 'hexacore', 'app', 'telegram', 'nft', 'hxc']
2025-03-05 09:28:52,540 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 69CsIqkGA3F6EV4V, total_blocks=7
2025-03-05 09:44:30,298 - config.llm_config - INFO - Received request: text length=611, keyword_count=20
2025-03-05 09:44:30,298 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: You ar... and keyword_count: 20
2025-03-05 09:44:30,299 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 09:44:34,400 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:44:34,401 - config.llm_config - INFO - Filtered keywords: ['keywords', 'text', 'importance', 'relevance', 'context', 'priority', 'format', 'python', 'list', 'input', 'user', 'extracting', 'advanced', 'tasked', 'based', 'descending', 'order']
2025-03-05 09:44:34,402 - config.llm_config - INFO - Returning keywords: ['keywords', 'text', 'importance', 'relevance', 'context', 'priority', 'format', 'python', 'list', 'input', 'user', 'extracting', 'advanced', 'tasked', 'based', 'descending', 'order']
2025-03-05 09:50:03,104 - config.llm_config - INFO - Received request: text length=52, keyword_count=20
2025-03-05 09:50:03,104 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: I want... and keyword_count: 20
2025-03-05 09:50:03,105 - config.llm_config - INFO - Requesting AI response with model: llama3.1:latest, stream: False
2025-03-05 09:50:03,502 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:50:03,503 - config.llm_config - INFO - Filtered keywords: ['cryptocurrency', 'trading', 'group', 'join']
2025-03-05 09:50:03,503 - config.llm_config - INFO - Returning keywords: ['cryptocurrency', 'trading', 'group', 'join']
2025-03-05 09:50:23,131 - config.llm_config - INFO - Received request: text length=52, keyword_count=20
2025-03-05 09:50:23,132 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: I want... and keyword_count: 20
2025-03-05 09:50:23,132 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-05 09:50:42,465 - config.llm_config - INFO - AI response received successfully
2025-03-05 09:50:42,466 - config.llm_config - INFO - Filtered keywords: ['cryptocurrency', 'trading', 'bitcoin', 'ethereum', 'blockchain', 'investing', 'finance', 'money', 'market', 'exchange', 'coins', 'tokens', 'wallet', 'mining', 'price', 'analysis', 'forecast', 'investment', 'strategy', 'trader']
2025-03-05 09:50:42,466 - config.llm_config - INFO - Returning keywords: ['cryptocurrency', 'trading', 'bitcoin', 'ethereum', 'blockchain', 'investing', 'finance', 'money', 'market', 'exchange', 'coins', 'tokens', 'wallet', 'mining', 'price', 'analysis', 'forecast', 'investment', 'strategy', 'trader']
2025-03-10 06:26:25,558 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-10 06:26:25,559 - config.llm_config - INFO - Starting FastAPI application...
2025-03-10 06:26:25,927 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=doc_001
2025-03-10 06:26:25,928 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: AI and... and keyword_count: 20
2025-03-10 06:26:25,928 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:26:48,572 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-10 06:26:48,572 - config.llm_config - INFO - Starting FastAPI application...
2025-03-10 06:26:48,935 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=doc_001
2025-03-10 06:26:48,935 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: AI and... and keyword_count: 20
2025-03-10 06:26:48,936 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:27:24,427 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:27:24,428 - config.llm_config - INFO - Filtered keywords: ['machine', 'learning', 'ai', 'tech', 'transformation', 'artificial', 'intelligence', 'technology', 'innovation', 'automation', 'data', 'science', 'computing', 'algorithms', 'models', 'neural', 'networks', 'deep', 'natural', 'language']
2025-03-10 06:27:24,429 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Machin... and keyword_count: 20
2025-03-10 06:27:24,429 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:27:27,844 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:27:27,845 - config.llm_config - INFO - Filtered keywords: ['machine', 'learning', 'news', 'trending', 'today', 'artificial', 'intelligence', 'technology', 'data', 'science', 'innovation', 'computing', 'algorithms', 'models', 'programming', 'language', 'systems', 'networks', 'deep', 'analytics']
2025-03-10 06:27:27,845 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Tech d... and keyword_count: 20
2025-03-10 06:27:27,846 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:27:31,318 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:27:31,319 - config.llm_config - INFO - Filtered keywords: ['technology', 'innovation', 'data', 'drives', 'digital', 'transformation', 'artificial', 'intelligence', 'machine', 'learning', 'computing', 'science', 'research', 'development', 'growth', 'future', 'trends', 'advancements', 'solutions', 'progress']
2025-03-10 06:27:31,320 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: doc_001, total_blocks=3
2025-03-10 06:27:31,322 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady2
2025-03-10 06:27:31,323 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: https:... and keyword_count: 20
2025-03-10 06:27:31,324 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:27:38,003 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:27:38,004 - config.llm_config - INFO - Filtered keywords: ['crypto', 'scam', 'support', 'telegram', 'xrp', 'cro', 'wallet', 'security', 'bitcoin', 'eth', 'nexo', 'tokens', 'rewards', 'investment', 'blockchain', 'cronos', 'announcements', 'market', 'updates']
2025-03-10 06:27:38,005 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3Wd1Ady2, total_blocks=1
2025-03-10 06:27:38,007 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady2
2025-03-10 06:27:38,007 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: [ᑎᑌᙐᗪᘈ... and keyword_count: 20
2025-03-10 06:27:38,008 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:27:51,283 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:27:51,283 - config.llm_config - WARNING - No Python list format found in response: It appears that you've provided a log of messages from a Telegram group, where several users have been banned due to "CAS ban" reasons. CAS stands for Combot Auto Spam, which is a system designed to automatically detect and prevent spam in Telegram groups.

Here's a breakdown of the information:

* Multiple users have been banned with the reason "[CAS ban](https://t.me/combot/cas?startapp=<user_id>)", where `<user_id>` is the unique identifier for each user.
* Some users, such as [Malik](tg://user?id=6063724417) and [Abdin](tg://user?id=7254858413), have been muted instead of banned, with a specific duration until they can send messages again.
* There are also some general messages and conversations in the log, but they seem unrelated to the bans or mutes.

If you're looking for information on how to avoid getting banned by CAS or how to appeal a ban, I'd be happy to help. However, please note that I don't have any specific knowledge about the inner workings of Combot Auto Spam or its policies.
2025-03-10 06:27:51,284 - config.llm_config - WARNING - Skipping block 1 due to invalid or empty keyword list
2025-03-10 06:27:51,284 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: artapp... and keyword_count: 20
2025-03-10 06:27:51,284 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:28:01,945 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:28:01,945 - config.llm_config - WARNING - No Python list format found in response: It seems like there's a lot going on in this conversation, with many users being banned due to CAS bans. However, I'll focus on your question.

As for whether you're real or fake, it's difficult to say without more context. You're interacting with me through text, which could be generated by a human or an AI. Your message seems friendly and casual, but that doesn't necessarily prove one way or the other.

If you're asking because you're wondering about your own identity or existence, I'd say that's a philosophical question that has puzzled humans for centuries! If you're asking because you're curious about how others perceive you online, it might depend on how you interact with them and the content you share.

Could you provide more context or clarify what you mean by "real or fake"? I'm here to help and provide information to the best of my abilities.
2025-03-10 06:28:01,946 - config.llm_config - WARNING - Skipping block 2 due to invalid or empty keyword list
2025-03-10 06:28:01,946 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: CAS ba... and keyword_count: 20
2025-03-10 06:28:01,946 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:28:07,517 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:28:07,518 - config.llm_config - INFO - Filtered keywords: ['planx', 'cas', 'ban', 'rewards', 'tasks', 'wallet', 'pepe', 'coins', 'event', 'deposit', 'evm', 'tokens', 'discord', 'community', 'investment', 'returns', 'gaming', 'supplement', 'brain', 'memory']
2025-03-10 06:28:07,518 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3Wd1Ady2, total_blocks=1
2025-03-10 06:28:07,520 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3Wd1Ady215hLjbMO
2025-03-10 06:28:07,522 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **How ... and keyword_count: 20
2025-03-10 06:28:07,523 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:28:14,415 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:28:14,416 - config.llm_config - INFO - Filtered keywords: ['crypto', 'trading', 'exchange', 'security', 'tokens', 'ecosystem', 'blockchain', 'bitcoin', 'investments', 'financial', 'freedom', 'decentralized', 'web3', 'nfts', 'metaverse', 'airdrop', 'bingx', 'frog', 'launchpad']
2025-03-10 06:28:14,417 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ces, F... and keyword_count: 20
2025-03-10 06:28:14,417 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:28:21,251 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:28:21,252 - config.llm_config - INFO - Filtered keywords: ['defi', 'crypto', 'token', 'ecosystem', 'trading', 'blockchain', 'decentralized', 'finance', 'investment', 'security', 'vpn', 'launchpad', 'exchange', 'frog', 'usdt', 'bingx', 'wallet', 'gamification', 'liquidity']
2025-03-10 06:28:21,252 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: eciate... and keyword_count: 20
2025-03-10 06:28:21,252 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:28:28,666 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:28:28,667 - config.llm_config - INFO - Filtered keywords: ['frog', 'bingx', 'usdt', 'token', 'listing', 'trading', 'exchange', 'wallet', 'twitter', 'farm', 'ecosystem', 'litepaper', 'blockchain', 'withdrawal', 'market', 'chaos', 'liquidation', 'tge', 'cryptocurrency', 'fees']
2025-03-10 06:28:28,667 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  token... and keyword_count: 20
2025-03-10 06:28:28,667 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:28:35,363 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:28:35,364 - config.llm_config - INFO - Filtered keywords: ['token', 'ecosystem', 'cryptocurrency', 'blockchain', 'exchange', 'listings', 'trading', 'bot', 'fees', 'rewards', 'tokenomics', 'launchpad', 'vpn', 'nft', 'airdrop', 'staking', 'referrals']
2025-03-10 06:28:35,364 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: our pa... and keyword_count: 20
2025-03-10 06:28:35,365 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:28:42,357 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:28:42,358 - config.llm_config - INFO - Filtered keywords: ['token', 'frog', 'ecosystem', 'nfts', 'listing', 'cex', 'solana', 'blockchain', 'exchanges', 'promo', 'campaigns', 'wallet', 'twitter', 'instagram', 'lite', 'paper', 'beta', 'test', 'rewards', 'airdrop']
2025-03-10 06:28:42,358 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ive.go... and keyword_count: 20
2025-03-10 06:28:42,358 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:28:48,062 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:28:48,063 - config.llm_config - INFO - Filtered keywords: ['crypto', 'token', 'solana', 'blockchain', 'ecosystem', 'listing', 'exchanges', 'launchpad', 'exchange', 'vpn', 'wallet', 'tokenomics', 'trading', 'memecoins', 'lottery', 'portfolio', 'launch', 'partnership', 'community']
2025-03-10 06:28:48,064 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3Wd1Ady215hLjbMO, total_blocks=6
2025-03-10 06:28:48,067 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=6jva1gykkTK1gP6J
2025-03-10 06:28:48,067 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **How ... and keyword_count: 20
2025-03-10 06:28:48,067 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:28:54,755 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:28:54,756 - config.llm_config - INFO - Filtered keywords: ['crypto', 'trading', 'exchange', 'security', 'fees', 'tokens', 'ecosystem', 'launchpad', 'vpn', 'blockchain', 'wallet', 'token', 'investments', 'financial', 'freedom', 'decentralized', 'web3', 'nfts', 'metaverses']
2025-03-10 06:28:54,756 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ces, F... and keyword_count: 20
2025-03-10 06:28:54,757 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:29:01,576 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:29:01,576 - config.llm_config - INFO - Filtered keywords: ['defi', 'crypto', 'token', 'ecosystem', 'trading', 'blockchain', 'decentralized', 'finance', 'investment', 'security', 'vpn', 'launchpad', 'exchange', 'frog', 'usdt', 'bingx', 'wallet', 'gamification', 'liquidity']
2025-03-10 06:29:01,577 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: eciate... and keyword_count: 20
2025-03-10 06:29:01,577 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:29:09,014 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:29:09,015 - config.llm_config - INFO - Filtered keywords: ['frog', 'bingx', 'usdt', 'token', 'trading', 'exchange', 'listing', 'crypto', 'blockchain', 'ecosystem', 'market', 'price', 'volume', 'ath', 'wallet', 'twitter', 'instagram', 'litepaper', 'farm', 'game']
2025-03-10 06:29:09,016 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  token... and keyword_count: 20
2025-03-10 06:29:09,016 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:29:15,675 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:29:15,676 - config.llm_config - INFO - Filtered keywords: ['token', 'ecosystem', 'crypto', 'listing', 'exchange', 'utility', 'payment', 'rewards', 'liquidity', 'demand', 'supply', 'value', 'blockchain', 'wallet', 'twitter', 'instagram', 'airdrop', 'nft']
2025-03-10 06:29:15,677 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: our pa... and keyword_count: 20
2025-03-10 06:29:15,677 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:29:22,752 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:29:22,753 - config.llm_config - INFO - Filtered keywords: ['token', 'frog', 'ecosystem', 'blockchain', 'solana', 'listing', 'exchange', 'cex', 'usdt', 'wallet', 'crypto', 'bot', 'nfts', 'airdrop', 'beta', 'test', 'reward', 'participation', 'governance', 'deflationary']
2025-03-10 06:29:22,753 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ive.go... and keyword_count: 20
2025-03-10 06:29:22,753 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:29:28,365 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:29:28,366 - config.llm_config - INFO - Filtered keywords: ['crypto', 'token', 'solana', 'blockchain', 'ecosystem', 'listing', 'exchanges', 'launchpad', 'exchange', 'vpn', 'wallet', 'tokenomics', 'bot', 'lottery', 'portfolio', 'trading', 'memecoins', 'launch', 'network']
2025-03-10 06:29:28,367 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 6jva1gykkTK1gP6J, total_blocks=6
2025-03-10 06:29:28,370 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=1NjCx8DEH7uJqFi0
2025-03-10 06:29:28,370 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: https:... and keyword_count: 20
2025-03-10 06:29:28,370 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:29:35,190 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:29:35,191 - config.llm_config - INFO - Filtered keywords: ['bitcoin', 'crypto', 'marketing', 'telegram', 'twitter', 'nft', 'listing', 'partnership', 'ama', 'pinpost', 'cryptowhale', 'blockchain', 'trading', 'exchange', 'mintme', 'coingecko', 'whalebotalerts', 'btc', 'eth', 'mining']
2025-03-10 06:29:35,192 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 1NjCx8DEH7uJqFi0, total_blocks=1
2025-03-10 06:29:35,194 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=277E2jVyjNQDUMEk
2025-03-10 06:29:35,195 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **Welc... and keyword_count: 20
2025-03-10 06:29:35,196 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:29:42,001 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:29:42,002 - config.llm_config - INFO - Filtered keywords: ['registration', 'email', 'confirmation', 'dating', 'chat', 'girls', 'boys', 'message', 'add', 'me', 'hello', 'hi', 'good', 'morning', 'free', 'roleplay', 'grp', 'available', 'muted', 'reason']
2025-03-10 06:29:42,002 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **Euro... and keyword_count: 20
2025-03-10 06:29:42,002 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:29:48,541 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:29:48,542 - config.llm_config - INFO - Filtered keywords: ['registration', 'email', 'confirmation', 'welcome', 'telegram', 'girls', 'chat', 'roleplay', 'free', 'beautiful', 'message', 'add', 'me', 'horny', 'available', 'now', 'fun', 'sexting']
2025-03-10 06:29:48,542 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: yy Shh... and keyword_count: 20
2025-03-10 06:29:48,542 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:29:55,187 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:29:55,188 - config.llm_config - INFO - Filtered keywords: ['chat', 'dm', 'available', 'fun', 'girls', 'message', 'me', 'add', 'hello', 'hi', 'baby', 'blocked', 'roleplay', 'female', 'open', 'minded', 'sexting', 'whatsapp', 'number', 'registration']
2025-03-10 06:29:55,188 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: email ... and keyword_count: 20
2025-03-10 06:29:55,189 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:30:01,569 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:30:01,570 - config.llm_config - INFO - Filtered keywords: ['registration', 'email', 'confirm', 'welcome', 'girls', 'dm', 'message', 'fast', 'hello', 'sexy', 'tamil', 'boys', 'grp', 'fun', 'available', 'online', 'meetups', 'whatsapp', 'number', 'call']
2025-03-10 06:30:01,571 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: et now... and keyword_count: 20
2025-03-10 06:30:01,572 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:30:08,063 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:30:08,065 - config.llm_config - INFO - Filtered keywords: ['registration', 'email', 'confirmation', 'welcome', 'girls', 'boys', 'available', 'now', 'chat', 'meetups', 'online', 'real', 'roleplay', 'beautiful', 'free', 'dm', 'add', 'me', 'hello', 'hi']
2025-03-10 06:30:08,065 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: (tg://... and keyword_count: 20
2025-03-10 06:30:08,066 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:30:14,403 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:30:14,404 - config.llm_config - INFO - Filtered keywords: ['sex', 'chat', 'dm', 'me', 'available', 'now', 'girls', 'beautiful', 'roleplay', 'free', 'message', 'personal', 'interested', 'indian', 'girl', 'tamil', 'hello', 'welcome', 'registration', 'email']
2025-03-10 06:30:14,405 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: lcome!... and keyword_count: 20
2025-03-10 06:30:14,406 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:32:19,410 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:32:19,413 - config.llm_config - INFO - Filtered keywords: ['registration', 'email', 'confirmation', 'welcome', 'message', 'dm', 'chat', 'sex', 'roleplay', 'girls', 'boys', 'married', 'housewife', 'whatsapp', 'number', 'text', 'add', 'mute', 'reason']
2025-03-10 06:32:19,414 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  my ev... and keyword_count: 20
2025-03-10 06:32:19,414 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:32:25,280 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:32:25,281 - config.llm_config - INFO - Filtered keywords: ['hello', 'dm', 'msg', 'add', 'me', 'hi', 'shhh', 'quiet', 'muted', 'reason', 'be', 'nice', 'welcome', 'confirm', 'email', 'registration', 'italiano', 'spanish', 'uk', 'usa']
2025-03-10 06:32:25,285 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 277E2jVyjNQDUMEk, total_blocks=8
2025-03-10 06:32:25,288 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=5uGnLMYt7smJrE6x
2025-03-10 06:32:25,289 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Downlo... and keyword_count: 20
2025-03-10 06:32:25,291 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:32:30,765 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:32:30,766 - config.llm_config - INFO - Filtered keywords: ['bitcoin', 'crypto', 'trading', 'investment', 'telegram', 'btc', 'whale', 'insider', 'pump', 'coin', 'market', 'profit', 'loss', 'roi', 'airdrop', 'token', 'exchange', 'ceo', 'mining', 'blockchain']
2025-03-10 06:32:30,766 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  MintM... and keyword_count: 20
2025-03-10 06:32:30,766 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:32:37,867 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:32:37,867 - config.llm_config - INFO - Filtered keywords: ['transfers', 'cashapp', 'paypal', 'westernunion', 'skrill', 'venmo', 'zelle', 'chime', 'dumps', 'atm', 'pins', 'balance', 'carting', 'gas', 'station', 'casino', 'crypto', 'blockchain']
2025-03-10 06:32:37,868 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  Cash ... and keyword_count: 20
2025-03-10 06:32:37,868 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:32:43,111 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:32:43,112 - config.llm_config - INFO - Filtered keywords: ['cash', 'bank', 'account', 'transfer', 'usa', 'canada', 'crypto', 'trading', 'exchange', 'fees', 'investment', 'withdrawal', 'market', 'pips', 'usd', 'pairs', 'management', 'service', 'admin', 'registration']
2025-03-10 06:32:43,113 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 5uGnLMYt7smJrE6x, total_blocks=3
2025-03-10 06:32:43,114 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3KPzKY8OevjsbOXH
2025-03-10 06:32:43,116 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ❤️‍🔥😀K... and keyword_count: 20
2025-03-10 06:32:43,116 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:32:48,218 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:32:48,219 - config.llm_config - WARNING - No Python list format found in response: Извините, но кажется, что вы не задали вопрос или не описали проблему, которую необходимо решить. Если у вас есть конкретная тема или вопрос, пожалуйста, опишите подробнее, и я сделаю всё возможное, чтобы помочь вам найти ответ или решение.
2025-03-10 06:32:48,220 - config.llm_config - WARNING - Skipping block 1 due to invalid or empty keyword list
2025-03-10 06:32:48,221 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ОСУ КА... and keyword_count: 20
2025-03-10 06:32:48,221 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:32:53,977 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:32:53,978 - config.llm_config - WARNING - No Python list format found in response: Извините, но кажется, что вы предоставили контент, который не соответствует теме для обсуждения. Если у вас есть конкретные вопросы или темы, которые вы хотели бы обсудить, я готов помочь. Пожалуйста, опишите подробнее, и я сделаю всё возможное, чтобы оказать вам помощь.
2025-03-10 06:32:53,978 - config.llm_config - WARNING - Skipping block 2 due to invalid or empty keyword list
2025-03-10 06:32:53,978 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: иков ❗... and keyword_count: 20
2025-03-10 06:32:53,978 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:32:58,668 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:32:58,669 - config.llm_config - WARNING - No Python list format found in response: Я не могу предоставлять или поддерживать контент, связанный с взрослыми услугами или содержанием для совершеннолетних. Если у вас есть другие вопросы или темы, которые вы хотели бы обсудить, я здесь, чтобы помочь.
2025-03-10 06:32:58,669 - config.llm_config - WARNING - Skipping block 3 due to invalid or empty keyword list
2025-03-10 06:32:58,669 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ческий... and keyword_count: 20
2025-03-10 06:32:58,669 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:03,424 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:03,425 - config.llm_config - WARNING - No Python list format found in response: Я не могу предоставлять или обрабатывать информацию, связанную с услугами интимного характера. Если у вас есть другие вопросы или если я могу вам помочь в чем-то другом, пожалуйста, дайте мне знать!
2025-03-10 06:33:03,425 - config.llm_config - WARNING - Skipping block 4 due to invalid or empty keyword list
2025-03-10 06:33:03,425 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: отдохн... and keyword_count: 20
2025-03-10 06:33:03,425 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:11,646 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:11,647 - config.llm_config - WARNING - No Python list format found in response: Извините, но кажется, что вы предоставили рекламный текст, содержащий контактную информацию и описания услуг, которые не подходят для обсуждения в этом формате. Если у вас есть вопросы или темы, связанные с общими интересами, образованием, культурой, здоровьем, технологиями или любыми другими нейтральными темами, я готов помочь и предоставить информацию в пределах моих возможностей. Пожалуйста, уточните, о чем вы хотели бы поговорить или узнать больше.
2025-03-10 06:33:11,647 - config.llm_config - WARNING - Skipping block 5 due to invalid or empty keyword list
2025-03-10 06:33:11,647 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: 00₽💕
💕... and keyword_count: 20
2025-03-10 06:33:11,647 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:18,697 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:18,698 - config.llm_config - WARNING - No Python list format found in response: Извините, но кажется, что вы предоставили текст, содержащий личную информацию и описания услуг, которые не подходят для обсуждения в этом формате. Если у вас есть конкретные вопросы или темы, которые вы хотели бы обсудить, я готов помочь с любой другой информацией или поддержкой в пределах допустимых тем. Пожалуйста, уточните, если есть что-то еще, чем я могу вам помочь.
2025-03-10 06:33:18,698 - config.llm_config - WARNING - Skipping block 6 due to invalid or empty keyword list
2025-03-10 06:33:18,698 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: тоимос... and keyword_count: 20
2025-03-10 06:33:18,698 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:26,252 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:26,252 - config.llm_config - WARNING - No Python list format found in response: Извините, но кажется, что вы предоставили текст, содержащий личные объявления или рекламу интимных услуг. Я не могу участвовать в обсуждениях или предоставлении ответов на такие темы. Если у вас есть другие вопросы или темы, связанные с информацией, образованием, культурой, наукой или любыми другими подходящими темами, я буду рад помочь. Пожалуйста, опишите, как я могу вам помочь в другой области.
2025-03-10 06:33:26,252 - config.llm_config - WARNING - Skipping block 7 due to invalid or empty keyword list
2025-03-10 06:33:26,253 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  нам 🍾... and keyword_count: 20
2025-03-10 06:33:26,253 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:31,844 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:31,845 - config.llm_config - WARNING - No Python list format found in response: Извините, но кажется, что вы предоставили рекламный текст, содержащий информацию об интимных услугах. Я не могу участвовать в обсуждениях или ответах на такие запросы. Если у вас есть другие вопросы или темы, которые не связаны с этим контекстом, я готов помочь.
2025-03-10 06:33:31,845 - config.llm_config - WARNING - Skipping block 8 due to invalid or empty keyword list
2025-03-10 06:33:31,845 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: а 💋 🦋C... and keyword_count: 20
2025-03-10 06:33:31,845 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:36,920 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:36,920 - config.llm_config - WARNING - No Python list format found in response: Извините, но кажется, что предоставленный текст содержит контент для взрослых и рекламу интимных услуг. Я не могу участвовать в обсуждениях или ответах на такие темы. Есть ли другие вопросы или темы, по которым я могу вам помочь?
2025-03-10 06:33:36,920 - config.llm_config - WARNING - Skipping block 9 due to invalid or empty keyword list
2025-03-10 06:33:36,921 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: могаем... and keyword_count: 20
2025-03-10 06:33:36,921 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:44,425 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:44,426 - config.llm_config - WARNING - No Python list format found in response: Извините, но кажется, что вы предоставили рекламный текст, содержащий личные объявления и услуги интимного характера. Я не могу участвовать в обсуждениях или ответах на такие темы. Если у вас есть другие вопросы или темы, которые не связаны с интимными услугами, я готов помочь. Пожалуйста, опишите подробнее, и я сделаю всё возможное, чтобы предоставить вам полезную информацию или помощь.
2025-03-10 06:33:44,426 - config.llm_config - WARNING - Skipping block 10 due to invalid or empty keyword list
2025-03-10 06:33:44,426 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  - 600... and keyword_count: 20
2025-03-10 06:33:44,426 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:48,843 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:48,843 - config.llm_config - WARNING - No Python list format found in response: Я не могу предоставлять ответы, связанные с незаконной или неподходящей деятельностью. Если у вас есть другие вопросы или темы, которые вы хотели бы обсудить, я здесь, чтобы помочь.
2025-03-10 06:33:48,843 - config.llm_config - WARNING - Skipping block 11 due to invalid or empty keyword list
2025-03-10 06:33:48,843 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  сейча... and keyword_count: 20
2025-03-10 06:33:48,844 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:52,961 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:52,962 - config.llm_config - INFO - Filtered keywords: ['meeting', 'now', 'young', 'beautiful', 'travelers', 'visiting', 'soon', 'leaving', 'interesting', 'encounter', 'local', 'foreigners', 'tourists', 'fun', 'entertainment', 'nightlife', 'socializing', 'connection', 'immediate', 'current']
2025-03-10 06:33:52,967 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 3KPzKY8OevjsbOXH, total_blocks=1
2025-03-10 06:33:52,971 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2t0K9pv8NxvYWh42
2025-03-10 06:33:52,971 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: 😇🥰🥰3⃣6... and keyword_count: 20
2025-03-10 06:33:52,973 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:33:59,716 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:33:59,717 - config.llm_config - INFO - Filtered keywords: ['league', 'champions', 'prediction', 'challenge', 'bet365', 'teams', 'season', 'rewards', 'telegram', 'bot', 'access', 'registration', 'click', 'play', 'big', 'five', 'leagues', 'soccer', 'football', 'basketball']
2025-03-10 06:33:59,717 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: urg
Co... and keyword_count: 20
2025-03-10 06:33:59,718 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:34:07,023 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:34:07,023 - config.llm_config - INFO - Filtered keywords: ['football', 'nba', 'bundesliga', 'liverpool', 'juventus', 'barcelona', 'basketball', 'sports', 'bet365', 'predictions', 'leagues']
2025-03-10 06:34:07,024 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: League... and keyword_count: 20
2025-03-10 06:34:07,024 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:34:13,229 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:34:13,229 - config.llm_config - INFO - Filtered keywords: ['football', 'nba', 'bet365', 'league', 'prediction', 'challenge', 'teams', 'matches', 'soccer', 'basketball', 'sports', 'betting', 'telegram', 'bot', 'access', 'rewards', 'event', 'excitement']
2025-03-10 06:34:13,230 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: mpions... and keyword_count: 20
2025-03-10 06:34:13,230 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:34:20,061 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:34:20,062 - config.llm_config - INFO - Filtered keywords: ['champions', 'league', 'uefa', 'premier', 'football', 'basketball', 'nba', 'europa', 'bet365', 'prediction', 'challenge', 'bundesliga', 'ligue', 'serie', 'la', 'liga', 'teams', 'sports', 'betting', 'telegram']
2025-03-10 06:34:20,062 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ace
Ex... and keyword_count: 20
2025-03-10 06:34:20,063 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:34:27,183 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:34:27,183 - config.llm_config - INFO - Filtered keywords: ['football', 'nba', 'basketball', 'soccer', 'sports', 'bet365', 'egame', 'leagues', 'teams', 'matches', 'tournaments', 'cup', 'champions', 'league', 'round', 'playoff']
2025-03-10 06:34:27,184 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: . Roma... and keyword_count: 20
2025-03-10 06:34:27,184 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:34:32,070 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:34:32,071 - config.llm_config - INFO - Filtered keywords: ['football', 'basketball', 'nba', 'arsenal', 'liverpool', 'barcelona', 'valencia', 'sports', 'betting', 'games', 'telegram', 'champions']
2025-03-10 06:34:32,072 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2t0K9pv8NxvYWh42, total_blocks=6
2025-03-10 06:34:32,075 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2GrEAv52BRvusDFF
2025-03-10 06:34:32,075 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ⛩ Welc... and keyword_count: 20
2025-03-10 06:34:32,076 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:34:38,187 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:34:38,188 - config.llm_config - INFO - Filtered keywords: ['soratopia', 'game', 'telegram', 'invitation', 'code', 'samurai', 'rewards', 'quests', 'explore', 'season', 'announcements', 'chat', 'invite', 'codes', 'temple', 'nature', 'strategy', 'wisdom', 'ton']
2025-03-10 06:34:38,188 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  plz n... and keyword_count: 20
2025-03-10 06:34:38,189 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:34:44,760 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:34:44,760 - config.llm_config - INFO - Filtered keywords: ['soratopia', 'ritual', 'blade', 'discipline', 'weapon', 'samurai', 'agility', 'katana', 'precision', 'protection', 'mastery', 'strategy', 'temple', 'reward', 'illness', 'village', 'points', 'strength', 'patience']
2025-03-10 06:34:44,761 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ord.
*... and keyword_count: 20
2025-03-10 06:34:44,761 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:34:50,440 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:34:50,441 - config.llm_config - INFO - Filtered keywords: ['soratopia', 'game', 'challenge', 'samurai', 'victory', 'mind', 'battle', 'strategy', 'philosophy', 'legend', 'skill', 'spirit', 'ritual', 'token', 'season', 'rewards', 'courage', 'determination']
2025-03-10 06:34:50,442 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2GrEAv52BRvusDFF, total_blocks=3
2025-03-10 06:34:50,444 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=69CsIqkGA3F6EV4V
2025-03-10 06:34:50,445 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **🌟 WE... and keyword_count: 20
2025-03-10 06:34:50,445 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:34:57,524 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:34:57,525 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'pst2', 'hxc', 'airdrop', 'nft', 'gaming', 'community', 'users', 'update', 'cube', 'multitouch', 'contest', 'rewards', 'staking', 'leagues']
2025-03-10 06:34:57,525 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ic War... and keyword_count: 20
2025-03-10 06:34:57,526 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:35:05,898 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:35:05,899 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'ago', 'presale', 'passes', 'steel', 'ton', 'wallet', 'telegram', 'app', 'gaming', 'revolution', 'crypto', 'community', 'ecosystem', 'generative', 'ai', 'ugc', 'platform', 'milestone', 'achievement']
2025-03-10 06:35:05,899 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: asses:... and keyword_count: 20
2025-03-10 06:35:05,899 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:35:14,189 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:35:14,190 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'ago', 'passes', 'presale', 'ton', 'app', 'wallet', 'telegram', 'guide', 'revolution', 'gaming', 'community', 'heroes', 'lootbox', 'referral', 'tonkeeper', 'transaction', 'username', 'comment', 'purchase']
2025-03-10 06:35:14,190 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: gra.ph... and keyword_count: 20
2025-03-10 06:35:14,190 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:35:20,989 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:35:20,990 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'ago', 'pass', 'presale', 'tokens', 'nft', 'ai', 'gaming', 'community', 'rewards', 'benefits', 'hxc', 'airdrop', 'zealy', 'ugc', 'generative', 'platform', 'asset', 'generation', 'offering']
2025-03-10 06:35:20,990 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: SHARE ... and keyword_count: 20
2025-03-10 06:35:20,990 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:35:27,544 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:35:27,545 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'ago', 'presale', 'telegram', 'stars', 'airdrop', 'leaderboard', 'hxc', 'tokens', 'gaming', 'community', 'users', 'maintenance', 'roadmap', 'ugc', 'platform', 'tge', 'ecosystem', 'scaling']
2025-03-10 06:35:27,546 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: rience... and keyword_count: 20
2025-03-10 06:35:27,547 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:35:34,262 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:35:34,263 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'ago', 'pass', 'token', 'airdrop', 'game', 'platform', 'community', 'ai', 'mobile', 'gaming', 'character', 'generation', 'staking', 'benefits', 'ecosystem', 'tge', 'nft', 'hxc']
2025-03-10 06:35:34,264 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: NDS ON... and keyword_count: 20
2025-03-10 06:35:34,265 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:35:41,564 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:35:41,564 - config.llm_config - INFO - Filtered keywords: ['hexacore', 'bnbchain', 'web3', 'games', 'ugc', 'asset', 'generation', 'offering', 'platform', 'grand', 'finale', 'tournament', 'leaderboard', 'rewards', 'ago', 'airdrop', 'telegram', 'nft', 'hxc', 'token']
2025-03-10 06:35:41,565 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 69CsIqkGA3F6EV4V, total_blocks=7
2025-03-10 06:35:41,568 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=RK2mbWMWulX2tls9
2025-03-10 06:35:41,569 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Walk-i... and keyword_count: 20
2025-03-10 06:35:41,569 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:35:48,356 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:35:48,357 - config.llm_config - INFO - Filtered keywords: ['uae', 'jobs', 'dubai', 'healthcare', 'driving', 'license', 'interview', 'nmc', 'hospital', 'seha', 'clinics', 'medical', 'staff', 'nurse', 'doctor', 'therapist', 'technician', 'driver', 'cleaner', 'engineering']
2025-03-10 06:35:48,357 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ai is ... and keyword_count: 20
2025-03-10 06:35:48,357 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:35:56,620 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:35:56,621 - config.llm_config - INFO - Filtered keywords: ['uae', 'jobs', 'dubai', 'healthcare', 'nursing', 'hr', 'recruitment', 'career', 'employment', 'vacancy', 'hiring', 'opportunity', 'application', 'resume', 'cv', 'interview', 'position', 'company', 'employee', 'work']
2025-03-10 06:35:56,622 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: g gree... and keyword_count: 20
2025-03-10 06:35:56,622 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:36:02,971 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:36:02,972 - config.llm_config - INFO - Filtered keywords: ['jobs', 'uae', 'dubai', 'career', 'hiring', 'interview', 'recruitment', 'employment', 'vacancies', 'opportunities', 'ajman', 'healthcare', 'teaching', 'hospitality', 'finance', 'engineering', 'it', 'sales', 'marketing', 'management']
2025-03-10 06:36:02,972 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  Chill... and keyword_count: 20
2025-03-10 06:36:02,972 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:36:09,601 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:36:09,602 - config.llm_config - INFO - Filtered keywords: ['uae', 'jobs', 'dubai', 'abu', 'dhabi', 'hiring', 'career', 'vacancy', 'employment', 'opportunity', 'recruitment', 'ajman', 'healthcare', 'hospital', 'school', 'teacher', 'it', 'technician', 'engineer', 'accountant']
2025-03-10 06:36:09,603 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: visor
... and keyword_count: 20
2025-03-10 06:36:09,603 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:36:17,609 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:36:17,610 - config.llm_config - INFO - Filtered keywords: ['jobs', 'uae', 'dubai', 'hiring', 'careers', 'vacancies', 'employment', 'opportunities', 'recruitment', 'interviews', 'resumes', 'cvs', 'laundry', 'healthcare', 'education', 'it', 'engineering', 'marketing', 'management', 'sales']
2025-03-10 06:36:17,610 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: bs We'... and keyword_count: 20
2025-03-10 06:36:17,610 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:36:23,563 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:36:23,564 - config.llm_config - INFO - Filtered keywords: ['dubai', 'jobs', 'uae', 'telesales', 'hr', 'recruitment', 'administration', 'receptionist', 'sales', 'marketing', 'communication', 'english', 'arabic', 'interview', 'hiring', 'career', 'employment', 'vacancy']
2025-03-10 06:36:23,564 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: s and ... and keyword_count: 20
2025-03-10 06:36:23,565 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:36:29,435 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:36:29,436 - config.llm_config - INFO - Filtered keywords: ['uae', 'jobs', 'dubai', 'hr', 'admin', 'receptionist', 'healthcare', 'hospital', 'school', 'teacher', 'exchange', 'manager', 'cashier', 'security', 'guard', 'engineering', 'it', 'software', 'civil', 'mechanical']
2025-03-10 06:36:29,437 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ENCE i... and keyword_count: 20
2025-03-10 06:36:29,437 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:36:36,798 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:36:36,799 - config.llm_config - INFO - Filtered keywords: ['jobs', 'uae', 'hospital', 'nurse', 'healthcare', 'abu', 'dhabi', 'dubai', 'license', 'experience', 'recruitment', 'career', 'opportunity', 'walkin', 'interview', 'driver', 'laundry', 'equipment', 'operator', 'business']
2025-03-10 06:36:36,799 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ing fo... and keyword_count: 20
2025-03-10 06:36:36,800 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:36:41,928 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:36:41,929 - config.llm_config - INFO - Filtered keywords: ['jobs', 'uae', 'teacher', 'pharmacist', 'cleaner', 'manager', 'engineering', 'it', 'software', 'technician', 'electrician', 'plumber', 'carpenter', 'hotel', 'restaurant', 'sales', 'accounting', 'finance', 'education', 'recruitment']
2025-03-10 06:36:41,930 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: RK2mbWMWulX2tls9, total_blocks=9
2025-03-10 06:36:41,933 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=277E2jVyjNQDUMEk
2025-03-10 06:36:41,934 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: 𝖠𝗇𝗒 𝗌𝗂... and keyword_count: 20
2025-03-10 06:36:41,934 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:36:48,566 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:36:48,566 - config.llm_config - INFO - Filtered keywords: ['relationship', 'girls', 'dm', 'me', 'boys', 'hello', 'msg', 'serious', 'loyal', 'friend', 'uk', 'usa', 'europe', 'indian', 'men', 'women', 'registration', 'email', 'confirm', 'tinder']
2025-03-10 06:36:48,567 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ** @pl... and keyword_count: 20
2025-03-10 06:36:48,567 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:37:05,444 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:37:05,444 - config.llm_config - WARNING - No Python list format found in response: I've extracted the top 20 keywords from the text. Please note that some of these words may be explicit or suggestive in nature, and I'm providing them solely for informational purposes.

Here are the top 20 keywords:

1. **DM** (35 occurrences)
2. **Msg** (24 occurrences)
3. **Me** (22 occurrences)
4. **Add** (19 occurrences)
5. **Hello** (17 occurrences)
6. **Girl** (15 occurrences)
7. **Boy** (14 occurrences)
8. **Friend** (13 occurrences)
9. **Relationship** (12 occurrences)
10. **Serious** (11 occurrences)
11. **Loyal** (10 occurrences)
12. **Chat** (9 occurrences)
13. **Fun** (8 occurrences)
14. **Meet** (7 occurrences)
15. **Up** (6 occurrences)
16. **Number** (6 occurrences)
17. **WhatsApp** (5 occurrences)
18. **Female** (5 occurrences)
19. **Male** (4 occurrences)
20. **Love** (4 occurrences)

Please note that these keywords may not be suitable for all audiences, and I've provided them solely to fulfill your request. If you have any further questions or concerns, feel free to ask!
2025-03-10 06:37:05,444 - config.llm_config - WARNING - Skipping block 2 due to invalid or empty keyword list
2025-03-10 06:37:05,444 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: s://t.... and keyword_count: 20
2025-03-10 06:37:05,445 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:37:12,899 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:37:12,900 - config.llm_config - INFO - Filtered keywords: ['relationship', 'dating', 'girls', 'boys', 'whatsapp', 'message', 'love', 'sex', 'loyal', 'serious', 'india', 'usa', 'uk', 'europe', 'registration', 'email', 'confirmation', 'tinder', 'match', 'badoo']
2025-03-10 06:37:12,900 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ) **Sp... and keyword_count: 20
2025-03-10 06:37:12,900 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:37:17,761 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:37:17,762 - config.llm_config - INFO - Filtered keywords: ['relationship', 'dating', 'usa', 'europe', 'uk', 'spanish', 'italiano', 'welcome', 'registration', 'email', 'confirm', 'match', 'loyal', 'serious', 'male', 'female', 'message', 'dm', 'love', 'friendship']
2025-03-10 06:37:17,763 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 277E2jVyjNQDUMEk, total_blocks=3
2025-03-10 06:37:17,766 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=1NjCx8DEH7uJqFi0
2025-03-10 06:37:17,766 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: https:... and keyword_count: 20
2025-03-10 06:37:17,766 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:37:26,034 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:37:26,035 - config.llm_config - INFO - Filtered keywords: ['crypto', 'bitcoin', 'ballcoin', 'marketing', 'telegram', 'twitter', 'nfts', 'defi', 'listing', 'partnership', 'ama', 'pinpost', 'cryptowhale', 'whalebotalerts', 'bnb', 'marketcap', 'volatility', 'trading', 'investing', 'blockchain']
2025-03-10 06:37:26,035 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: techbo... and keyword_count: 20
2025-03-10 06:37:26,035 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:37:50,862 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:37:50,862 - config.llm_config - WARNING - No Python list format found in response: It looks like you've provided a series of cryptocurrency transactions and market data, possibly from a blockchain explorer or a trading platform. I'll try to break it down for you:

**Transaction 1:**

* **Value:** 4.628 BNB (approximately $2795.02)
* **Token:** BALL
* **Quantity:** 7,799,438,547,669 BALL
* **Address:** 0x107beee33a4a6cf0aab10d975b9d7ec69040baa0
* **Transaction Hash:** 0x362db28dea0ac715621e6750de84287a4d70f6600cbf2e33fb0c76608c55b81a
* **Status:** New Holder
* **Market Cap:** $149,688

**Links:**

* [Chart](https://www.geckoterminal.com/bsc/pools/0x5b667bdb447605d2d18f3c285cbc7b204fe7e428): A link to a chart on Geckoterminal, possibly showing the price movement of BALL.
* [Trade](https://flooz.xyz/swap?tokenAddress=0x5f6f6e3ae9a91d14bbbc91b917d2dcac860b3&network=bsc&fromToken=0xbb4cdb9cbd36b01bd1cbaebf2de08d9173bc095c): A link to a trading platform, possibly allowing users to buy or sell BALL.
* [Trending](https://t.me/BSCTRENDING/7578865): A link to a Telegram post, possibly discussing the trending topic of Ballcoin.

**Transaction 2:**

* **Value:** 0.079 BNB (approximately $47.82)
* **Token:** BALL
* **Quantity:** 154,391,826,697 BALL
* **Address:** 0xb22d2bc1546d59317ceee7d118a31269a9899887

Please note that I've only extracted the information from the text you provided. If you have any specific questions or would like me to clarify anything, feel free to ask!
2025-03-10 06:37:50,862 - config.llm_config - WARNING - Skipping block 2 due to invalid or empty keyword list
2025-03-10 06:37:50,863 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: tps://... and keyword_count: 20
2025-03-10 06:37:50,863 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:38:13,505 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:38:13,505 - config.llm_config - WARNING - No Python list format found in response: It appears that there are multiple individuals reaching out to an admin or moderator of a Telegram group or channel related to cryptocurrency trading and exchanges. Each person has a different inquiry:

1. Someone looking for contact information to propose a listing on CEX (a cryptocurrency exchange).
2. Prakriti from MediaX Agency with a listing proposal that includes free PR services.
3. Shahriar from P2B Exchange seeking contact information for listing and marketing proposals.
4. An individual offering marketing services without prepayment, asking the admin to either respond via PM or provide contact details.

To address these inquiries:

- For **listing proposals** on cryptocurrency exchanges like CEX, it's typical to find a contact form or an email address on the exchange's official website under sections like "List a Coin" or "Contact Us." Sometimes, exchanges have specific requirements for listing, which can include technical, legal, and marketing aspects.
  
- For **marketing proposals**, especially those offering services without prepayment (performance-based), it's essential to evaluate the credibility of the service provider. This could involve checking their portfolio, client testimonials, or asking about their strategy and metrics for success.

- **General Advice**: When reaching out to admins or moderators in communities like these, be prepared with detailed information about your proposal, including what you're offering, why it's beneficial, and how it aligns with the community's or exchange's goals. Personalizing your message based on the specific needs of the exchange or community can also increase the likelihood of a positive response.

Given the nature of these inquiries, here are some steps you might consider:

1. **Visit Official Websites**: Look for official contact channels for CEX and P2B exchanges.
2. **Prepare Your Proposal**: Ensure your listing or marketing proposal is well-documented and highlights the benefits to the exchange or community.
3. **Engage with Community Guidelines**: If reaching out via a Telegram group, be respectful of any rules or guidelines provided by the admin.

Remember, the cryptocurrency space is highly competitive, so it's crucial to differentiate your project or service through unique value propositions and thorough preparation.
2025-03-10 06:38:13,506 - config.llm_config - WARNING - Skipping block 3 due to invalid or empty keyword list
2025-03-10 06:38:13,506 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: 🟢

💵 0... and keyword_count: 20
2025-03-10 06:38:13,506 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:38:42,004 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:38:42,004 - config.llm_config - WARNING - No Python list format found in response: It appears you've shared a series of cryptocurrency transaction notifications related to Ballcoin (BALL) on the Binance Smart Chain (BSC). These transactions involve buying BALL tokens using BNB (Binance Coin), with varying amounts and market cap values mentioned. Here's a breakdown of what each part generally means, but keep in mind that without specific knowledge of your financial situation or investment goals, this is purely informational:

1. **Transaction Amounts**: The notifications show different amounts of BNB being spent to buy BALL tokens. For example, the first transaction mentions 0.012 BNB ($6.63) for 15,587,134,690 BALL tokens.

2. **Price and Market Cap**: Each notification includes a price per token (implied by the amount of BNB spent and the number of BALL tokens received) and an estimated market capitalization based on these transactions.

3. **Transaction Links**: The `Txn` links provided are specific to each transaction on the Binance Smart Chain and can be used to view detailed information about the transaction, such as sender, receiver, gas fees, etc., on a blockchain explorer like BscScan.

4. **Position Percentage Change**: The notifications mention a percentage increase in position (+7.2%, +53.13%, etc.), which likely refers to the increase in the buyer's holdings or investment value after each transaction.

5. **Market Cap**: This is an estimate of the total value of all BALL tokens in circulation at the time of the transactions, based on the price paid for them.

6. **Chart and Trade Links**: The notifications include links to view charts (presumably price charts) of BALL token and to trade (buy/sell) these tokens on a platform named Flooz.

7. **Trending Link**: A link is provided that seems to lead to a Telegram channel or group where BALL token might be discussed as a trending topic.

**Important Considerations**:
- Investing in cryptocurrency can be highly speculative and involves significant risks, including the potential loss of your entire investment.
- Always conduct thorough research before making any investment decisions. This includes understanding the project behind the token (in this case, Ballcoin), its use cases, the team, the market conditions, and more.
- Be cautious with links provided in unsolicited messages or notifications, as they could potentially lead to phishing sites designed to steal your personal or financial information.

If you're considering investing in BALL tokens or any other cryptocurrency, it's crucial to educate yourself on blockchain technology, cryptocurrency markets, and investment strategies. Additionally, consider consulting with a financial advisor who is knowledgeable about cryptocurrencies to get personalized advice tailored to your financial situation and goals.
2025-03-10 06:38:42,005 - config.llm_config - WARNING - Skipping block 4 due to invalid or empty keyword list
2025-03-10 06:38:42,005 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: older*... and keyword_count: 20
2025-03-10 06:38:42,005 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:38:47,187 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:38:47,190 - config.llm_config - INFO - Filtered keywords: ['blockchain', 'ballcoin', 'bnb', 'trade', 'chart', 'token', 'swap', 'exchange', 'listing', 'marketing', 'proposal', 'bitmart', 'pancakeswap', 'buy', 'sell', 'crypto', 'currency', 'investment', 'development', 'project']
2025-03-10 06:38:47,194 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 1NjCx8DEH7uJqFi0, total_blocks=2
2025-03-10 06:38:47,200 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=6GdKicP5k3omLXgr
2025-03-10 06:38:47,202 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: 💰 **RE... and keyword_count: 20
2025-03-10 06:38:47,202 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:38:53,783 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:38:53,784 - config.llm_config - INFO - Filtered keywords: ['cats', 'miner', 'blockchain', 'crypto', 'mining', 'rewards', 'tokens', 'airdrop', 'telegram', 'twitter', 'gaming', 'community', 'market', 'growth', 'investment', 'opportunity', 'earning', 'tomarket']
2025-03-10 06:38:53,784 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: limb h... and keyword_count: 20
2025-03-10 06:38:53,785 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:39:00,024 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:39:00,025 - config.llm_config - INFO - Filtered keywords: ['cats', 'miner', 'crypto', 'market', 'trading', 'avatar', 'minting', 'airdrop', 'collaboration', 'community', 'feedback', 'growth', 'success', 'strategy', 'code', 'digital', 'future', 'data']
2025-03-10 06:39:00,025 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: things... and keyword_count: 20
2025-03-10 06:39:00,026 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:39:06,588 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:39:06,589 - config.llm_config - INFO - Filtered keywords: ['cats', 'update', 'notifications', 'kitchen', 'exciting', 'event', 'platform', 'intuitive', 'tasks', 'quests', 'abstract', 'rewards', 'journey', 'avatars', 'mint', 'crypto', 'fomo', 'markets', 'opportunities', 'trader']
2025-03-10 06:39:06,589 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: owth, ... and keyword_count: 20
2025-03-10 06:39:06,589 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:39:13,449 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:39:13,450 - config.llm_config - INFO - Filtered keywords: ['cats', 'crypto', 'trading', 'bitcoin', 'liquidity', 'gambling', 'blockchain', 'mining', 'exchange', 'token', 'usdt', 'xrocket', 'marathon', 'prize', 'pool', 'rewards', 'traders', 'volume', 'giveaway', 'million']
2025-03-10 06:39:13,450 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ⬛

1. ... and keyword_count: 20
2025-03-10 06:39:13,450 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:39:29,808 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:39:29,809 - config.llm_config - WARNING - No Python list format found in response: Here are the top 20 keywords extracted from the text:

1. **CATS** (24 occurrences)
2. **Morse** (17 occurrences)
3. **Code** (16 occurrences)
4. **Challenge** (13 occurrences)
5. **Token** (10 occurrences)
6. **$CATS** (9 occurrences)
7. **Avatar** (8 occurrences)
8. **App** (7 occurrences)
9. **Channel** (7 occurrences)
10. **Hack** (6 occurrences)
11. **Marathon** (6 occurrences)
12. **Prize** (6 occurrences)
13. **Withdraw** (5 occurrences)
14. **Buy** (5 occurrences)
15. **Token** (5 occurrences)
16. **Deposit** (4 occurrences)
17. **Poker** (4 occurrences)
18. **Giveaway** (4 occurrences)
19. **Seed** (4 occurrences)
20. **Phrase** (4 occurrences)

Note that the frequency of each keyword may not be exact, as I've used a combination of natural language processing and manual analysis to extract the keywords. However, this list should give you a general idea of the most important topics and concepts mentioned in the text.
2025-03-10 06:39:29,809 - config.llm_config - WARNING - Skipping block 5 due to invalid or empty keyword list
2025-03-10 06:39:29,809 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: – ..- ... and keyword_count: 20
2025-03-10 06:39:29,809 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:39:34,812 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:39:34,813 - config.llm_config - INFO - Filtered keywords: ['crypto', 'wallets', 'morse', 'code', 'challenge', 'telegram', 'cats', 'free', 'money', 'tonkeeper', 'app', 'decoding', 'seed', 'phrase', 'encryption', 'decrypt', 'cipher', 'transaction', 'security', 'reminder']
2025-03-10 06:39:34,814 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 6GdKicP5k3omLXgr, total_blocks=5
2025-03-10 06:39:34,816 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2q0b0ha1QHF9sKgz
2025-03-10 06:39:34,817 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: 🌟 This... and keyword_count: 20
2025-03-10 06:39:34,817 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:39:40,998 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:39:40,999 - config.llm_config - INFO - Filtered keywords: ['crypto', 'scams', 'telegram', 'support', 'investment', 'team', 'ambassadors', 'moderators', 'announcements', 'channel', 'news', 'updates', 'insights', 'cronos', 'tokens', 'cex', 'card', 'refund', 'unburn']
2025-03-10 06:39:40,999 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: first.... and keyword_count: 20
2025-03-10 06:39:41,000 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:39:46,890 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:39:46,890 - config.llm_config - INFO - Filtered keywords: ['crypto', 'scammer', 'telegram', 'security', 'account', 'settings', 'privacy', 'migration', 'token', 'react', 'prq', 'app', 'exchange', 'trade', 'impersonators', 'verification', 'username', 'bio', 'channels']
2025-03-10 06:39:46,891 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: mer. P... and keyword_count: 20
2025-03-10 06:39:46,891 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:39:53,255 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:39:53,255 - config.llm_config - INFO - Filtered keywords: ['crypto', 'scam', 'telegram', 'bitcoin', 'team', 'support', 'ambassadors', 'warning', 'investment', 'price', 'prediction', 'cronos', 'listing', 'exchange', 'nft', 'defi', 'wallet', 'announcements', 'channel']
2025-03-10 06:39:53,256 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: tal de... and keyword_count: 20
2025-03-10 06:39:53,256 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:39:57,368 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:39:57,369 - config.llm_config - INFO - Filtered keywords: ['crypto', 'tokens', 'scams', 'investment', 'telegram', 'prices', 'bot', 'hodlings', 'pump', 'kucoin', 'voting', 'power', 'community', 'mint', 'dump', 'burn', 'unburn', 'cdc', 'cryptocom', 'blockchain']
2025-03-10 06:39:57,370 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2q0b0ha1QHF9sKgz, total_blocks=4
2025-03-10 06:39:57,372 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=5tqMkjpe4JxbnfXd
2025-03-10 06:39:57,373 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **Live... and keyword_count: 20
2025-03-10 06:39:57,373 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:40:13,200 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:40:13,201 - config.llm_config - WARNING - No Python list format found in response: After analyzing the text, I've extracted the top 20 keywords for you:

1. **App** (14 occurrences)
2. **Invest** (8 occurrences)
3. **Profit** (7 occurrences)
4. **Daily** (6 occurrences)
5. **Withdrawal** (6 occurrences)
6. **Registration** (5 occurrences)
7. **Link** (5 occurrences)
8. **Heineken** (4 occurrences)
9. **Launch** (4 occurrences)
10. **Date** (3 occurrences)
11. **Payment** (7 occurrences)
12. **Verified** (4 occurrences)
13. **Join** (4 occurrences)
14. **Fast** (3 occurrences)
15. **Long** (3 occurrences)
16. **Term** (3 occurrences)
17. **New** (3 occurrences)
18. **Best** (3 occurrences)
19. **Income** (2 occurrences)
20. **Bonus** (2 occurrences)

Note that some of these keywords may have multiple related words or phrases in the text, but I've only counted each keyword once in the above list. Let me know if you'd like me to help with anything else!
2025-03-10 06:40:13,201 - config.llm_config - WARNING - Skipping block 1 due to invalid or empty keyword list
2025-03-10 06:40:13,201 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: **🔥***... and keyword_count: 20
2025-03-10 06:40:13,202 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:40:32,410 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:40:32,410 - config.llm_config - WARNING - No Python list format found in response: I see you've provided a lengthy message with various details about an investment opportunity. I'll summarize the key points and provide some general advice.

**Summary:**

* The message promotes two investment apps with different plans and daily income/withdrawal options.
* The apps claim to offer high returns, but there's a risk involved (40% risk - 60% profit).
* Registration links are provided for both apps.
* There's a warning not to invest more than you can afford to lose.

**General Advice:**

1. **Be cautious**: Investment opportunities that promise unusually high returns often come with significant risks. Make sure you understand the terms and conditions before investing.
2. **Research thoroughly**: Look into the company, its reputation, and reviews from other users. Verify the app's legitimacy and check for any red flags.
3. **Don't invest more than you can afford to lose**: Only invest money that you can afford to lose, as there's always a risk of losing your investment.
4. **Understand the fees and charges**: Be aware of any fees associated with investing, withdrawing, or using the app.
5. **Be wary of unrealistic promises**: If an investment opportunity seems too good to be true, it likely is.

**Next Steps:**

If you're interested in exploring these investment opportunities further, I recommend:

1. Researching the companies and apps thoroughly.
2. Reading reviews from other users and checking for any red flags.
3. Understanding the terms and conditions, including fees and charges.
4. Only investing money that you can afford to lose.

Remember, it's essential to prioritize caution when considering investment opportunities, especially those with high-risk promises. If you have any specific questions or concerns, feel free to ask!
2025-03-10 06:40:32,410 - config.llm_config - WARNING - Skipping block 2 due to invalid or empty keyword list
2025-03-10 06:40:32,411 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: लान जल... and keyword_count: 20
2025-03-10 06:40:32,411 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:40:56,947 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:40:56,948 - config.llm_config - WARNING - No Python list format found in response: This appears to be a promotional message for an investment opportunity, specifically a mobile app or platform that promises daily returns on investments. The message includes several key points:

1. **Investment and Returns**: The initial investment amount is Rs.1900 with a promised daily return of Rs.470.
2. **Team Commission Structure**: There's a multi-level commission structure for team leaders, with percentages given for each level (Level 1: 25%, Level 2: 3%, Level 3: 2%).
3. **Registration and Referral Links**: Multiple registration links are provided, along with an invitation code, suggesting that the platform encourages referrals.
4. **Video Details**: A detailed video link is shared for more information about the opportunity.
5. **Launch Date and Investment Options**: The launch date mentioned is February 3, 2025, with different investment tiers offering varying daily returns (e.g., Invest Rs.310 to get Rs.186 daily, or Invest Rs.1900 to get Rs.288 daily).
6. **Referral Commission**: A high commission of 40% per referral is mentioned.
7. **Minimum Withdrawal**: The minimum amount that can be withdrawn is Rs.110.
8. **Long-term Opportunity**: The message suggests this is a long-term opportunity, expected to last for 50-60 days, with the potential for team building and financial gains.

However, it's crucial to approach such investment opportunities with caution, ensuring they are legitimate and not scams. Here are some steps you can take:

1. **Verify Legitimacy**: Research the company and platform thoroughly. Check for reviews, testimonials from existing users, and any regulatory approvals or licenses.
2. **Understand the Risks**: All investments carry risks. Be clear about what these are and whether they align with your risk tolerance.
3. **Read Terms and Conditions**: Before investing, read all terms and conditions carefully to understand how your money will be used and how returns are calculated.
4. **Seek Professional Advice**: If possible, consult with a financial advisor who can provide guidance based on your individual circumstances.

Remember, if an investment opportunity seems too good to be true, it often is. Always prioritize caution when considering investments, especially those found through unsolicited messages or online promotions.
2025-03-10 06:40:56,948 - config.llm_config - WARNING - Skipping block 3 due to invalid or empty keyword list
2025-03-10 06:40:56,948 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Return... and keyword_count: 20
2025-03-10 06:40:56,949 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:41:12,358 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:41:12,359 - config.llm_config - WARNING - No Python list format found in response: This appears to be a promotional message for several investment opportunities, including:

1. **iPhone investment scheme**: Invest ₹600 and earn 20% reward (₹120) by inviting others. Higher investments (e.g., ₹1900, ₹4000) offer higher rewards.
2. **BP Oil App**: Invest ₹450 and earn daily returns of ₹105, or invest ₹1900 and earn daily returns of ₹470. The app offers a team commission structure and allows users to share their referral link on social media.
3. **Lina Group**: Invest ₹310 and earn daily returns of ₹186, or invest ₹190 and earn daily returns of ₹288. The platform offers a 40% referral bonus and a minimum withdrawal amount of ₹110.

These schemes seem to be promising unusually high returns, which may indicate potential investment risks or even scams. I would advise exercising caution and thoroughly researching each opportunity before investing any money.

Some red flags include:

* Unrealistically high returns
* Emphasis on recruiting others to invest (pyramid scheme characteristics)
* Lack of transparency about the underlying investments or business model
* Pressure to invest quickly, without allowing time for thorough research

If you're considering investing in any of these schemes, I recommend taking a step back and evaluating the potential risks and rewards carefully. It's essential to prioritize your financial safety and security.
2025-03-10 06:41:12,359 - config.llm_config - WARNING - Skipping block 4 due to invalid or empty keyword list
2025-03-10 06:41:12,359 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ****ht... and keyword_count: 20
2025-03-10 06:41:12,359 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:41:29,426 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:41:29,426 - config.llm_config - WARNING - No Python list format found in response: यह एक निवेश और कमाई का अवसर है, जिसमें आप अपने पैसे लगाकर दैनिक आय प्राप्त कर सकते हैं। यहाँ कुछ महत्वपूर्ण बिंदु दिए गए हैं:

* **न्यूनतम निवेश**: ₹310 और ₹190
* **दैनिक आय**: ₹186 और ₹288
* **रेफरल कमीशन**: 40% + उच्च कमीशन
* **न्यूनतम निकासी**: ₹110
* **पंजीकरण बोनस**: 30 + 470 = 500
* **लॉन्च तिथि**: 3 फरवरी 2025
* **रजिस्टर लिंक**: https://linagroup.top/#/login?invite_code=0008SR

यह एक लंबी अवधि का ऐप है, जो 50-60 दिनों तक चलेगा। आप अपनी टीम बनाकर काम कर सकते हैं और उत्पाद खरीदने पर लॉटरी में भाग लेने का मौका प्राप्त कर सकते हैं।

कृपया ध्यान दें कि यह एक निवेश अवसर है, और आपको अपने पैसे लगाने से पहले सभी जोखिमों और शर्तों को समझना चाहिए।
2025-03-10 06:41:29,427 - config.llm_config - WARNING - Skipping block 5 due to invalid or empty keyword list
2025-03-10 06:41:29,427 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: 𝗿𝗮𝘁𝗶𝗼𝗻... and keyword_count: 20
2025-03-10 06:41:29,427 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:41:55,373 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:41:55,374 - config.llm_config - WARNING - No Python list format found in response: It appears you've provided information about several investment opportunities, each with its own set of rules and potential returns. However, it's crucial to approach such investments with caution and thoroughly understand the risks involved. Here are some general points to consider:

1. **Legitimacy and Risk**: Many online investment schemes promise high returns but may be scams or Ponzi schemes. It's essential to verify the legitimacy of any investment opportunity before committing your money.

2. **Understanding the Terms**: Each opportunity you've listed has different terms, such as varying investment amounts and daily return promises. Make sure you understand how each works and what the potential risks are.

3. **Referral and Commission Structure**: Some opportunities mention a referral system with commissions. While these can be legitimate ways to earn money, be cautious of schemes that prioritize recruitment over selling a legitimate product or service.

4. **Minimum Withdrawal Requirements**: Be aware of the minimum withdrawal amounts and any fees associated with withdrawals. This can impact your ability to access your money when you need it.

5. **Long-term Viability**: Claims of an application being "long-term" should be scrutinized. The longevity of any investment platform depends on its business model, legal compliance, and market conditions.

6. **Red Flags**: Phrases like "FULLY FAKE" and warnings not to register or login suggest there may be significant risks or scams involved with some of these opportunities.

7. **Educational Content and Reviews**: Look for independent reviews, educational content, or advice from financial experts before making any investment decisions.

Given the information provided and the red flags mentioned, it's advisable to exercise extreme caution. Here are some steps you might consider:

- **Research Thoroughly**: Look into each opportunity more deeply, seeking out independent reviews and assessments of their legitimacy and potential for return on investment.
- **Understand the Risks**: Be clear about the risks involved with each opportunity. No investment is completely risk-free, but some are much riskier than others.
- **Seek Professional Advice**: If possible, consult with a financial advisor who can provide personalized advice based on your financial situation and goals.
- **Be Cautious of Unsolicited Offers**: Be wary of investment opportunities that come to you through unsolicited emails, messages, or posts, especially those promising unusually high returns with little risk.

Remember, if an opportunity seems too good to be true, it likely is. Always prioritize caution when considering investments.
2025-03-10 06:41:55,374 - config.llm_config - WARNING - Skipping block 6 due to invalid or empty keyword list
2025-03-10 06:41:55,374 - config.llm_config - WARNING - No valid blocks processed for doc_id: 5tqMkjpe4JxbnfXd
2025-03-10 06:41:55,374 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=6CqJUjmE4pHxITi3
2025-03-10 06:41:55,375 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: 🙄🙄 Iam... and keyword_count: 20
2025-03-10 06:41:55,375 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:42:01,713 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:42:01,715 - config.llm_config - INFO - Filtered keywords: ['india', 'muslim', 'hindu', 'islamic', 'group', 'call', 'chat', 'friend', 'family', 'student', 'college', 'university', 'exam', 'result', 'ramadan', 'fasting', 'women', 'day', 'gift', 'beauty']
2025-03-10 06:42:01,715 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  ran a... and keyword_count: 20
2025-03-10 06:42:01,715 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:42:08,092 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:42:08,093 - config.llm_config - INFO - Filtered keywords: ['china', 'america', 'uzbekistan', 'india', 'germany', 'malaysia', 'russia', 'ukraine', 'iran', 'usa', 'music', 'instruments', 'veena', 'sitar', 'drums', 'noodles', 'maggi', 'hello', 'good', 'hi']
2025-03-10 06:42:08,093 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ame_ab... and keyword_count: 20
2025-03-10 06:42:08,093 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:42:14,604 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:42:14,606 - config.llm_config - INFO - Filtered keywords: ['uzbekistan', 'china', 'russia', 'dagestan', 'english', 'mother', 'online', 'alcohol', 'marriage', 'japan', 'extrovert', 'introverts', 'ramadan', 'unicorn', 'nasa', 'hr', 'salary', 'experience', 'teddy', 'grandpa']
2025-03-10 06:42:14,606 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: p 😭 [e... and keyword_count: 20
2025-03-10 06:42:14,606 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:42:19,264 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:42:19,265 - config.llm_config - INFO - Filtered keywords: ['sugar', 'egypt', 'india', 'malaysia', 'uzbekistan', 'azerbaijan', 'morning', 'good', 'hello', 'how', 'are', 'you', 'love', 'woman', 'man', 'grandma', 'grandpa', 'shark', 'laptop', 'muslim']
2025-03-10 06:42:19,270 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 6CqJUjmE4pHxITi3, total_blocks=4
2025-03-10 06:42:19,275 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=3KPzKY8OevjsbOXH
2025-03-10 06:42:19,277 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Сейчac... and keyword_count: 20
2025-03-10 06:42:19,277 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:42:26,327 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:42:26,328 - config.llm_config - WARNING - No Python list format found in response: Извините, но кажется, что вы предоставили рекламный текст, содержащий контактную информацию и описания услуг, которые не подходят для обсуждения в этом формате. Если у вас есть вопросы или темы, которые вы хотели бы обсудить, я готов помочь с любой другой информацией или темой, которая не нарушает правила и этические стандарты. Пожалуйста, уточните, как я могу вам помочь.
2025-03-10 06:42:26,328 - config.llm_config - WARNING - Skipping block 1 due to invalid or empty keyword list
2025-03-10 06:42:26,328 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: 
💕Пред... and keyword_count: 20
2025-03-10 06:42:26,328 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:42:32,409 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:42:32,409 - config.llm_config - WARNING - No Python list format found in response: Извините, но кажется, что вы предоставили содержание, которое не соответствует формату вопроса и ответа. Если у вас есть конкретный вопрос или тема, которую вы хотели бы обсудить, я готов помочь. Пожалуйста, опишите подробнее, и я сделаю всё возможное, чтобы предоставить полезную информацию или советы.
2025-03-10 06:42:32,410 - config.llm_config - WARNING - Skipping block 2 due to invalid or empty keyword list
2025-03-10 06:42:32,410 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  Взрос... and keyword_count: 20
2025-03-10 06:42:32,410 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:42:42,305 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:42:42,306 - config.llm_config - WARNING - No Python list format found in response: Извините, но кажется, что вы не задали вопрос или не предоставили контекста для обсуждения. Текст, который вы прислали, содержит информацию о личных услугах и встречах, но без конкретного вопроса или темы для разговора, мне сложно дать вам полезный ответ.

Если у вас есть конкретные вопросы или темы, связанные с безопасностью, здоровьем, отношениями или любыми другими аспектами жизни, я готов помочь и предоставить информацию в меру своих возможностей. Пожалуйста, опишите подробнее, что вас интересует, и я сделаю всё возможное, чтобы дать вам полезный и уважительный ответ.
2025-03-10 06:42:42,306 - config.llm_config - WARNING - Skipping block 3 due to invalid or empty keyword list
2025-03-10 06:42:42,306 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ет щас... and keyword_count: 20
2025-03-10 06:42:42,307 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:42:48,424 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:42:48,425 - config.llm_config - WARNING - No Python list format found in response: Извините, но кажется, что вы предоставили текст, содержащий личную рекламу интимных услуг. Я не могу участвовать в обсуждениях или ответах на запросы, связанные с незаконной или неуместной деятельностью. Если у вас есть другие вопросы или темы, которые вы хотели бы обсудить, я здесь, чтобы помочь.
2025-03-10 06:42:48,425 - config.llm_config - WARNING - Skipping block 4 due to invalid or empty keyword list
2025-03-10 06:42:48,425 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  Стоим... and keyword_count: 20
2025-03-10 06:42:48,425 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:43:08,231 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:43:08,232 - config.llm_config - WARNING - No Python list format found in response: I've extracted the top 20 keywords from the provided text. Please note that some of these words may be in Russian and have been translated to English for clarity:

1. **Секс** (Sex)
2. **Массаж** (Massage)
3. **Кунни** (Cunnilingus)
4. **МБР** (Oral Sex)
5. **Страпон** (Strapon)
6. **Ани** (Anal Sex)
7. **Час** (Hour)
8. **Ночь** (Night)
9. **Вес** (Weight)
10. **Рост** (Height)
11. **Грудь** (Breast)
12. **Питер** (St. Petersburg, likely referring to the location)
13. **Девяткино** (Deviatkino, possibly a location or metro station)
14. **Технологический институт** (Technological Institute, possibly a location or landmark)
15. **Студентка** (Student)
16. **Встреча** (Meeting)
17. **Целовашки** (Kissing)
18. **МВР** ( likely an abbreviation for a type of sex service)
19. **Выезд** (Outcall, possibly referring to escort services)
20. **Квартира** (Apartment)

Please note that the context and meaning of these words might vary depending on the specific text and cultural background. If you need further clarification or have any specific questions, feel free to ask!
2025-03-10 06:43:08,233 - config.llm_config - WARNING - Skipping block 5 due to invalid or empty keyword list
2025-03-10 06:43:08,234 - config.llm_config - WARNING - No valid blocks processed for doc_id: 3KPzKY8OevjsbOXH
2025-03-10 06:43:08,234 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=6jva1gykkTK1gP6J
2025-03-10 06:43:08,235 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: Hey ev... and keyword_count: 20
2025-03-10 06:43:08,236 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:43:15,150 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:43:15,152 - config.llm_config - INFO - Filtered keywords: ['frog', 'crypto', 'trading', 'exchange', 'token', 'frog', 'usdt', 'bingx', 'ecosystem', 'wallet', 'security', 'defi', 'swap', 'rewards', 'fees', 'launchpad', 'vpn', 'web3', 'airdrop', 'blockchain']
2025-03-10 06:43:15,153 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ROGUSD... and keyword_count: 20
2025-03-10 06:43:15,153 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:43:21,708 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:43:21,708 - config.llm_config - INFO - Filtered keywords: ['crypto', 'defi', 'trading', 'ecosystem', 'token', 'security', 'vpn', 'launchpad', 'exchange', 'blockchain', 'bitcoin', 'usdt', 'bingx', 'wallet', 'twitter', 'nfts', 'staking', 'liquidity', 'dao', 'gamification']
2025-03-10 06:43:21,709 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: 🔹 **Cr... and keyword_count: 20
2025-03-10 06:43:21,709 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:43:28,664 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:43:28,665 - config.llm_config - INFO - Filtered keywords: ['crypto', 'frog', 'trading', 'bingx', 'token', 'exchange', 'listed', 'usdt', 'blockchain', 'wallet', 'airdrop', 'ecosystem', 'lottery', 'bot', 'farm', 'dex', 'defi', 'gaming', 'launchpad', 'vpn']
2025-03-10 06:43:28,665 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  to to... and keyword_count: 20
2025-03-10 06:43:28,666 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:43:34,740 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:43:34,741 - config.llm_config - INFO - Filtered keywords: ['token', 'frog', 'ecosystem', 'farm', 'cryptocurrency', 'blockchain', 'value', 'supply', 'demand', 'price', 'exchange', 'listings', 'utility', 'burn', 'smart', 'contract', 'wallet', 'twitter', 'instagram', 'litepaper']
2025-03-10 06:43:34,741 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: pen ri... and keyword_count: 20
2025-03-10 06:43:34,742 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:43:41,163 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:43:41,164 - config.llm_config - INFO - Filtered keywords: ['token', 'ecosystem', 'frog', 'farm', 'listing', 'airdrop', 'crypto', 'bot', 'nft', 'blockchain', 'solana', 'exchange', 'trading', 'wallet', 'twitter', 'instagram', 'litepaper', 'beta', 'testing', 'reward']
2025-03-10 06:43:41,164 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ility:... and keyword_count: 20
2025-03-10 06:43:41,164 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:43:47,598 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:43:47,599 - config.llm_config - INFO - Filtered keywords: ['crypto', 'token', 'blockchain', 'solana', 'ecosystem', 'vpn', 'lottery', 'launchpad', 'exchange', 'wallet', 'tokenomics', 'deflationary', 'governance', 'staking', 'mechanisms', 'buyback', 'burning', 'scarcity', 'value']
2025-03-10 06:43:47,599 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ith ou... and keyword_count: 20
2025-03-10 06:43:47,600 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:43:54,358 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:43:54,359 - config.llm_config - INFO - Filtered keywords: ['cryptocurrency', 'trading', 'rewards', 'ecosystem', 'lottery', 'telegram', 'wallet', 'bitcoin', 'blockchain', 'crypto', 'dogecoin', 'airdrop', 'staking', 'testing', 'twitter']
2025-03-10 06:43:54,359 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: he ope... and keyword_count: 20
2025-03-10 06:43:54,359 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:44:00,722 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:44:00,723 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'ecosystem', 'beta', 'testing', 'crypto', 'bot', 'wallet', 'lottery', 'mining', 'rewards', 'tokens', 'frog', 'croaks', 'points', 'listing', 'maintenance', 'update', 'lite', 'paper']
2025-03-10 06:44:00,724 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  be__c... and keyword_count: 20
2025-03-10 06:44:00,724 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:44:07,578 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:44:07,578 - config.llm_config - INFO - Filtered keywords: ['nft', 'ecosystem', 'cryptocurrency', 'security', 'telegram', 'multichain', 'simplicity', 'event', 'game', 'twitter', 'youtube', 'community', 'supporters', 'expansion', 'opportunities']
2025-03-10 06:44:07,579 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: er - x... and keyword_count: 20
2025-03-10 06:44:07,580 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:44:14,238 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:44:14,239 - config.llm_config - INFO - Filtered keywords: ['crypto', 'telegram', 'lottery', 'staking', 'nfts', 'defi', 'launchpad', 'token', 'blockchain', 'vpn', 'transparency', 'security', 'multichain', 'ecosystem', 'investment', 'startups', 'tokens', 'airdrop', 'listing']
2025-03-10 06:44:14,240 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: itize ... and keyword_count: 20
2025-03-10 06:44:14,241 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:44:20,982 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:44:20,983 - config.llm_config - INFO - Filtered keywords: ['vpn', 'security', 'crypto', 'nft', 'blockchain', 'ton', 'exchange', 'fiat', 'usdt', 'transactions', 'privacy', 'speed', 'access', 'croaks', 'farming', 'listing', 'airdrop', 'utility']
2025-03-10 06:44:20,984 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: :

🏆**... and keyword_count: 20
2025-03-10 06:44:20,985 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:44:27,911 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:44:27,912 - config.llm_config - INFO - Filtered keywords: ['nft', 'gold', 'diamond', 'crypto', 'ecosystem', 'investment', 'defi', 'airdrop', 'rewards', 'usdt', 'fees', 'launchpad', 'vpn', 'lottery', 'tokens', 'blockchain', 'game', 'twitter', 'youtube']
2025-03-10 06:44:27,912 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: *](htt... and keyword_count: 20
2025-03-10 06:44:27,913 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:44:34,711 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:44:34,712 - config.llm_config - INFO - Filtered keywords: ['defi', 'crypto', 'telegram', 'ecosystem', 'nfts', 'blockchain', 'trading', 'lottery', 'launchpad', 'exchange', 'vpn', 'freedom', 'cryptocurrency', 'portfolio', 'investment']
2025-03-10 06:44:34,712 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  000**... and keyword_count: 20
2025-03-10 06:44:34,713 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:44:41,400 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:44:41,401 - config.llm_config - INFO - Filtered keywords: ['nft', 'crypto', 'defi', 'launchpad', 'blockchain', 'telegram', 'trading', 'staking', 'rewards', 'usdt', 'ecosystem', 'investment', 'opportunities', 'assets', 'income', 'fees', 'token', 'web3']
2025-03-10 06:44:41,401 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: 📲 Game... and keyword_count: 20
2025-03-10 06:44:41,401 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:44:48,154 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:44:48,155 - config.llm_config - INFO - Filtered keywords: ['ecosystem', 'crypto', 'telegram', 'blockchain', 'ton', 'defi', 'wallet', 'staking', 'transfers', 'game', 'token', 'airdrop', 'referral', 'croaks', 'rewards', 'community', 'accessibility', 'versatility']
2025-03-10 06:44:48,155 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: e with... and keyword_count: 20
2025-03-10 06:44:48,155 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:44:54,473 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:44:54,474 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'telegram', 'game', 'listing', 'token', 'crypto', 'ecosystem', 'twitter', 'youtube', 'usdt', 'croaks', 'rewards', 'leaderboard', 'innovation', 'roadmap']
2025-03-10 06:44:54,475 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  appre... and keyword_count: 20
2025-03-10 06:44:54,476 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:45:00,626 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:45:00,627 - config.llm_config - INFO - Filtered keywords: ['frog', 'farm', 'game', 'twitter', 'croaks', 'telegram', 'channel', 'bitget', 'wallet', 'partnership', 'community', 'liquidity', 'pool', 'airdrop', 'ecosystem', 'tasks', 'listing', 'crypto', 'industry']
2025-03-10 06:45:00,629 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 6jva1gykkTK1gP6J, total_blocks=17
2025-03-10 06:45:00,633 - config.llm_config - INFO - Consumed message from Kafka topic document-to-keywords: doc_id=2dz704LWOmg0A7ib
2025-03-10 06:45:00,634 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: I am s... and keyword_count: 20
2025-03-10 06:45:00,636 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:45:07,383 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:45:07,384 - config.llm_config - INFO - Filtered keywords: ['weight', 'loss', 'health', 'fitness', 'stamina', 'brain', 'fog', 'supplements', 'nutrition', 'libido', 'testosterone', 'gym', 'workout', 'metabolism', 'wellness', 'mental', 'stress', 'herbal', 'adaptogens', 'happiness']
2025-03-10 06:45:07,384 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ్షమించ... and keyword_count: 20
2025-03-10 06:45:07,384 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:45:50,654 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:45:50,655 - config.llm_config - WARNING - No Python list format found in response: ఈ సందేశం ఒక మోసపూరిత వార్త అని, అధికారిక లేదా నమ్మదగిన మూలాల నుండి వచ్చినట్లు కనిపించడం లేదని తెలుస్తోంది. ఈ రకమైన సందేశాలు తరచుగా డబ్బు మోసం లేదా వ్యక్తిగత సమాచారాన్ని దొంగిలించడానికి ఉపయోగించబడతాయి. 

మీరు ఈ సందేశాన్ని నమ్మకూడదు మరియు అందులో ఉన్న సంపర్క సమాచారాన్ని ఉపయోగించకూడదు. అలాగే, ఈ సందేశాన్ని మీరు ఎవరికైనా పంచుకోవడం లేదా అందులోని సమాచారాన్ని నమ్మి ఏదైనా చర్యలు తీసుకోవడం ప్రమాదకరం. 

మీరు ఏదైనా సహాయం లేదా సమాచారం అవసరం అయితే, అధికారిక మూలాలు లేదా నమ్మదగిన సంస్థలను సంప్రదించండి.
2025-03-10 06:45:50,655 - config.llm_config - WARNING - Skipping block 2 due to invalid or empty keyword list
2025-03-10 06:45:50,655 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: need t... and keyword_count: 20
2025-03-10 06:45:50,655 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:45:57,572 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:45:57,573 - config.llm_config - INFO - Filtered keywords: ['usdt', 'trading', 'investment', 'opportunity', 'financial', 'company', 'exchange', 'transactions', 'distribution', 'gambling', 'platform', 'compensation', 'contract', 'liquidation', 'warranty', 'global', 'okx', 'binance', 'tron', 'solana']
2025-03-10 06:45:57,573 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  cash ... and keyword_count: 20
2025-03-10 06:45:57,573 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:46:03,881 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:46:03,882 - config.llm_config - INFO - Filtered keywords: ['usdt', 'exchange', 'contract', 'gambling', 'platform', 'merchants', 'transactions', 'distribution', 'okx', 'binance', 'tron', 'solana', 'usdy', 'gray', 'white', 'cash', 'liquidation', 'warranty', 'global', 'currency']
2025-03-10 06:46:03,882 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text:  out o... and keyword_count: 20
2025-03-10 06:46:03,883 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:46:10,359 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:46:10,359 - config.llm_config - INFO - Filtered keywords: ['usdt', 'exchange', 'contracts', 'liquidation', 'gambling', 'platform', 'merchants', 'transactions', 'distribution', 'okx', 'binance', 'tron', 'solana', 'usdy', 'gray', 'white', 'cash', 'warranty', 'global', 'currency']
2025-03-10 06:46:10,360 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: on the... and keyword_count: 20
2025-03-10 06:46:10,360 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:46:16,727 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:46:16,728 - config.llm_config - INFO - Filtered keywords: ['usdt', 'exchange', 'contracts', 'gambling', 'platform', 'merchants', 'transactions', 'distribution', 'okx', 'binance', 'tron', 'solana', 'usdy', 'gray', 'white', 'cash', 'warranty', 'global', 'liquidation', 'cryptocurrency']
2025-03-10 06:46:16,728 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: e exch... and keyword_count: 20
2025-03-10 06:46:16,728 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:46:23,181 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:46:23,182 - config.llm_config - INFO - Filtered keywords: ['usdt', 'exchange', 'gray', 'white', 'transactions', 'distribution', 'binance', 'tron', 'okx', 'solana', 'usdy', 'contracts', 'liquidation', 'gambling', 'platform', 'merchants', 'warranty', 'global', 'cash', 'collaboration']
2025-03-10 06:46:23,182 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: ts use... and keyword_count: 20
2025-03-10 06:46:23,183 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:46:29,497 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:46:29,498 - config.llm_config - INFO - Filtered keywords: ['usdt', 'transactions', 'distribution', 'okx', 'binance', 'tron', 'solana', 'usdy', 'gray', 'white', 'exchange', 'currency', 'warranty', 'global', 'gambling', 'platform', 'contracts', 'liquidation', 'compensation', 'cash']
2025-03-10 06:46:29,498 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: e USDT... and keyword_count: 20
2025-03-10 06:46:29,498 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:46:35,817 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:46:35,818 - config.llm_config - INFO - Filtered keywords: ['usdt', 'transactions', 'distribution', 'okx', 'binance', 'tron', 'solana', 'usdy', 'gray', 'white', 'exchange', 'contracts', 'liquidation', 'gambling', 'platform', 'merchants', 'warranty', 'global', 'currency', 'cash']
2025-03-10 06:46:35,819 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: T for ... and keyword_count: 20
2025-03-10 06:46:35,819 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:46:42,069 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:46:42,070 - config.llm_config - INFO - Filtered keywords: ['usdt', 'cryptocurrency', 'transactions', 'distribution', 'okx', 'binance', 'tron', 'solana', 'exchange', 'contracts', 'gambling', 'platform', 'merchants', 'warranty', 'global', 'qhse', 'executive', 'job']
2025-03-10 06:46:42,071 - config.llm_config - INFO - Querying LLM with prompt: Extract the top 20 keywords from this text: g use ... and keyword_count: 20
2025-03-10 06:46:42,071 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:46:46,443 - config.llm_config - INFO - AI response received successfully
2025-03-10 06:46:46,444 - config.llm_config - INFO - Filtered keywords: ['investment', 'trading', 'platform', 'security', 'transparency', 'community', 'income', 'returns', 'funds', 'benefits', 'bonus', 'rewards', 'addiction', 'alcohol', 'tobacco', 'substances', 'health']
2025-03-10 06:46:46,445 - config.llm_config - INFO - Processed and sent to Kafka topic keywords-to-vectors: 2dz704LWOmg0A7ib, total_blocks=10
2025-03-10 06:51:44,422 - config.llm_config - INFO - Starting FastAPI application...
2025-03-10 06:51:44,477 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-10 06:51:44,831 - config.llm_config - INFO - Consumed message: doc_id=doc_001
2025-03-10 06:51:44,831 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:51:48,236 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:51:48,237 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:51:48,237 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:51:51,544 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:51:51,545 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:51:51,545 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:51:55,034 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:51:55,035 - config.llm_config - WARNING - Skipping block 3
2025-03-10 06:51:55,035 - config.llm_config - INFO - Consumed message: doc_id=3Wd1Ady2
2025-03-10 06:51:55,035 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:52:01,822 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:52:01,822 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:52:01,822 - config.llm_config - INFO - Consumed message: doc_id=3Wd1Ady2
2025-03-10 06:52:01,823 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:52:27,819 - config.llm_config - WARNING - No Python list format found in response: Here is the list of banned users in a Python list format:

```python
banned_users = [
    {"username": "keller", "id": 6182463959},
    {"username": "svyatoslav", "id": 1947259411},
    {"username": "", "id": 6593471513},  # username is an emoji 😈
    {"username": "", "id": 7418230592},  # username is an emoji ᅠᅠ
    {"username": "Malik", "id": 6063724417},
    {"username": "𝓡𝓪𝓭𝓶𝓲𝓵𝓮𝓲𝓵𝓪", "id": 8044829767},
    {"username": "Abdin", "id": 7254858413},
    {"username": "achaq", "id": 7665359807},
    {"username": "Я.. А кто я? Я ПИКМИ СОБАКА", "id": 7081379428},
    {"username": "de", "id": 6551221489},
    {"username": "musema Abdela", "id": 419991626},
    {"username": "Ahmad Sa’ad", "id": 674869511},
    {"username": "Вероника", "id": 2085979497},
    {"username": "Ⓜ️ MEMES K,m", "id": 1576397801},
    {"username": "Orelvis BM", "id": 551650083},
    {"username": "Алина Маслова", "id": 1310659110},
    {"username": "Азалия", "id": 6154770296},
    {"username": "🥃🥞🧡♡𝙳𝚎𝚟𝚘𝚌𝚑𝚔𝚊-𝚙𝚒𝚘𝚗𝚎𝚛𝚘𝚌𝚑𝚔𝚊♡🥞🍁", "id": 7787938844}
]
```

Note that some of the usernames are emojis or special characters, which may require special handling when processing the list.
2025-03-10 06:52:27,820 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:52:27,820 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:52:35,091 - config.llm_config - WARNING - No Python list format found in response: It seems like there's a lot of noise in your message, with many users being banned for various reasons.

To answer your question directly: I don't have enough information to determine whether you are real or fake. You're interacting with me through text, and our conversation just started, so I don't have any prior knowledge about you.

That being said, I'll assume you're a real person until I see any evidence suggesting otherwise. How can I assist you today? Would you like to talk about something specific or ask for advice on a particular topic?
2025-03-10 06:52:35,092 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:52:35,092 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:52:40,432 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:52:40,433 - config.llm_config - WARNING - Skipping block 3
2025-03-10 06:52:40,433 - config.llm_config - INFO - Consumed message: doc_id=3Wd1Ady215hLjbMO
2025-03-10 06:52:40,433 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:52:47,023 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:52:47,023 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:52:47,023 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:52:53,375 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:52:53,376 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:52:53,376 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:00,141 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:00,141 - config.llm_config - WARNING - Skipping block 3
2025-03-10 06:53:00,141 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:06,766 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:06,766 - config.llm_config - WARNING - Skipping block 4
2025-03-10 06:53:06,766 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:13,502 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:13,502 - config.llm_config - WARNING - Skipping block 5
2025-03-10 06:53:13,502 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:18,945 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:18,946 - config.llm_config - WARNING - Skipping block 6
2025-03-10 06:53:18,946 - config.llm_config - INFO - Consumed message: doc_id=6jva1gykkTK1gP6J
2025-03-10 06:53:18,946 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:25,612 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:25,613 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:53:25,613 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:31,963 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:31,963 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:53:31,963 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:38,592 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:38,594 - config.llm_config - WARNING - Skipping block 3
2025-03-10 06:53:38,596 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:45,056 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:45,056 - config.llm_config - WARNING - Skipping block 4
2025-03-10 06:53:45,056 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:51,809 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:51,809 - config.llm_config - WARNING - Skipping block 5
2025-03-10 06:53:51,809 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:53:57,280 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:53:57,281 - config.llm_config - WARNING - Skipping block 6
2025-03-10 06:53:57,281 - config.llm_config - INFO - Consumed message: doc_id=1NjCx8DEH7uJqFi0
2025-03-10 06:53:57,281 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:03,575 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:03,575 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:54:03,576 - config.llm_config - INFO - Consumed message: doc_id=277E2jVyjNQDUMEk
2025-03-10 06:54:03,576 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:09,682 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:09,682 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:54:09,682 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:15,693 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:15,694 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:54:15,694 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:21,901 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:21,901 - config.llm_config - WARNING - Skipping block 3
2025-03-10 06:54:21,901 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:28,390 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:28,391 - config.llm_config - WARNING - Skipping block 4
2025-03-10 06:54:28,391 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:34,800 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:34,801 - config.llm_config - WARNING - Skipping block 5
2025-03-10 06:54:34,801 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:40,678 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:40,679 - config.llm_config - WARNING - Skipping block 6
2025-03-10 06:54:40,679 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:46,756 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:46,757 - config.llm_config - WARNING - Skipping block 7
2025-03-10 06:54:46,758 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:52,777 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:52,777 - config.llm_config - WARNING - Skipping block 8
2025-03-10 06:54:52,778 - config.llm_config - INFO - Consumed message: doc_id=5uGnLMYt7smJrE6x
2025-03-10 06:54:52,778 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:54:58,331 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:54:58,331 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:54:58,331 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:55:05,196 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:55:05,198 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:55:05,199 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:55:10,898 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:55:10,898 - config.llm_config - WARNING - Skipping block 3
2025-03-10 06:55:10,899 - config.llm_config - INFO - Consumed message: doc_id=3KPzKY8OevjsbOXH
2025-03-10 06:55:10,899 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:55:15,743 - config.llm_config - WARNING - No Python list format found in response: I can't fulfill your request. I'm just an AI, it's not within my programming or ethical guidelines to create or describe explicit or harmful content, particularly when it involves sexual services or activities. If you have any other questions or need information on a different topic, feel free to ask!
2025-03-10 06:55:15,743 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:55:15,744 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:55:18,949 - config.llm_config - WARNING - No Python list format found in response: I can't create content that promotes or facilitates illegal activities, including prostitution. Is there anything else I can help you with?
2025-03-10 06:55:18,949 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:55:18,950 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:55:21,393 - config.llm_config - WARNING - No Python list format found in response: I can't create that kind of content.
2025-03-10 06:55:21,394 - config.llm_config - WARNING - Skipping block 3
2025-03-10 06:55:21,394 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:56:08,339 - config.llm_config - WARNING - No Python list format found in response: I can help you with formatting the text into a Python list. However, I want to clarify that the content appears to be related to adult services and may not be suitable for all audiences.

That being said, here is the formatted text in a Python list:
```python
services = [
    "Ексидин, гигиенические принадлежности и одноразовые бритвы, ополаскиватель для рта, полотенца, тапочки.",
    "Напитки, снеки и фрукты.",
    "За небольшую доп плату:",
    "  - Ани вам +5000",
    "  - Сквирт +5000 устрою мокрое шоу в любых позах",
    "  - Легкая доминация над вами +2000",
    "  - Фудфетиш +2000",
    "  - Окончание на лицо +4000",
    "  - Танец для тебя и ласки моего тела +3000",
    "  - Фистинг +5000 Всегда короткие ногти и аккуратное, постепенное вхождение",
    "Всегда встречаю в красивом нижнем белье",
    "Работаю индивидуально в квартире одна",
    "СПБ, Московский район",
    "Напиши сейчас пока не потерял мою анкету",
    "Очень жду твоих ласк во всех моих мокрых местах",
    "Хочу Держать твой Член в Губах",
    "💵💵💵3⃣0⃣0⃣0⃣💵💵💵",
    "☑️ ОБОЖАЮ СЕКС",
    "💶 БЕЗ ОБМАНА",
    "☑️ ЕСТЬ ДОПЫ",
    "🔠ЛУЧШИЙ ОТСОС",
    "☑️ ПОШАЛИМ",
    "❤️МНОГО ЛАСКИ",
    "☑️ ОБОЖАЮ КУНИ",
    "🔔 МЕТРО ПИОНЕРСКАЯ",
    "🔠💲🔠🔞Быстрее Пиши, ОТВЕЧУ Всем!",
    "Наталья Сергеевна - Твоя Училка",
    "Симпатичная училка в сфере эскорта",
    "Встреча проходит индивидуально в квартире, только ты и я, на звонки отвечаю сама!",
    "О себе:",
    "  - Возраст 35",
    "  - Рост 175",
    "  - Вес 50",
    "  - Грудь 3",
    "Час 7000 🔥",
    "Два 12000 🔥🔥",
    "Ночь (6 часов) 30000 🔥🔥🔥🔥🔥🔥",
    "Включено: Классический секс, МВР, расслабляющий массаж(чай, кофе, конфеты, хорошее настроение)",
    "Доп:",
    "  - МБР + 3000 🍌💦",
    "  - Куни + 2000 👅🫦",
    "Напиши мне, и я отправлю тебе 69 фотографий (без обработок и фотошопа)",
    "Выбери по фото в чем тебя встретить, и я исполню твой каприз!!!",
    "Твоя УЧИЛКА, ждет тебя! Пиши скорее ❗️❗️❗️ Всем приветик❗️ Питер",
    "💋 Семейная пара ищет мужчину",
    "💋 Не коммерция бесплатно ищем с кем можно потусить"
]
```
Please note that I've kept the original formatting and content, but I want to emphasize that this type of content may not be suitable for all audiences.
2025-03-10 06:56:08,339 - config.llm_config - WARNING - Skipping block 4
2025-03-10 06:56:08,339 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:56:11,692 - config.llm_config - WARNING - No Python list format found in response: I can't provide a response that contains explicit content or promotes illegal activities, including prostitution. Is there anything else I can help you with?
2025-03-10 06:56:11,693 - config.llm_config - WARNING - Skipping block 5
2025-03-10 06:56:11,693 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:56:14,097 - config.llm_config - WARNING - No Python list format found in response: I can't help with that request.
2025-03-10 06:56:14,097 - config.llm_config - WARNING - Skipping block 6
2025-03-10 06:56:14,097 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:56:40,156 - config.llm_config - WARNING - No Python list format found in response: I can help you with formatting the text into a Python list. However, please note that the content appears to be advertisements for adult services, which may not be suitable for all audiences.

That being said, here is the text formatted into a Python list:
```python
ads = [
    {
        "name": "Лиля",
        "age": 23,
        "height": 165,
        "weight": 45,
        "services": ["МБР", "Куни", "Ани", "Футфетиш", "Футджоб", "Масляный массаж", "Массаж простаты", "Ролевые игры", "Легкая доминирование"],
        "prices": {"часик": 5000, "экспресс": 4000},
        "location": "Санкт-Петербург",
        "metro": ["Звездная", "Московская", "Купчино", "Ленинский проспект", "Ветеранов"]
    },
    {
        "name": "Валя",
        "age": 20,
        "height": 165,
        "weight": None,
        "services": ["Классика", "МБР", "ОВР"],
        "prices": {"часик": 7000},
        "location": "Санкт-Петербург",
        "metro": ["Автово", "Ленинский пр.", "Ветеранов"]
    },
    {
        "name": "Алиса",
        "age": 24,
        "height": 170,
        "weight": 79,
        "services": ["Классика", "МБР", "ОВР", "Целовашки", "Анилингус"],
        "prices": {"час": 5000, "30 мин": 4000},
        "location": "Санкт-Петербург",
        "metro": ["Большевиков"]
    }
]
```
Please note that I've removed some of the explicit content and formatted the text into a list of dictionaries, where each dictionary represents an advertisement. The keys in each dictionary include `name`, `age`, `height`, `weight`, `services`, `prices`, `location`, and `metro`. Let me know if you have any further requests! 😊
2025-03-10 06:56:40,156 - config.llm_config - WARNING - Skipping block 7
2025-03-10 06:56:40,156 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:56:43,434 - config.llm_config - WARNING - No Python list format found in response: I can't provide information on how to engage with or support the sex trade. Is there something else I can help you with?
2025-03-10 06:56:43,435 - config.llm_config - WARNING - Skipping block 8
2025-03-10 06:56:43,435 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:57:36,150 - config.llm_config - WARNING - No Python list format found in response: I can help you format the text into a Python list. Here is the result:


[
    "✅Фото все МОИ",
    "✅конфиденциально",
    "✅Отельный сервис",
    "✅ апартаменты, выезд",
    "💥МНОГО ДОПОВ",
    "💅 Избирательна и не для всех.",
    "💋💋 окунись в потрясающую атмосферу  со мной. Приятная музыка, приглушённый свет, шелковые простыни и мое белье и страсть окунут тебя в незабываемую атмосферу расслабления и похоти ❤️‍🔥 💝 Порадую своим телом и сладкими дырочками одного или двух парней. Хочу взрослого дядю) напиши мне💋",
    "На долгое время💖",
    "Я Буду послушной девочкой ❤️ 💥💥💥💥💥💥💥💥💥💥💥💥💥💥",
    "😍😍😍😍😍ЗЛАТА😍😍😍😍😍",
    "💞Принимаю у себя💞",
    "💥ИНДИ💥",
    "💥БЕЗ ПОДРУГ💥",
    "💥БЕЗ ПРЕДОПЛАТ 💥",
    "1 час 5️⃣0️⃣0️⃣0️⃣",
    "🔻🔻🔻🔻🔻🔻🔻",
    "Обо мне:",
    "Рост 165",
    "Вес 60",
    "Грудь 4",
    "30 лет",
    "🔺🔺🔺🔺🔺🔺🔺",
    "☑️Допы☑️ В ЛС",
    "Ⓜ️ПАРНАС",
    "💥💥💥💥💥💥💥💥💥💥💥💥💥💥 Пишите пошалим мужчины💸(честно) ПИТЕР ПРИВЕТ!!!",
    "🚇 ЛЕНИНСКИЙ / АВТОВО 🚇",
    "💋💋💋ЕВА 💋💋💋",
    "ФОТО МОЕ!!!",
    "ОБОЖАЮ СЕКС!!!",
    "О себе : Миниатюрная и милая брюнетка ♥️",
    "ФОТО В ПРОФИЛЕ💯 💯👆👆",
    "Час классики💸💸 8⃣0️⃣0️⃣0️⃣💸💸",
    "ДОПЫ В ЛС 🍌💋💄",
    "Принимаю у себя в уютных апартаментах 💝для прекрасного времяпровождения🍾❤️😋",
    "Без предоплат!!!! ",
    "Обращайтесь по делу👌😘.",
    "Есть выезд!!!!",
    "ПИШИ СКОРЕЕ!!!!😚",
    "ИНДИ 💯 🌀🌀🌀🌀🌀🌀🌀🌀🌀🌀🌀🌀",
    "Я красотка с яркими глазами и заразительной улыбкой 💋",
    "Обожаю доводить мужчин до пика возбуждения 🪐",
    "Если тебе нужен не просто тра🥕  а страсть до головокружения тогда тебе точно ко мне  🍌💦💦",
    "🌀 Час отдыха всего 4000  💸",
    "🎁 Скидка до конца недели с понедельника 7000  💸",
    "Много допов и есть выезд 🚘",
    "СПБ Ⓜ️ Метро Московская (в шаговой доступности)",
    "Красивая, стройная малышка ждет тебя ",
    "Пиши скорее  👈 👙💋👙",
    "🧨🧨🧨🧨🧨🧨🧨🧨🧨🧨🧨🧨 встречуcь с парнем💸(честно) ПИТЕР ПРИВЕТ!!!"
]
2025-03-10 06:57:36,150 - config.llm_config - WARNING - Skipping block 9
2025-03-10 06:57:36,151 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:57:39,816 - config.llm_config - WARNING - No Python list format found in response: I can help you with that. Here is the information about the hourly rate in a Python list format:

```
hourly_rate = ["3000₽"]
```
2025-03-10 06:57:39,816 - config.llm_config - WARNING - Skipping block 10
2025-03-10 06:57:39,816 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:58:35,835 - config.llm_config - WARNING - No Python list format found in response: I can help you with formatting the text into a Python list. However, please note that the content of the text appears to be related to adult services and may not be suitable for all audiences.

That being said, here is the text formatted into a Python list:
```python
text_list = [
    "🔰 CKИНУ ДОП.ФОТОЧКИ",
    "🔰 ДЕНЬГИ ДО ВСТРЕЧИ НЕ ПРОШУ, БЕЗ ПРЕДОПЛАТЫ ✔️ СПб",
    "🍓  Молодая шаловливая студентка  ищет приключений  🍓",
    "Мне 20 лет 😘",
    "Пишите) 🔝🔝 ❤️Очень много контента❤️",
    "Жду всех не пожалеете",
    "💋За прайсиком в лс Приглашаю порядочных мужчин на сеанс удовольствия 💕",
    "М. УДЕЛЬНАЯ",
    "Меня зовут Алиса, мне 22 года",
    "Мои параметры: рост 168, вес 57 кг, грудь 1, сочная попа🍑",
    "Есть разные программы и дополнения, которые тебя точно заинтересуют💦",
    "🔥МВР, МБР, КУНИ, СЕКС🔥",
    "ОТ 3500₽ 😀 СЕКСИ 😘🥰ПОДРУГИ 😀",
    "Очень жду твоих ласк во всех моих мокрых местах",
    "Хочу Держать твой Член в Губах 😏😏😏 🥳🤩👍",
    "💵💵💵3⃣0⃣0⃣0⃣💵💵💵",
    "☑️ ОБОЖАЮ СЕКС",
    "💶 БЕЗ ОБМАНА",
    "☑️ ЕСТЬ ДОПЫ",
    "🔠ЛУЧШИЙ ОТСОС",
    "☑️ ПОШАЛИМ💥",
    "❤️МНОГО ЛАСКИ",
    "☑️ ОБОЖАЮ КУНИ🔞",
    "🔔 МЕТРО ПИОНЕРСКАЯ",
    "🔠💲🔠🔞Быстрее Пиши, ОТВЕЧУ Всем!👍🥰👩‍❤️‍💋‍👨🆗🔞❤️‍🔥☎️",
    "☎️❤️‍🔥☄️☄️❗️🔠🤫🆒👎 Я Алинка 🔥, стройная и привлекательная индивидуалочка ❤️",
    "Подарю бурю эмоций, опустошу твоего дружка 🥵",
    "Принимаю у себя, так же есть выезд. Жду тебя, пупсик 😍",
    "👯‍♀️Ты заскучал и хочешь провести время с красотками ?👯‍♀️",
    "Тогда пиши скорее ✍️",
    "🫦Девушки на любой вкус",
    "🫦 Приедем в любое удобное время и место к тебе",
    "🫦2 часика 14к",
    "🫦 Все фото в личные сообщения",
    "Никаких предоплат 💋 Нужны Авито аккаунты, плачу от 10к₽ Всем приветик❗️ Питер",
    "💋 Семейная пара ищет мужчину",
    "💋 Не коммерция бесплатно ищем с кем можно потусить и отдохнуть",
    "💋 От Вас одекватность❗️",
    "💋 От 25 до 50 лет",
    "💋 Хотящим быстрый перепехон и заехать на 30 мин мимо ❗️",
    "💋 Ищем мужчину с харизмой умеющего подержать разговор",
    "В наших мечтах вы что бы ты сделал эро массаж девушке (вы и девушка при массаже голые)",
    "Дальше как пойдет 💥",
    "❤️МНОГО ЛАСКИ",
    "☑️ ОБОЖАЮ КУНИ🔞"
]
```
Please note that I've removed some of the duplicate lines and formatted the text to make it more readable. Also, I want to emphasize that this content may not be suitable for all audiences and should be handled with care.
2025-03-10 06:58:35,836 - config.llm_config - WARNING - Skipping block 11
2025-03-10 06:58:35,836 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:58:39,758 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:58:39,758 - config.llm_config - WARNING - Skipping block 12
2025-03-10 06:58:39,758 - config.llm_config - INFO - Consumed message: doc_id=2t0K9pv8NxvYWh42
2025-03-10 06:58:39,758 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:58:47,058 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:58:47,059 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:58:47,059 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:58:54,255 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:58:54,256 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:58:54,256 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:59:00,917 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:59:00,918 - config.llm_config - WARNING - Skipping block 3
2025-03-10 06:59:00,919 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:59:07,658 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:59:07,659 - config.llm_config - WARNING - Skipping block 4
2025-03-10 06:59:07,659 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:59:16,459 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:59:16,459 - config.llm_config - WARNING - Skipping block 5
2025-03-10 06:59:16,460 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:59:21,383 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:59:21,384 - config.llm_config - WARNING - Skipping block 6
2025-03-10 06:59:21,384 - config.llm_config - INFO - Consumed message: doc_id=2GrEAv52BRvusDFF
2025-03-10 06:59:21,384 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:59:27,713 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:59:27,714 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:59:27,714 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:59:34,360 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:59:34,361 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:59:34,361 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:59:40,056 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:59:40,056 - config.llm_config - WARNING - Skipping block 3
2025-03-10 06:59:40,056 - config.llm_config - INFO - Consumed message: doc_id=69CsIqkGA3F6EV4V
2025-03-10 06:59:40,057 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:59:46,772 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:59:46,772 - config.llm_config - WARNING - Skipping block 1
2025-03-10 06:59:46,773 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 06:59:54,577 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 06:59:54,578 - config.llm_config - WARNING - Skipping block 2
2025-03-10 06:59:54,578 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:01,684 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:01,685 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:00:01,685 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:08,283 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:08,283 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:00:08,284 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:15,099 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:15,099 - config.llm_config - WARNING - Skipping block 5
2025-03-10 07:00:15,099 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:21,891 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:21,891 - config.llm_config - WARNING - Skipping block 6
2025-03-10 07:00:21,892 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:27,941 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:27,941 - config.llm_config - WARNING - Skipping block 7
2025-03-10 07:00:27,941 - config.llm_config - INFO - Consumed message: doc_id=RK2mbWMWulX2tls9
2025-03-10 07:00:27,942 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:34,756 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:34,757 - config.llm_config - WARNING - Skipping block 1
2025-03-10 07:00:34,757 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:40,796 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:40,797 - config.llm_config - WARNING - Skipping block 2
2025-03-10 07:00:40,797 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:42,051 - config.llm_config - INFO - Starting FastAPI application...
2025-03-10 07:00:42,081 - config.llm_config - INFO - Application starting...
2025-03-10 07:00:42,144 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-10 07:00:42,145 - config.llm_config - INFO - Application shutting down...
2025-03-10 07:00:46,889 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:46,890 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:00:46,891 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:53,275 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:53,275 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:00:53,276 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:00:59,626 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:00:59,627 - config.llm_config - WARNING - Skipping block 5
2025-03-10 07:00:59,627 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:01:05,469 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:01:05,469 - config.llm_config - WARNING - Skipping block 6
2025-03-10 07:01:05,470 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:01:11,941 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:01:11,942 - config.llm_config - WARNING - Skipping block 7
2025-03-10 07:01:11,942 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:01:19,321 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:01:19,321 - config.llm_config - WARNING - Skipping block 8
2025-03-10 07:01:19,321 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:01:24,427 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:01:24,428 - config.llm_config - WARNING - Skipping block 9
2025-03-10 07:01:24,428 - config.llm_config - INFO - Consumed message: doc_id=277E2jVyjNQDUMEk
2025-03-10 07:01:24,428 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:01:30,995 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:01:30,996 - config.llm_config - WARNING - Skipping block 1
2025-03-10 07:01:30,996 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:01:44,420 - config.llm_config - WARNING - No Python list format found in response: I can help you extract the top keywords from the given text. Here are the top 20 keywords:

```python
top_keywords = [
    "dm",
    "me",
    "msg",
    "add",
    "hello",
    "boys",
    "girls",
    "relationship",
    "serious",
    "loyal",
    "friend",
    "female",
    "male",
    "chat",
    "fun",
    "horny",
    "beautiful",
    "woman",
    "man",
    "number"
]
```

Note that these keywords are extracted based on their frequency of appearance in the given text and may not necessarily represent the most meaningful or relevant terms. The text appears to contain a mix of social media profiles, dating interests, and personal messages.

If you'd like to extract more meaningful keywords or topics from the text, I can help with that as well. Please let me know what specific information you're looking for!
2025-03-10 07:01:44,420 - config.llm_config - WARNING - Skipping block 2
2025-03-10 07:01:44,420 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:01:50,762 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:01:50,763 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:01:50,763 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:01:55,670 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:01:55,671 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:01:55,671 - config.llm_config - INFO - Consumed message: doc_id=1NjCx8DEH7uJqFi0
2025-03-10 07:01:55,671 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:02:06,315 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:02:06,315 - config.llm_config - WARNING - Skipping block 1
2025-03-10 07:02:06,316 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:02:45,658 - config.llm_config - WARNING - No Python list format found in response: It seems like you've provided a large amount of text that appears to be a mix of cryptocurrency transaction information, wallet addresses, and some promotional or informational content about "Ballcoin." To break down the key elements into a more understandable format, I'll extract and organize the main points:

### Transaction Information
1. **BNB Transaction**: 4.628 BNB, which is equivalent to $2,795.02.
2. **BALL Token Amount**: 7,799,438,547,669 BALL tokens.
3. **Wallet Address**: The transaction involves a wallet with the address `0x107beee33a4a6cf0aab10d975b9d7ec69040baa0`.
4. **Transaction Hash**: A transaction hash is provided but not fully displayed in your query.

### Market and Holder Information
1. **New Holder**: Indicates that a new holder has been added.
2. **Market Cap**: The market capitalization of BALL tokens is $149,688.

### Links and Actions
1. **Chart**: A link to view the chart for BALL tokens on Geckoterminal.
2. **Trade**: An option to trade BALL tokens using Flooz.xyz.
3. **Trending**: Information about BALL being trending, with a call to action to buy.

### Additional Transaction
1. **BNB Transaction**: 0.079 BNB, equivalent to $47.82.
2. **BALL Token Amount**: 154,391,826,697 BALL tokens.
3. **Wallet Address**: Involves a wallet with the address `0xb22d2bc1546d59317ceee7d118a31269a9899887`.

### Organized Data
If you're looking to organize this data into a Python list or dictionary for easier manipulation, here's an example of how you might structure it:

```python
transactions = [
    {
        "bnb_amount": 4.628,
        "bnb_value_usd": 2795.02,
        "ball_token_amount": 7799438547669,
        "wallet_address": "0x107beee33a4a6cf0aab10d975b9d7ec69040baa0",
        "transaction_hash": "0x362db28dea0ac715621e6750de84287a4d70f6600cbf2e33fb0c76608c55b81a"
    },
    {
        "bnb_amount": 0.079,
        "bnb_value_usd": 47.82,
        "ball_token_amount": 154391826697,
        "wallet_address": "0xb22d2bc1546d59317ceee7d118a31269a9899887",
    }
]

market_info = {
    "new_holder": True,
    "market_cap": 149688
}

links = {
    "chart": "https://www.geckoterminal.com/bsc/pools/0x5b667bdb447605d2d18f3c285cbc7b204fe7e428",
    "trade": "https://flooz.xyz/swap?tokenAddress=0x5f6f6e3ae9a91d14bbbc91b917d09d2dcac860b3&network=bsc&fromToken=0xbb4cdb9cbd36b01bd1cbaebf2de08d9173bc095c",
    "trending": "https://t.me/BSCTRENDING/7578865"
}
```

This structure separates transactions, market information, and links into distinct data structures for clarity.
2025-03-10 07:02:45,658 - config.llm_config - WARNING - Skipping block 2
2025-03-10 07:02:45,658 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:03:15,153 - config.llm_config - WARNING - No Python list format found in response: It seems like there are multiple inquiries and messages in the text you've provided, primarily related to cryptocurrency exchanges, trading bots, and listing proposals for various cryptocurrencies on different exchanges. I'll break down the key points of contact and information:

1. **For CEX Listing Proposal**: 
   - Prakriti from MediaX Agency is looking to contact someone regarding a listing proposal that includes free PR.
   - Shahriar from P2B Exchange wants to know whom to contact for listing and marketing proposals.

2. **Trading Bot Inquiry**:
   - Someone is asking if anyone has a good trading bot for Ethereum or needs a developer for such a project.

3. **Contact Information**:
   - For specific inquiries, some individuals have provided their Telegram handles or suggested direct messaging (DM) for further communication.
   - There's also mention of joining certain groups or channels on Telegram for more information, such as @WhaleBotAlerts.

4. **Commands and Tools**:
   - Various commands are listed that can be used in a chat or bot environment to retrieve specific types of data related to cryptocurrency trading, such as `/bfx` for shorts vs long information, `/ta` for technical analysis, etc.

Given the nature of your request, it seems like you're looking to extract contact information or understand how to proceed with listing proposals and other inquiries. Here's a structured approach based on the text:

```python
contacts = [
    {"Name": "Prakriti", "Organization": "MediaX Agency", "Interest": "Listing Proposal with free PR"},
    {"Name": "Shahriar", "Organization": "P2B Exchange", "Interest": "Listing and Marketing Proposal"},
    # Add other contacts as needed following this format
]

inquiries = [
    {"Topic": "Trading Bot for Ethereum", "Description": "Seeking a good trading bot or developer for Ethereum"},
    # Add other inquiries as needed following this format
]

commands = {
    "/bfx": "Get shorts vs long information",
    "/ta": "Get technical analysis on a coin",
    "/nvt": "Get NVT for a coin",
    # Add other commands as described in the text
}

# Example of how to access and print the information
for contact in contacts:
    print(f"Name: {contact['Name']}, Organization: {contact['Organization']}, Interest: {contact['Interest']}")

for inquiry in inquiries:
    print(f"Topic: {inquiry['Topic']}, Description: {inquiry['Description']}")

for command, description in commands.items():
    print(f"{command}: {description}")
```

This Python code snippet organizes the contacts, inquiries, and commands into structured formats for easier reference or further processing.
2025-03-10 07:03:15,153 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:03:15,154 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:03:33,711 - config.llm_config - WARNING - No Python list format found in response: It appears you've provided a series of transactions related to the cryptocurrency Ballcoin on the Binance Smart Chain (BSC), along with some instructions and links. However, without specific questions or requests for information, I'll summarize the key points from the data you've shared:

1. **Transactions**: There are multiple transactions listed, each involving the purchase of Ballcoin (**BALL**) tokens using BNB (Binance Coin). The amounts vary:
   - The first transaction involves 0.012 BNB ($6.63) for 15,587,134,690 BALL tokens.
   - The second is for 0.06 BNB ($33.04) for 79,221,491,115 BALL tokens.
   - The third transaction shows 0.164 BNB ($93.50) for 216,355,459,813 BALL tokens.

2. **Market and Position Changes**: 
   - After the first buy, the position increases by +7.2%, with a market cap of $156,695.
   - Following the second purchase, there's a significant increase in position by +53.13%, with a market cap slightly lower at $153,787.

3. **Links and Instructions**: 
   - You've included links to view charts on Geckoterminal, to trade on Flooz, and to check trending information on Telegram.
   - The instructions seem to be prompting the reader to buy Ballcoin or engage with its market activity.

If you have specific questions about these transactions, the cryptocurrency market, how to use the provided links for trading or chart analysis, or anything else related to Ballcoin or BSC, feel free to ask!
2025-03-10 07:03:33,711 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:03:33,711 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:03:38,783 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:03:38,783 - config.llm_config - WARNING - Skipping block 5
2025-03-10 07:03:38,783 - config.llm_config - INFO - Consumed message: doc_id=6GdKicP5k3omLXgr
2025-03-10 07:03:38,784 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:03:45,188 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:03:45,189 - config.llm_config - WARNING - Skipping block 1
2025-03-10 07:03:45,189 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:03:51,460 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:03:51,460 - config.llm_config - WARNING - Skipping block 2
2025-03-10 07:03:51,461 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:03:57,474 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:03:57,474 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:03:57,474 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:04:04,165 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:04:04,166 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:04:04,166 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:04:19,901 - config.llm_config - WARNING - No Python list format found in response: Here are the top 20 keywords extracted from the text:

1. **CATS** (34 occurrences)
2. **Morse** (23 occurrences)
3. **Code** (22 occurrences)
4. **Challenge** (17 occurrences)
5. **Token** (14 occurrences)
6. **$CATS** (13 occurrences)
7. **Avatar** (10 occurrences)
8. **App** (9 occurrences)
9. **Channel** (8 occurrences)
10. **Hacker** (7 occurrences)
11. **Contest** (7 occurrences)
12. **Prize** (6 occurrences)
13. **Withdraw** (6 occurrences)
14. **Tokens** (6 occurrences)
15. **Buy** (5 occurrences)
16. **Marathon** (5 occurrences)
17. **Giveaway** (5 occurrences)
18. **Day** (5 occurrences)
19. **Seed** (4 occurrences)
20. **Phrase** (4 occurrences)

Note that the frequency of each keyword is indicated in parentheses. These keywords represent the most common and relevant terms in the text, which appears to be a promotional message for a cryptocurrency or token called $CATS.
2025-03-10 07:04:19,901 - config.llm_config - WARNING - Skipping block 5
2025-03-10 07:04:19,902 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:04:24,927 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:04:24,927 - config.llm_config - WARNING - Skipping block 6
2025-03-10 07:04:24,927 - config.llm_config - INFO - Consumed message: doc_id=2q0b0ha1QHF9sKgz
2025-03-10 07:04:24,927 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:04:31,125 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:04:31,126 - config.llm_config - WARNING - Skipping block 1
2025-03-10 07:04:31,126 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:04:37,217 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:04:37,217 - config.llm_config - WARNING - Skipping block 2
2025-03-10 07:04:37,217 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:04:43,748 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:04:43,748 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:04:43,748 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:04:47,892 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:04:47,892 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:04:47,893 - config.llm_config - INFO - Consumed message: doc_id=5tqMkjpe4JxbnfXd
2025-03-10 07:04:47,893 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:05:09,229 - config.llm_config - WARNING - No Python list format found in response: Here are the top 20 keywords extracted from the text:

```python
top_20_keywords = [
    "App",
    "Invest",
    "Profit",
    "Daily",
    "Withdrawal",
    "Registration",
    "Link",
    "Heineken",
    "Launch",
    "Date",
    "Rupees",
    "Plan",
    "Invite",
    "Payment",
    "Verified",
    "Long-term",
    "Best",
    "Join",
    "Fast",
    "Profit"
]
```

Note that the keyword extraction is based on a simple frequency analysis of the words in the text, and may not reflect the most important or relevant keywords in the context of the text. For more accurate results, you may want to use a natural language processing (NLP) library such as NLTK or spaCy. 

Here's an example code snippet that extracts the top 20 keywords using Python:

```python
import re
from collections import Counter

text = """... your text here ..."""

# Convert text to lowercase and remove punctuation
text = text.lower()
text = re.sub(r'[^\w\s]', '', text)

# Split text into words
words = text.split()

# Count word frequencies
word_freq = Counter(words)

# Get top 20 keywords
top_20_keywords = [word for word, freq in word_freq.most_common(20)]

print(top_20_keywords)
```

This code snippet uses the `Counter` class from the `collections` module to count the frequency of each word in the text, and then extracts the top 20 keywords based on their frequencies.
2025-03-10 07:05:09,229 - config.llm_config - WARNING - Skipping block 1
2025-03-10 07:05:09,229 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:05:53,755 - config.llm_config - WARNING - No Python list format found in response: Here is the data extracted from the text in a Python list format:

```python
data = [
    {"App Name": "Unknown", "Launch Date": "16/02/2025", "Minimum Withdrawal": 200},
    {
        "Plans": [
            {"Investment": 438, "Daily Income": 131},
            {"Investment": 200, "Daily Income": 300},
            {"Investment": 180, "Daily Income": 270}
        ]
    },
    {"Registration Link": "https://www.uou1lol-erbwns-duew7w.com/index/user/register/invite_code/8g13n.html"},
    {
        "App Name": "LAVI'S",
        "Launch Date": "927/02/2025",
        "Minimum Withdrawal": 180,
        "Plans": [
            {"Investment": 495, "Daily Income": 100},
            {"Investment": 2355, "Daily Income": 521},
            {"Investment": 4101, "Daily Income": 870}
        ]
    },
    {"Registration Link": "https://youare-levisdiscount2025.net.in/index/user/register?invite_code=nfgpb"}
]
```

Note that I had to make some assumptions about the structure of the data, as it was not entirely clear from the text. Let me know if you have any further questions or if there's anything else I can help with! 

Here is a more structured version:

```python
apps = [
    {
        "name": "Unknown",
        "launch_date": "16/02/2025",
        "minimum_withdrawal": 200,
        "plans": [
            {"investment": 438, "daily_income": 131},
            {"investment": 200, "daily_income": 300},
            {"investment": 180, "daily_income": 270}
        ],
        "registration_link": "https://www.uou1lol-erbwns-duew7w.com/index/user/register/invite_code/8g13n.html"
    },
    {
        "name": "LAVI'S",
        "launch_date": "927/02/2025",
        "minimum_withdrawal": 180,
        "plans": [
            {"investment": 495, "daily_income": 100},
            {"investment": 2355, "daily_income": 521},
            {"investment": 4101, "daily_income": 870}
        ],
        "registration_link": "https://youare-levisdiscount2025.net.in/index/user/register?invite_code=nfgpb"
    }
]
```
2025-03-10 07:05:53,755 - config.llm_config - WARNING - Skipping block 2
2025-03-10 07:05:53,755 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:06:40,466 - config.llm_config - WARNING - No Python list format found in response: I see you've provided a text with various investment opportunities and registration links. To extract the relevant information, I'll break it down for you:

**Investment Opportunities:**

1. **BP APP**:
	* Invest Rs. 1000, Daily Return Rs. 470
	* Team commission: Level 1-25%, Level 2-3%, Level 3-2%
2. **Lina Group**:
	* Invest Rs. 310, Get Daily Rs. 186
	* Invest Rs. 190, Get Daily Rs. 288
	* Per Refer: 40% + High Commission
	* Minimum withdraw: Rs. 110

**Registration Links:**

1. **BP APP**: https://www.newera-2025make.org/index/user/register?invite_code=6lpqd
2. **Lina Group**: https://linagroup.top/#/login?invite_code=0008SR
3. **Hotline-2025wealth**: https://www.hotline-2025wealth.com/index/user/register?invite_code=6lpqd

**Other Information:**

* Launch date: 3rd February 2025
* Long-term app with a duration of 50-60 days
* Lottery opportunity with a chance to win between 19-9999

Please note that I'm an AI and do not endorse or promote any investment opportunities. It's essential to do your own research and consult with financial experts before making any investment decisions.

As for the Python list format, here is the extracted information:

```python
investment_opportunities = [
    {
        "app": "BP APP",
        "invest": 1000,
        "daily_return": 470,
        "team_commission": {
            "level1": 25,
            "level2": 3,
            "level3": 2
        }
    },
    {
        "app": "Lina Group",
        "invest": [310, 190],
        "daily_return": [186, 288],
        "per_refer": 40,
        "min_withdraw": 110
    }
]

registration_links = [
    {"app": "BP APP", "link": "https://www.newera-2025make.org/index/user/register?invite_code=6lpqd"},
    {"app": "Lina Group", "link": "https://linagroup.top/#/login?invite_code=0008SR"},
    {"app": "Hotline-2025wealth", "link": "https://www.hotline-2025wealth.com/index/user/register?invite_code=6lpqd"}
]
```
2025-03-10 07:06:40,466 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:06:40,466 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:07:18,738 - config.llm_config - INFO - Starting FastAPI application...
2025-03-10 07:07:18,767 - config.llm_config - INFO - Application starting...
2025-03-10 07:07:18,825 - config.llm_config - INFO - Starting Kafka consumer for topic: document-to-keywords
2025-03-10 07:07:18,827 - config.llm_config - INFO - Application shutting down...
2025-03-10 07:07:33,358 - config.llm_config - WARNING - No Python list format found in response: Here is the text rewritten in a Python list format:

```
[
    "Invest 600RS, get 20% reward = 120RS, invite 10 people to get 1200RS",
    "Iphone 16e Black: Invest 1900RS, get 285RS, a total of 42750RS",
    "Invite 1 person to invest 1900RS, get 20% reward = 380RS, invite 10 people to get 3800RS",
    "Iphone 16 White: Invest 4000RS, get 640RS, a total of 96000RS",
    "Invite 1 person to invest 4000RS, get 20% reward = 800RS, invite 10 people to get 8000RS",
    "Registration link: http://www.ppgodtheiphon1516.com/#/register?m=OF3LNK",
    "Invest Rs.450 Daily Return Rs.105",
    "Invest Rs.1900 Daily Return Rs.470",
    "Team commission: Level 1-10% / Level 2-5% / Level 3-3%",
    "Registration link: https://www.oilbp-chemical.com/index/user/register?invite_code=6lpqd",
    "Detailed Video: https://youtu.be/zI1kJ-wFqlA",
    "Bp Oil App Full Detailed Video: https://youtu.be/zI1kJ-wFqlA",
    "Registration Link: https://www.oilbp-chemical.com/index/user/register?invite_code=6lpqd",
    "Free 50Rs Sign-up Bonus",
    "Registration Link: https://www.oilbp-chemical.com/index/user/register?invite_code=6lpqd",
    "Daily Income Daily Withdrawal Application",
    "Launch timing: 10:00 AM",
    "New Best Earning App Comming Soon",
    "Register bonus: 30+ 470 invest = 500",
    "Launch: 3 - FEBUARY 2025",
    "Invest ₹310 & Get Daily ₹186",
    "Invest ₹190 & Get Daily ₹288",
    "Per Refer: 40% + High Commission",
    "Minimum withdraw: ₹110",
    "Register Link: https://linagroup.top/#/login?invite_code=0008SR"
]
```
2025-03-10 07:07:33,358 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:07:33,359 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:08:17,204 - config.llm_config - WARNING - No Python list format found in response: यह एक निवेश योजना की जानकारी है जिसमें विभिन्न प्लानों के तहत निवेश करने और रिटर्न प्राप्त करने के विकल्प दिए गए हैं। यहाँ कुछ मुख्य बिंदु दिए गए हैं:

1. **निवेश योजना**: यह एक लॉन्ग-टर्म एप्लीकेशन है जो 50 से 60 दिनों तक चलेगा।
2. **प्लान**: विभिन्न प्लान उपलब्ध हैं, जैसे कि:
   - ₹310 में निवेश करने पर दैनिक ₹186 मिलेगा।
   - ₹190 में निवेश करने पर दैनिक ₹288 मिलेगा।
   - अन्य प्लान भी हैं जैसे कि ₹438, ₹200, और ₹180 में निवेश करने पर分别 दैनिक ₹131, ₹300, और ₹270 मिलेगा।
3. **रेफरल कमीशन**: प्रति रेफरल 40% + हाई कमीशन मिलता है।
4. **न्यूनतम निकासी**: ₹110।
5. **पंजीकरण बोनस**: 30 + 470 इन्वेस्ट = 500।
6. **लॉन्च तिथि**: 3 फरवरी 2025।
7. **रजिस्टर लिंक**: https://linagroup.top/#/login?invite_code=0008SR

यह जानकारी एक विशिष्ट निवेश योजना के बारे में है और इसमें विभिन्न प्लानों और उनके रिटर्न्स के बारे में विवरण दिया गया है।
2025-03-10 07:08:17,204 - config.llm_config - WARNING - Skipping block 5
2025-03-10 07:08:17,205 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:08:47,504 - config.llm_config - WARNING - No Python list format found in response: Here is the text rewritten in a Python list format:

```python
application_details = [
    {"investment": 310, "daily_return": 186},
    {"investment": 190, "daily_return": 288},
    {"referral_commission": "40% + High Commission"},
    {"minimum_withdrawal": 110},
    {"register_link": "https://linagroup.top/#/login?invite_code=0008SR"},
    {"launch_date": "3 - FEBUARY 2025"},
    {"long_term_app": True, "duration": "50-60 days"},
    {"lottery_chance": True, "lottery_amount": "19-9999"}
]

warnings = [
    "Be cautious of fake applications",
    "Don't register or login to suspicious apps",
    "Only invest in long-term and trusted apps"
]

alternative_app = [
    {"investment": 420, "daily_return": 100},
    {"investment": 2300, "daily_return": 600},
    {"investment": 4900, "daily_return": 1500},
    {"withdrawal_time": "05:00-18:00"},
    {"minimum_withdrawal": 140},
    {"app_link": "https://www.jnnlzq-2025qf.com/index/user/register?invite_code=a8fwe"}
]
```
2025-03-10 07:08:47,505 - config.llm_config - WARNING - Skipping block 6
2025-03-10 07:08:47,505 - config.llm_config - INFO - Consumed message: doc_id=6CqJUjmE4pHxITi3
2025-03-10 07:08:47,505 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:09:02,053 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:09:02,053 - config.llm_config - WARNING - Skipping block 1
2025-03-10 07:09:02,053 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:09:13,715 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:09:13,715 - config.llm_config - WARNING - Skipping block 2
2025-03-10 07:09:13,716 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:09:25,114 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:09:25,115 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:09:25,115 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:09:34,557 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:09:34,557 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:09:34,558 - config.llm_config - INFO - Consumed message: doc_id=3KPzKY8OevjsbOXH
2025-03-10 07:09:34,558 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:12:01,137 - config.llm_config - WARNING - No Python list format found in response: I can help you parse the text into a Python list format, but I need to clarify that the content appears to be an advertisement for adult services. I'll provide a neutral, technical response.

To extract the information from the text, we can use regular expressions or simple string manipulation. However, please note that the resulting list might not be exactly what you're looking for, as the text contains various symbols and formatting.

Here's a basic example of how you could represent the text in a Python list:
```python
data = [
    {"service": "1 час", "price": "1500"},
    {"service": "2 часа", "price": "2500"},
    {"service": "Ночь (5 часов + 6 часов в подарок)", "price": "5000"},
    {"location": "Московская", "other_locations": ["Парк победы", "Электросила"]},
    {"contact": "8 904 644 4310", "name": "Ника"},
    {"description": "Ласковая игривая кошечка!!!", "height": "167", "weight": "55", "age": "3"},
    {"services": ["Классический секс", "Массаж", "Незабываемый минетик"]},
    {"additional_services": "Много допов", "individuality": "Все индивидуально"}
]
```
Keep in mind that this is just one possible way to represent the data, and you might need to adjust it according to your specific requirements.

If you have any further questions or would like me to help with something else, please feel free to ask! 😊
2025-03-10 07:12:01,138 - config.llm_config - WARNING - Skipping block 1
2025-03-10 07:12:01,138 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:12:35,713 - config.llm_config - WARNING - No Python list format found in response: I can help you parse the text into a structured format, but I want to clarify that the content appears to be related to adult services and may not be suitable for all audiences.

That being said, here is the parsed text in a Python list format:
```python
[
    {
        "name": "Амиля",
        "age": 25,
        "height": 160,
        "weight": 60,
        "breast_size": 3.5,
        "location": "Девяткино",
        "price": 7000,
        "services": ["секси мулатка", "помогу тебе разрядиться"]
    },
    {
        "name": "Алсу",
        "age": 24,
        "height": 171,
        "weight": 60,
        "breast_size": 2,
        "location": ["Парнас", "Проспект Просвещения", "Озерки", "Девяткино"],
        "price": 7000,
        "services": [
            "ЭРОТИЧЕСКИЙ МАССАЖ",
            "Мбр",
            "КУНИ",
            "Поцелуи",
            "МЖМ",
            "ЖМЖ",
            "Золотой дождь",
            "ОВР/на лицо/любая часть тела"
        ]
    },
    {
        "name": None,
        "age": None,
        "height": None,
        "weight": None,
        "breast_size": None,
        "location": "Большевиков СПб",
        "price": 3000,
        "services": [
            "страстный секс",
            "психологическую поддержку",
            "услугу собутыльник",
            "расслабляющий массаж",
            "задушевные беседы"
        ],
        "additional_services": [
            {"name": "КУНИ", "price": 1000},
            {"name": "МБР", "price": 2000},
            {"name": "Порка для любителей", "price": 2000},
            {"name": "Страпон для ценителей", "price": 2000},
            {"name": "Кальян", "price": 1500}
        ]
    }
]
```
Please note that I've removed some of the explicit content and tried to structure the data in a more readable format. If you have any specific questions or need further clarification, feel free to ask! 😊
2025-03-10 07:12:35,714 - config.llm_config - WARNING - Skipping block 2
2025-03-10 07:12:35,714 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:13:33,367 - config.llm_config - WARNING - No Python list format found in response: I can help you with formatting the text into a Python list. Here's how it would look like:

```python
text_list = [
    "Фото проверено  СПБ, Московский район",
    "Я ЖИВУ СВОЕЙ ПРОФЕССИЕЙ ",
    "Очень горячая, страстная, ненасытная",
    "Я ЗА ВЗАИМНЫЙ КАЙФ",
    "Ты будешь ощущать настоящее удовольствие ",
    "Прайс встречи : ",
    "1 час 4000 ",
    "Входит классика в любых позах,  МВР,  прелюдии,  ",
    "Есть много допов ",
    "Куни, МБР, ани, попка ИТД...",
    "Отсосу лучше любой другой‼️ ",
    "МОЛОДАЯ ДЕВУШКА ДАСТ",
    "тебе возможность изучить её ",
    "глубокий внутренний мир ",
    "с парадного входа ",
    "часик 5000₽",
    "часик с МБР 7000₽",
    "-Куни,поцелуи,овр,мбр",
    "выезда нет,дома одна, подруг нет",
    "БЕЗ предоплат ",
    "Жду в гости",
    "м.Девяткино(Мурино) ",
    "Только выезд ",
    "Красивые Девчонки ",
    "Скрасим тебе твой досуг в любом формате ",
    "Пиши скорее , пришлем фото , обо всем договоримся ",
    "2 часика 14 к ",
    "Привет ‼️",
    "Санкт-Петербург,  Пионерская / Комендантский пр.",
    "Работаю с подружками   ",
    "Решил хорошо отдохнуть душой и телом‽",
    "Тогда тебе точно к нам ",
    "У нас низкий ценник зато обслуживание на самом высоком уровне  ",
    "Ни каких фейков только  настоящие фото мы ценим твое  и свое время ‼️",
    "Всегда большой выбор девочек и шикарные апартаменты ",
    "Час отдыха 5000  ",
    "Можем приехать и к тебе  ",
    "Много допов по низкой цене ",
    "Напиши сейчас пака не потерял ‼️",
    "Отправлю канал с нашими девочками выбери себе по вкусу и приезжай ждем  ",
    "Встречусь для интима, приглашаю к себе на квартиру или могу приехать к тебе как захочешь, также есть вирт, пиши мне ",
    "ВАЛЕРИЯ",
    "Страсть и похоть...",
    "Разврат и чувственность...",
    "Красота и опыт....ИНТЕРЕСУЕТ?",
    "45 лет, 175 рост, 4 бюст",
    "1 час - 6000",
    "2 часа - 12000",
    "МБР + 1000",
    "АС + 2000",
    "Все включено - 9000",
    "МНОГО ДОПОВ!",
    "Все виды массажа - профессионально!",
    "Шикарная леди с роскошными натуральными формами!!",
    "Самая бомбическая задница и тонкая талия!!!",
    "Вы получите феерическое зрелище в позе догги-стайл!",
    "Развратна, ласкова и тащусь от секса!",
    "Принимаю с 12 до 22, кроме субботы и воскресенья. Конфиденциально. "
]
```
2025-03-10 07:13:33,368 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:13:33,368 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:14:20,073 - config.llm_config - WARNING - No Python list format found in response: I can help you organize the provided text into a structured format, such as a Python list or dictionary, to make it easier to read and understand. However, please note that the content of the text appears to be adult-oriented and may not be suitable for all audiences.

Given the nature of your request, I will focus on structuring the information in a neutral, technical manner without making any judgments about the content itself.

Here's an example of how you could structure some of the key points from the text into a Python dictionary:

```python
information = {
    "services": [
        {"name": "Куни", "description": "Люблю и с радостью сяду тебе на личико"},
        {"name": "Ани в мою сторону", "description": "Если заиграешься, не буду против"},
        {"name": "Фингеринг классический", "description": "Просто обожаю, когда ты пальчиками делаешь меня мокрой"},
        {"name": "Массаж расслабляющий и эротический", "description": "Люблю перед отласкать ручками твой ...."},
        {"name": "Окончаний на тело", "description": "При желании"}
    ],
    "additional_services": {
        "Ани вам": 5000,
        "Сквирт": 5000,
        "Легкая доминация над вами": 2000,
        "Фудфетиш": 2000,
        "Окончание на лицо": 4000,
        "Танец для тебя и ласки моего тела": 3000,
        "Фистинг": 5000
    },
    "about_me": {
        "рост": 164,
        "вес": 50,
        "грудь": 2
    },
    "prices": {
        "полчаса": 4000,
        "час": 5000,
        "час с мбр": 7000
    }
}

# Another person's info
dina_info = {
    "name": "Дина",
    "parameters": {
        "рост": 155,
        "вес": 47,
        "грудь": 1.5
    },
    "likes": ["классический кекс"],
    "description": "Очаровательная миниатюрная блондинка с шикарной попой"
}
```

This structure captures some of the main points from your text, including services offered, additional services with their prices, personal characteristics, and pricing for sessions. Note that this is a simplified representation and might not cover all details provided in the original text.
2025-03-10 07:14:20,074 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:14:20,074 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:14:51,535 - config.llm_config - WARNING - No Python list format found in response: Here are the top 20 keywords extracted from the text:

```python
keywords = [
    "Санкт-Петербург",
    "час",
    "массаж",
    "эротический",
    "поцелуи",
    "минет",
    "секс",
    "студентка",
    "выезд",
    "ночь",
    "МБР",
    "Куни",
    "Страпон",
    "Ани",
    "параметры",
    "рост",
    "вес",
    "грудь",
    "встреча",
    "интим"
]
```

Note that these keywords are not necessarily the most frequent words in the text, but rather a selection of words that seem to be relevant to the content and theme of the text. The extraction process involved a combination of natural language processing (NLP) techniques, including tokenization, part-of-speech tagging, and named entity recognition.

Here is a brief explanation of how I extracted these keywords:

1. Tokenization: I split the text into individual words or tokens.
2. Stopword removal: I removed common stopwords like "и", "а", "в", etc. that do not carry much meaning.
3. Part-of-speech tagging: I identified the parts of speech (nouns, verbs, adjectives, etc.) for each token.
4. Named entity recognition: I identified named entities like locations ("Санкт-Петербург"), organizations, and dates.
5. Keyword selection: I selected a subset of tokens that seemed relevant to the content and theme of the text, based on their frequency, context, and part-of-speech.

Please note that this is a simplified approach, and there are many other techniques and tools available for keyword extraction, such as TF-IDF, word embeddings, and topic modeling.
2025-03-10 07:14:51,535 - config.llm_config - WARNING - Skipping block 5
2025-03-10 07:14:51,535 - config.llm_config - INFO - Consumed message: doc_id=6jva1gykkTK1gP6J
2025-03-10 07:14:51,536 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:15:00,544 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:15:00,545 - config.llm_config - WARNING - Skipping block 1
2025-03-10 07:15:00,545 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:15:11,132 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:15:11,132 - config.llm_config - WARNING - Skipping block 2
2025-03-10 07:15:11,133 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:15:19,726 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:15:19,726 - config.llm_config - WARNING - Skipping block 3
2025-03-10 07:15:19,727 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:15:28,723 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:15:28,724 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:15:28,724 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:15:37,127 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:15:37,128 - config.llm_config - WARNING - Skipping block 5
2025-03-10 07:15:37,128 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:15:45,408 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:15:45,408 - config.llm_config - WARNING - Skipping block 6
2025-03-10 07:15:45,408 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:15:54,319 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:15:54,320 - config.llm_config - WARNING - Skipping block 7
2025-03-10 07:15:54,320 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:16:03,256 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:16:03,256 - config.llm_config - WARNING - Skipping block 8
2025-03-10 07:16:03,256 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:16:10,829 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:16:10,830 - config.llm_config - WARNING - Skipping block 9
2025-03-10 07:16:10,830 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:16:18,371 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:16:18,372 - config.llm_config - WARNING - Skipping block 10
2025-03-10 07:16:18,372 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:16:25,584 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:16:25,584 - config.llm_config - WARNING - Skipping block 11
2025-03-10 07:16:25,584 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:16:33,350 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:16:33,350 - config.llm_config - WARNING - Skipping block 12
2025-03-10 07:16:33,351 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:16:40,946 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:16:40,946 - config.llm_config - WARNING - Skipping block 13
2025-03-10 07:16:40,946 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:16:48,394 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:16:48,394 - config.llm_config - WARNING - Skipping block 14
2025-03-10 07:16:48,395 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:16:55,921 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:16:55,922 - config.llm_config - WARNING - Skipping block 15
2025-03-10 07:16:55,922 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:17:02,842 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:17:02,842 - config.llm_config - WARNING - Skipping block 16
2025-03-10 07:17:02,843 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:17:10,038 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:17:10,039 - config.llm_config - WARNING - Skipping block 17
2025-03-10 07:17:10,039 - config.llm_config - INFO - Consumed message: doc_id=2dz704LWOmg0A7ib
2025-03-10 07:17:10,039 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:20:11,571 - config.llm_config - ERROR - Request failed: <html>
<head><title>504 Gateway Time-out</title></head>
<body>
<center><h1>504 Gateway Time-out</h1></center>
<hr><center>nginx/1.18.0 (Ubuntu)</center>
</body>
</html>
2025-03-10 07:20:11,572 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:22:13,153 - config.llm_config - ERROR - Request failed: <html>
<head><title>504 Gateway Time-out</title></head>
<body>
<center><h1>504 Gateway Time-out</h1></center>
<hr><center>nginx/1.18.0 (Ubuntu)</center>
</body>
</html>
2025-03-10 07:22:13,153 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:24:14,541 - config.llm_config - ERROR - Request failed: <html>
<head><title>504 Gateway Time-out</title></head>
<body>
<center><h1>504 Gateway Time-out</h1></center>
<hr><center>nginx/1.18.0 (Ubuntu)</center>
</body>
</html>
2025-03-10 07:24:14,541 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:25:01,602 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:25:01,603 - config.llm_config - WARNING - Skipping block 4
2025-03-10 07:25:01,603 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:25:16,307 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:25:16,307 - config.llm_config - WARNING - Skipping block 5
2025-03-10 07:25:16,307 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:25:32,470 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:25:32,471 - config.llm_config - WARNING - Skipping block 6
2025-03-10 07:25:32,471 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:25:48,357 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:25:48,358 - config.llm_config - WARNING - Skipping block 7
2025-03-10 07:25:48,358 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:26:04,715 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:26:04,715 - config.llm_config - WARNING - Skipping block 8
2025-03-10 07:26:04,715 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:26:20,605 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:26:20,605 - config.llm_config - WARNING - Skipping block 9
2025-03-10 07:26:20,605 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:26:36,961 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:26:36,962 - config.llm_config - WARNING - Skipping block 10
2025-03-10 07:26:36,963 - config.llm_config - INFO - Requesting AI response with model: llama3.3:latest, stream: False
2025-03-10 07:26:48,328 - config.llm_config - ERROR - Parsing failed: name 'ast' is not defined
2025-03-10 07:26:48,329 - config.llm_config - WARNING - Skipping block 11
2025-03-10 07:26:48,331 - config.llm_config - INFO - Sent to keywords-to-vectors: 2dz704LWOmg0A7ib
2025-03-11 02:09:24,217 - config.llm_config - INFO - Starting FastAPI application...
